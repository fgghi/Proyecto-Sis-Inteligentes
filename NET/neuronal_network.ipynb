{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('valoracion_aerolineas.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/dataset')\n",
    "\n",
    "df_train = pd.read_csv('/content/dataset/train.csv')\n",
    "df_test = pd.read_csv('/content/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>...</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Inflight service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>13</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco Plus</td>\n",
       "      <td>460</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>18.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>26</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1142</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>562</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>61</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103899</th>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>23</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103900</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>2347</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103901</th>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>30</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103902</th>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>22</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103903</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>27</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1723</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103594 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender      Customer Type  Age   Type of Travel     Class  \\\n",
       "0         Male     Loyal Customer   13  Personal Travel  Eco Plus   \n",
       "1         Male  disloyal Customer   25  Business travel  Business   \n",
       "2       Female     Loyal Customer   26  Business travel  Business   \n",
       "3       Female     Loyal Customer   25  Business travel  Business   \n",
       "4         Male     Loyal Customer   61  Business travel  Business   \n",
       "...        ...                ...  ...              ...       ...   \n",
       "103899  Female  disloyal Customer   23  Business travel       Eco   \n",
       "103900    Male     Loyal Customer   49  Business travel  Business   \n",
       "103901    Male  disloyal Customer   30  Business travel  Business   \n",
       "103902  Female  disloyal Customer   22  Business travel       Eco   \n",
       "103903    Male     Loyal Customer   27  Business travel  Business   \n",
       "\n",
       "        Flight Distance  Inflight wifi service  \\\n",
       "0                   460                      3   \n",
       "1                   235                      3   \n",
       "2                  1142                      2   \n",
       "3                   562                      2   \n",
       "4                   214                      3   \n",
       "...                 ...                    ...   \n",
       "103899              192                      2   \n",
       "103900             2347                      4   \n",
       "103901             1995                      1   \n",
       "103902             1000                      1   \n",
       "103903             1723                      1   \n",
       "\n",
       "        Departure/Arrival time convenient  Ease of Online booking  \\\n",
       "0                                       4                       3   \n",
       "1                                       2                       3   \n",
       "2                                       2                       2   \n",
       "3                                       5                       5   \n",
       "4                                       3                       3   \n",
       "...                                   ...                     ...   \n",
       "103899                                  1                       2   \n",
       "103900                                  4                       4   \n",
       "103901                                  1                       1   \n",
       "103902                                  1                       1   \n",
       "103903                                  3                       3   \n",
       "\n",
       "        Gate location  ...  Inflight entertainment  On-board service  \\\n",
       "0                   1  ...                       5                 4   \n",
       "1                   3  ...                       1                 1   \n",
       "2                   2  ...                       5                 4   \n",
       "3                   5  ...                       2                 2   \n",
       "4                   3  ...                       3                 3   \n",
       "...               ...  ...                     ...               ...   \n",
       "103899              3  ...                       2                 3   \n",
       "103900              4  ...                       5                 5   \n",
       "103901              3  ...                       4                 3   \n",
       "103902              5  ...                       1                 4   \n",
       "103903              3  ...                       1                 1   \n",
       "\n",
       "        Leg room service  Baggage handling  Checkin service  Inflight service  \\\n",
       "0                      3                 4                4                 5   \n",
       "1                      5                 3                1                 4   \n",
       "2                      3                 4                4                 4   \n",
       "3                      5                 3                1                 4   \n",
       "4                      4                 4                3                 3   \n",
       "...                  ...               ...              ...               ...   \n",
       "103899                 1                 4                2                 3   \n",
       "103900                 5                 5                5                 5   \n",
       "103901                 2                 4                5                 5   \n",
       "103902                 5                 1                5                 4   \n",
       "103903                 1                 4                4                 3   \n",
       "\n",
       "        Cleanliness  Departure Delay in Minutes  Arrival Delay in Minutes  \\\n",
       "0                 5                          25                      18.0   \n",
       "1                 1                           1                       6.0   \n",
       "2                 5                           0                       0.0   \n",
       "3                 2                          11                       9.0   \n",
       "4                 3                           0                       0.0   \n",
       "...             ...                         ...                       ...   \n",
       "103899            2                           3                       0.0   \n",
       "103900            4                           0                       0.0   \n",
       "103901            4                           7                      14.0   \n",
       "103902            1                           0                       0.0   \n",
       "103903            1                           0                       0.0   \n",
       "\n",
       "                   satisfaction  \n",
       "0       neutral or dissatisfied  \n",
       "1       neutral or dissatisfied  \n",
       "2                     satisfied  \n",
       "3       neutral or dissatisfied  \n",
       "4                     satisfied  \n",
       "...                         ...  \n",
       "103899  neutral or dissatisfied  \n",
       "103900                satisfied  \n",
       "103901  neutral or dissatisfied  \n",
       "103902  neutral or dissatisfied  \n",
       "103903  neutral or dissatisfied  \n",
       "\n",
       "[103594 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_train = df_train.drop(columns=['Unnamed: 0', 'id'])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>...</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Inflight service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1142</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103899</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103900</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2347</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103901</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103902</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103903</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1723</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103594 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender  Customer Type  Age  Type of Travel  Class  Flight Distance  \\\n",
       "0            1              0   13               1      2              460   \n",
       "1            1              1   25               0      0              235   \n",
       "2            0              0   26               0      0             1142   \n",
       "3            0              0   25               0      0              562   \n",
       "4            1              0   61               0      0              214   \n",
       "...        ...            ...  ...             ...    ...              ...   \n",
       "103899       0              1   23               0      1              192   \n",
       "103900       1              0   49               0      0             2347   \n",
       "103901       1              1   30               0      0             1995   \n",
       "103902       0              1   22               0      1             1000   \n",
       "103903       1              0   27               0      0             1723   \n",
       "\n",
       "        Inflight wifi service  Departure/Arrival time convenient  \\\n",
       "0                           3                                  4   \n",
       "1                           3                                  2   \n",
       "2                           2                                  2   \n",
       "3                           2                                  5   \n",
       "4                           3                                  3   \n",
       "...                       ...                                ...   \n",
       "103899                      2                                  1   \n",
       "103900                      4                                  4   \n",
       "103901                      1                                  1   \n",
       "103902                      1                                  1   \n",
       "103903                      1                                  3   \n",
       "\n",
       "        Ease of Online booking  Gate location  ...  Inflight entertainment  \\\n",
       "0                            3              1  ...                       5   \n",
       "1                            3              3  ...                       1   \n",
       "2                            2              2  ...                       5   \n",
       "3                            5              5  ...                       2   \n",
       "4                            3              3  ...                       3   \n",
       "...                        ...            ...  ...                     ...   \n",
       "103899                       2              3  ...                       2   \n",
       "103900                       4              4  ...                       5   \n",
       "103901                       1              3  ...                       4   \n",
       "103902                       1              5  ...                       1   \n",
       "103903                       3              3  ...                       1   \n",
       "\n",
       "        On-board service  Leg room service  Baggage handling  Checkin service  \\\n",
       "0                      4                 3                 4                4   \n",
       "1                      1                 5                 3                1   \n",
       "2                      4                 3                 4                4   \n",
       "3                      2                 5                 3                1   \n",
       "4                      3                 4                 4                3   \n",
       "...                  ...               ...               ...              ...   \n",
       "103899                 3                 1                 4                2   \n",
       "103900                 5                 5                 5                5   \n",
       "103901                 3                 2                 4                5   \n",
       "103902                 4                 5                 1                5   \n",
       "103903                 1                 1                 4                4   \n",
       "\n",
       "        Inflight service  Cleanliness  Departure Delay in Minutes  \\\n",
       "0                      5            5                          25   \n",
       "1                      4            1                           1   \n",
       "2                      4            5                           0   \n",
       "3                      4            2                          11   \n",
       "4                      3            3                           0   \n",
       "...                  ...          ...                         ...   \n",
       "103899                 3            2                           3   \n",
       "103900                 5            4                           0   \n",
       "103901                 5            4                           7   \n",
       "103902                 4            1                           0   \n",
       "103903                 3            1                           0   \n",
       "\n",
       "        Arrival Delay in Minutes  satisfaction  \n",
       "0                           18.0             0  \n",
       "1                            6.0             0  \n",
       "2                            0.0             1  \n",
       "3                            9.0             0  \n",
       "4                            0.0             1  \n",
       "...                          ...           ...  \n",
       "103899                       0.0             0  \n",
       "103900                       0.0             1  \n",
       "103901                      14.0             0  \n",
       "103902                       0.0             0  \n",
       "103903                       0.0             0  \n",
       "\n",
       "[103594 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dummie = df_train.copy()\n",
    "\n",
    "# Aplicar Label Encoding a las columnas categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df_train_dummie.select_dtypes(include=['object']).columns:\n",
    "    df_train_dummie[column] = label_encoder.fit_transform(df_train_dummie[column])\n",
    "\n",
    "df_train_dummie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103899</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103900</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103901</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103902</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103594 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type of Travel  Class  Online boarding  satisfaction\n",
       "0                    1      2                3             0\n",
       "1                    0      0                3             0\n",
       "2                    0      0                5             1\n",
       "3                    0      0                2             0\n",
       "4                    0      0                5             1\n",
       "...                ...    ...              ...           ...\n",
       "103899               0      1                2             0\n",
       "103900               0      0                4             1\n",
       "103901               0      0                1             0\n",
       "103902               0      1                1             0\n",
       "103903               0      0                1             0\n",
       "\n",
       "[103594 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_selected = df_train_dummie[['Type of Travel','Class','Online boarding','satisfaction']]\n",
    "df_train_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age Cluster</th>\n",
       "      <th>Weight Comfort Seats</th>\n",
       "      <th>Mean Satisfaction Services</th>\n",
       "      <th>Sum Inflight Services</th>\n",
       "      <th>Space Seat and Class</th>\n",
       "      <th>Weight Basic Services</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>16</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103899</th>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103900</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.357143</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103901</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103902</th>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103903</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103594 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age Cluster  Weight Comfort Seats  Mean Satisfaction Services  \\\n",
       "0                 0                   4.0                    3.857143   \n",
       "1                 1                   0.2                    2.285714   \n",
       "2                 2                   1.0                    3.714286   \n",
       "3                 1                   0.4                    3.000000   \n",
       "4                 6                   1.0                    3.500000   \n",
       "...             ...                   ...                         ...   \n",
       "103899            1                   1.4                    2.214286   \n",
       "103900            5                   1.0                    4.357143   \n",
       "103901            2                   1.0                    3.071429   \n",
       "103902            1                   1.2                    2.285714   \n",
       "103903            2                   0.2                    2.000000   \n",
       "\n",
       "        Sum Inflight Services  Space Seat and Class  Weight Basic Services  \n",
       "0                          16                   1.2                    3.0  \n",
       "1                          11                   0.0                    0.2  \n",
       "2                          16                   0.0                    1.0  \n",
       "3                          10                   0.0                    0.4  \n",
       "4                          14                   0.0                    0.7  \n",
       "...                       ...                   ...                    ...  \n",
       "103899                      9                   0.2                    1.4  \n",
       "103900                     18                   0.0                    0.6  \n",
       "103901                     11                   0.0                    0.8  \n",
       "103902                      7                   1.0                    1.2  \n",
       "103903                      6                   0.0                    0.2  \n",
       "\n",
       "[103594 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age cluster\n",
    "df_train_new_features = pd.DataFrame()\n",
    "age_bins = [7,18,26,33,40,47,54,63,86]\n",
    "df_train_new_features['Age Cluster'] = pd.cut(df_train_dummie['Age'], bins=age_bins, labels=False, right=False)\n",
    "\n",
    "# Weight Comfort Seats\n",
    "df_train_new_features['Weight Comfort Seats'] = (df_train_dummie['Seat comfort']/5 + df_train_dummie['Class'] + df_train_dummie['Type of Travel'])\n",
    "\n",
    "# Media de todos los servicios que tienen valor del 0-5\n",
    "df_train_new_features['Mean Satisfaction Services'] = df_train_dummie[['Inflight wifi service','Departure/Arrival time convenient','Ease of Online booking','Gate location','Food and drink',\n",
    "                                  'Online boarding','Seat comfort','Inflight entertainment','On-board service','Leg room service','Baggage handling','Checkin service','Inflight service','Cleanliness']].mean(axis=1)\n",
    "\n",
    "# Suma del Servicio en Vuelo\n",
    "df_train_new_features['Sum Inflight Services'] = df_train_dummie['Inflight wifi service'] + df_train_dummie['Inflight service'] + df_train_dummie['Inflight entertainment'] + df_train_dummie['Online boarding']\n",
    "\n",
    "# Peso sobre el espacio de los pies según la clase\n",
    "df_train_new_features['Space Seat and Class'] = (df_train_dummie['Class'] * df_train_dummie['Leg room service']) / 5\n",
    "\n",
    "# suma de servicios básicos\n",
    "df_train_new_features['Weight Basic Services'] = df_train_dummie['Class'] + (df_train_dummie['Food and drink'] + df_train_dummie['Cleanliness'])/10\n",
    "\n",
    "df_train_new_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>Age Cluster</th>\n",
       "      <th>Weight Comfort Seats</th>\n",
       "      <th>Mean Satisfaction Services</th>\n",
       "      <th>Sum Inflight Services</th>\n",
       "      <th>Space Seat and Class</th>\n",
       "      <th>Weight Basic Services</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>16</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103899</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103900</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.357143</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103901</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103902</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103594 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type of Travel  Class  Online boarding  satisfaction  Age Cluster  \\\n",
       "0                    1      2                3             0            0   \n",
       "1                    0      0                3             0            1   \n",
       "2                    0      0                5             1            2   \n",
       "3                    0      0                2             0            1   \n",
       "4                    0      0                5             1            6   \n",
       "...                ...    ...              ...           ...          ...   \n",
       "103899               0      1                2             0            1   \n",
       "103900               0      0                4             1            5   \n",
       "103901               0      0                1             0            2   \n",
       "103902               0      1                1             0            1   \n",
       "103903               0      0                1             0            2   \n",
       "\n",
       "        Weight Comfort Seats  Mean Satisfaction Services  \\\n",
       "0                        4.0                    3.857143   \n",
       "1                        0.2                    2.285714   \n",
       "2                        1.0                    3.714286   \n",
       "3                        0.4                    3.000000   \n",
       "4                        1.0                    3.500000   \n",
       "...                      ...                         ...   \n",
       "103899                   1.4                    2.214286   \n",
       "103900                   1.0                    4.357143   \n",
       "103901                   1.0                    3.071429   \n",
       "103902                   1.2                    2.285714   \n",
       "103903                   0.2                    2.000000   \n",
       "\n",
       "        Sum Inflight Services  Space Seat and Class  Weight Basic Services  \n",
       "0                          16                   1.2                    3.0  \n",
       "1                          11                   0.0                    0.2  \n",
       "2                          16                   0.0                    1.0  \n",
       "3                          10                   0.0                    0.4  \n",
       "4                          14                   0.0                    0.7  \n",
       "...                       ...                   ...                    ...  \n",
       "103899                      9                   0.2                    1.4  \n",
       "103900                     18                   0.0                    0.6  \n",
       "103901                     11                   0.0                    0.8  \n",
       "103902                      7                   1.0                    1.2  \n",
       "103903                      6                   0.0                    0.2  \n",
       "\n",
       "[103594 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_combined = pd.concat([df_train_selected, df_train_new_features], axis=1)\n",
    "\n",
    "# Eliminar las columnas duplicadas si es necesario\n",
    "df_train_combined = df_train_combined.loc[:, ~df_train_combined.columns.duplicated()]\n",
    "df_train_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un callback personalizado para medir el tiempo de entrenamiento\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.times = []\n",
    "        self.train_start_time = time.time()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.times.append(time.time() - self.epoch_start_time)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.total_train_time = time.time() - self.train_start_time\n",
    "        \n",
    "time_callback = TimeHistory()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 1: Valores sin análisis previo\n",
    "- Inputs: Todo el data set (dummie)\n",
    "- Epochs = 100\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 relu\n",
    "- 3ra capa = 1 sigmoid\n",
    "- learning_rate=0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_dummie.drop('satisfaction', axis=1)\n",
    "y = df_train_dummie['satisfaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 3s 860us/step - loss: 0.1963 - accuracy: 0.9200 - val_loss: 0.1417 - val_accuracy: 0.9439\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 2s 786us/step - loss: 0.1328 - accuracy: 0.9450 - val_loss: 0.1273 - val_accuracy: 0.9520\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 2s 915us/step - loss: 0.1169 - accuracy: 0.9515 - val_loss: 0.1112 - val_accuracy: 0.9535\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 2s 921us/step - loss: 0.1077 - accuracy: 0.9540 - val_loss: 0.1040 - val_accuracy: 0.9585\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 2s 911us/step - loss: 0.1013 - accuracy: 0.9568 - val_loss: 0.1007 - val_accuracy: 0.9583\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 2s 832us/step - loss: 0.0971 - accuracy: 0.9581 - val_loss: 0.1007 - val_accuracy: 0.9590\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 2s 843us/step - loss: 0.0938 - accuracy: 0.9598 - val_loss: 0.1053 - val_accuracy: 0.9514\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 2s 859us/step - loss: 0.0913 - accuracy: 0.9605 - val_loss: 0.0952 - val_accuracy: 0.9580\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 2s 873us/step - loss: 0.0899 - accuracy: 0.9605 - val_loss: 0.0961 - val_accuracy: 0.9586\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 2s 858us/step - loss: 0.0886 - accuracy: 0.9616 - val_loss: 0.0961 - val_accuracy: 0.9621\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 2s 841us/step - loss: 0.0869 - accuracy: 0.9624 - val_loss: 0.0945 - val_accuracy: 0.9597\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 2s 912us/step - loss: 0.0861 - accuracy: 0.9625 - val_loss: 0.0909 - val_accuracy: 0.9619\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.0850 - accuracy: 0.9629 - val_loss: 0.0929 - val_accuracy: 0.9601\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 2s 942us/step - loss: 0.0835 - accuracy: 0.9632 - val_loss: 0.0934 - val_accuracy: 0.9596\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 2s 965us/step - loss: 0.0830 - accuracy: 0.9636 - val_loss: 0.0940 - val_accuracy: 0.9622\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 3s 989us/step - loss: 0.0823 - accuracy: 0.9639 - val_loss: 0.0924 - val_accuracy: 0.9617\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 2s 929us/step - loss: 0.0817 - accuracy: 0.9639 - val_loss: 0.0899 - val_accuracy: 0.9632\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 2s 920us/step - loss: 0.0812 - accuracy: 0.9643 - val_loss: 0.0947 - val_accuracy: 0.9615\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 2s 915us/step - loss: 0.0806 - accuracy: 0.9645 - val_loss: 0.0900 - val_accuracy: 0.9624\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 2s 859us/step - loss: 0.0800 - accuracy: 0.9653 - val_loss: 0.0911 - val_accuracy: 0.9624\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 2s 898us/step - loss: 0.0798 - accuracy: 0.9648 - val_loss: 0.0917 - val_accuracy: 0.9617\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 2s 861us/step - loss: 0.0790 - accuracy: 0.9655 - val_loss: 0.0909 - val_accuracy: 0.9620\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 51.59 segundos\n",
      "Pérdida: 0.07897747308015823\n",
      "Accuracy: 96.54660820960999\n"
     ]
    }
   ],
   "source": [
    "model.save('../Modelos/Modelo1.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 2\n",
    "- Inputs: Todo el data set (dummie)\n",
    "- Epochs = 100\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 relu\n",
    "- 3ra capa = 16 relu \n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate=0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 3s 928us/step - loss: 0.1886 - accuracy: 0.9244 - val_loss: 0.1374 - val_accuracy: 0.9449\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 2s 915us/step - loss: 0.1271 - accuracy: 0.9468 - val_loss: 0.1147 - val_accuracy: 0.9526\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.1116 - accuracy: 0.9529 - val_loss: 0.1132 - val_accuracy: 0.9541\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 2s 925us/step - loss: 0.1030 - accuracy: 0.9561 - val_loss: 0.1012 - val_accuracy: 0.9570\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 2s 862us/step - loss: 0.0982 - accuracy: 0.9578 - val_loss: 0.1031 - val_accuracy: 0.9564\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 2s 909us/step - loss: 0.0956 - accuracy: 0.9589 - val_loss: 0.0981 - val_accuracy: 0.9592\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 2s 906us/step - loss: 0.0927 - accuracy: 0.9601 - val_loss: 0.0944 - val_accuracy: 0.9594\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 3s 977us/step - loss: 0.0904 - accuracy: 0.9608 - val_loss: 0.0955 - val_accuracy: 0.9589\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.0885 - accuracy: 0.9612 - val_loss: 0.0938 - val_accuracy: 0.9606\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.0873 - accuracy: 0.9619 - val_loss: 0.0927 - val_accuracy: 0.9614\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 2s 910us/step - loss: 0.0857 - accuracy: 0.9627 - val_loss: 0.0924 - val_accuracy: 0.9608\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 2s 900us/step - loss: 0.0847 - accuracy: 0.9632 - val_loss: 0.0937 - val_accuracy: 0.9616\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 3s 979us/step - loss: 0.0827 - accuracy: 0.9641 - val_loss: 0.0905 - val_accuracy: 0.9626\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 2s 946us/step - loss: 0.0823 - accuracy: 0.9642 - val_loss: 0.0960 - val_accuracy: 0.9608\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 2s 951us/step - loss: 0.0809 - accuracy: 0.9645 - val_loss: 0.0901 - val_accuracy: 0.9626\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 2s 937us/step - loss: 0.0807 - accuracy: 0.9647 - val_loss: 0.0983 - val_accuracy: 0.9597\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.0794 - accuracy: 0.9646 - val_loss: 0.0906 - val_accuracy: 0.9627\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 3s 985us/step - loss: 0.0784 - accuracy: 0.9652 - val_loss: 0.0888 - val_accuracy: 0.9616\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 2s 916us/step - loss: 0.0781 - accuracy: 0.9656 - val_loss: 0.0884 - val_accuracy: 0.9632\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 2s 894us/step - loss: 0.0775 - accuracy: 0.9659 - val_loss: 0.0886 - val_accuracy: 0.9621\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 2s 885us/step - loss: 0.0770 - accuracy: 0.9663 - val_loss: 0.0915 - val_accuracy: 0.9624\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 2s 906us/step - loss: 0.0760 - accuracy: 0.9666 - val_loss: 0.0920 - val_accuracy: 0.9618\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 2s 917us/step - loss: 0.0751 - accuracy: 0.9666 - val_loss: 0.0932 - val_accuracy: 0.9623\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 2s 912us/step - loss: 0.0751 - accuracy: 0.9671 - val_loss: 0.0924 - val_accuracy: 0.9623\n",
      "Tiempo total de entrenamiento: 58.75 segundos\n",
      "Pérdida: 0.075148805975914\n",
      "Accuracy: 96.71071171760559\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie.drop('satisfaction', axis=1)\n",
    "y = df_train_dummie['satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save('../Modelos/Modelo2.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 3: Correlaciones cercanas > 0.3\n",
    "- Inputs: 'Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service',\"Cleanliness\"\n",
    "- Epochs = 100\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 relu\n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate=0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 2s 860us/step - loss: 0.2938 - accuracy: 0.8816 - val_loss: 0.2646 - val_accuracy: 0.8934\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 2s 887us/step - loss: 0.2589 - accuracy: 0.8957 - val_loss: 0.2597 - val_accuracy: 0.8963\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 2s 917us/step - loss: 0.2509 - accuracy: 0.8977 - val_loss: 0.2447 - val_accuracy: 0.8986\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 2s 818us/step - loss: 0.2449 - accuracy: 0.8999 - val_loss: 0.2406 - val_accuracy: 0.9031\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 2s 831us/step - loss: 0.2401 - accuracy: 0.9029 - val_loss: 0.2365 - val_accuracy: 0.9022\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 2s 849us/step - loss: 0.2369 - accuracy: 0.9022 - val_loss: 0.2397 - val_accuracy: 0.8996\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 2s 834us/step - loss: 0.2332 - accuracy: 0.9042 - val_loss: 0.2314 - val_accuracy: 0.9037\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 2s 864us/step - loss: 0.2308 - accuracy: 0.9055 - val_loss: 0.2313 - val_accuracy: 0.9017\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 2s 823us/step - loss: 0.2293 - accuracy: 0.9050 - val_loss: 0.2288 - val_accuracy: 0.9057\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 2s 810us/step - loss: 0.2274 - accuracy: 0.9059 - val_loss: 0.2260 - val_accuracy: 0.9062\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 2s 859us/step - loss: 0.2264 - accuracy: 0.9060 - val_loss: 0.2290 - val_accuracy: 0.9058\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 2s 822us/step - loss: 0.2259 - accuracy: 0.9062 - val_loss: 0.2271 - val_accuracy: 0.9066\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 2s 842us/step - loss: 0.2250 - accuracy: 0.9056 - val_loss: 0.2268 - val_accuracy: 0.9054\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 2s 879us/step - loss: 0.2238 - accuracy: 0.9082 - val_loss: 0.2234 - val_accuracy: 0.9067\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 2s 856us/step - loss: 0.2228 - accuracy: 0.9080 - val_loss: 0.2225 - val_accuracy: 0.9067\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 2s 825us/step - loss: 0.2221 - accuracy: 0.9071 - val_loss: 0.2226 - val_accuracy: 0.9062\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 2s 910us/step - loss: 0.2218 - accuracy: 0.9087 - val_loss: 0.2212 - val_accuracy: 0.9086\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 2s 919us/step - loss: 0.2217 - accuracy: 0.9078 - val_loss: 0.2222 - val_accuracy: 0.9055\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 2s 804us/step - loss: 0.2204 - accuracy: 0.9085 - val_loss: 0.2224 - val_accuracy: 0.9081\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 2s 795us/step - loss: 0.2203 - accuracy: 0.9089 - val_loss: 0.2243 - val_accuracy: 0.9071\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 2s 858us/step - loss: 0.2190 - accuracy: 0.9091 - val_loss: 0.2224 - val_accuracy: 0.9060\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 2s 873us/step - loss: 0.2193 - accuracy: 0.9085 - val_loss: 0.2254 - val_accuracy: 0.9040\n",
      "648/648 [==============================] - 0s 674us/step - loss: 0.2212 - accuracy: 0.9086\n",
      "Accuracy: 90.86%\n",
      "Tiempo total de entrenamiento: 48.85 segundos\n",
      "Pérdida: 0.2192971110343933\n",
      "Accuracy: 90.85248708724976\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo3.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 4: Correlaciones cercanas > 0.3 (+1 capa)\n",
    "- Inputs: 'Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service',\"Cleanliness\"\n",
    "- Epochs = 100\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 relu\n",
    "- 3ra capa = 16 relu\n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate=0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1157/2590 [============>.................] - ETA: 2s - loss: 0.3102 - accuracy: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15160\\3671380407.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n\u001b[0;32m     20\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Accuracy: {accuracy*100:.2f}%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ddcre\\anaconda3\\envs\\tensorenviron\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ddcre\\anaconda3\\envs\\tensorenviron\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1372\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1377\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[0;32m   1378\u001b[0m                 \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m                 \u001b[0mepoch_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ddcre\\anaconda3\\envs\\tensorenviron\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1242\u001b[0m     while (self._inferred_steps is None or\n\u001b[0;32m   1243\u001b[0m            self._current_step < self._inferred_steps):\n\u001b[0;32m   1244\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1246\u001b[1;33m       \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1247\u001b[0m       can_run_full_execution = (\n\u001b[0;32m   1248\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ddcre\\anaconda3\\envs\\tensorenviron\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    676\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32mc:\\Users\\ddcre\\anaconda3\\envs\\tensorenviron\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    748\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ddcre\\anaconda3\\envs\\tensorenviron\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ddcre\\anaconda3\\envs\\tensorenviron\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1083\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ddcre\\anaconda3\\envs\\tensorenviron\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    283\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"graph\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;31m# Make sure we get an input with handle data attached from resource\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ddcre\\anaconda3\\envs\\tensorenviron\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4064\u001b[0m         _ctx, \"Identity\", name, input)\n\u001b[0;32m   4065\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4066\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4067\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4068\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4069\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4070\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4071\u001b[0m       return identity_eager_fallback(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo4.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 5: Mayores niveles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.4468 - accuracy: 0.8810 - val_loss: 0.2991 - val_accuracy: 0.9167\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3252 - accuracy: 0.9028 - val_loss: 0.2694 - val_accuracy: 0.9214\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3031 - accuracy: 0.9080 - val_loss: 0.2549 - val_accuracy: 0.9268\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2893 - accuracy: 0.9113 - val_loss: 0.2418 - val_accuracy: 0.9324\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2803 - accuracy: 0.9141 - val_loss: 0.2338 - val_accuracy: 0.9342\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2749 - accuracy: 0.9153 - val_loss: 0.2318 - val_accuracy: 0.9290\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2709 - accuracy: 0.9159 - val_loss: 0.2256 - val_accuracy: 0.9310\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2660 - accuracy: 0.9165 - val_loss: 0.2230 - val_accuracy: 0.9349\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2615 - accuracy: 0.9172 - val_loss: 0.2218 - val_accuracy: 0.9319\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2616 - accuracy: 0.9172 - val_loss: 0.2167 - val_accuracy: 0.9330\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 6s 3ms/step - loss: 0.2600 - accuracy: 0.9174 - val_loss: 0.2192 - val_accuracy: 0.9333\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2575 - accuracy: 0.9176 - val_loss: 0.2196 - val_accuracy: 0.9341\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2575 - accuracy: 0.9172 - val_loss: 0.2154 - val_accuracy: 0.9346\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2546 - accuracy: 0.9189 - val_loss: 0.2151 - val_accuracy: 0.9319\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2525 - accuracy: 0.9188 - val_loss: 0.2177 - val_accuracy: 0.9325\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2527 - accuracy: 0.9191 - val_loss: 0.2145 - val_accuracy: 0.9344\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2523 - accuracy: 0.9194 - val_loss: 0.2140 - val_accuracy: 0.9341\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2508 - accuracy: 0.9201 - val_loss: 0.2109 - val_accuracy: 0.9363\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2517 - accuracy: 0.9200 - val_loss: 0.2149 - val_accuracy: 0.9347\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2504 - accuracy: 0.9194 - val_loss: 0.2113 - val_accuracy: 0.9305\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2490 - accuracy: 0.9195 - val_loss: 0.2090 - val_accuracy: 0.9324\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2498 - accuracy: 0.9199 - val_loss: 0.2221 - val_accuracy: 0.9272\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2474 - accuracy: 0.9210 - val_loss: 0.2091 - val_accuracy: 0.9353\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2471 - accuracy: 0.9195 - val_loss: 0.2075 - val_accuracy: 0.9359\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2493 - accuracy: 0.9194 - val_loss: 0.2070 - val_accuracy: 0.9339\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2475 - accuracy: 0.9193 - val_loss: 0.2071 - val_accuracy: 0.9324\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2464 - accuracy: 0.9189 - val_loss: 0.2105 - val_accuracy: 0.9348\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2461 - accuracy: 0.9195 - val_loss: 0.2083 - val_accuracy: 0.9343\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2463 - accuracy: 0.9201 - val_loss: 0.2088 - val_accuracy: 0.9350\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2462 - accuracy: 0.9207 - val_loss: 0.2054 - val_accuracy: 0.9360\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2458 - accuracy: 0.9203 - val_loss: 0.2073 - val_accuracy: 0.9342\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2435 - accuracy: 0.9208 - val_loss: 0.2064 - val_accuracy: 0.9346\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2447 - accuracy: 0.9209 - val_loss: 0.2131 - val_accuracy: 0.9313\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2458 - accuracy: 0.9215 - val_loss: 0.2019 - val_accuracy: 0.9379\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2447 - accuracy: 0.9200 - val_loss: 0.2113 - val_accuracy: 0.9342\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2433 - accuracy: 0.9211 - val_loss: 0.2066 - val_accuracy: 0.9357\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2427 - accuracy: 0.9216 - val_loss: 0.2065 - val_accuracy: 0.9371\n",
      "Epoch 38/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2462 - accuracy: 0.9205 - val_loss: 0.2049 - val_accuracy: 0.9351\n",
      "Epoch 39/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2438 - accuracy: 0.9200 - val_loss: 0.2080 - val_accuracy: 0.9313\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.2019 - accuracy: 0.9379\n",
      "Accuracy: 93.79%\n",
      "Tiempo total de entrenamiento: 235.77 segundos\n",
      "Pérdida: 0.24376218020915985\n",
      "Accuracy: 92.00241565704346\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Online boarding','Inflight wifi service','Class','Type of Travel','Inflight entertainment','Seat comfort','Leg room service','Customer Type','Ease of Online booking']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "    Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "    Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo5.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 6: Mayor correlación individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.5796 - accuracy: 0.8434 - val_loss: 0.3475 - val_accuracy: 0.9034\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 6s 3ms/step - loss: 0.3963 - accuracy: 0.8817 - val_loss: 0.3128 - val_accuracy: 0.9106\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3729 - accuracy: 0.8893 - val_loss: 0.2986 - val_accuracy: 0.9198\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3656 - accuracy: 0.8914 - val_loss: 0.2865 - val_accuracy: 0.9199\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3552 - accuracy: 0.8938 - val_loss: 0.2780 - val_accuracy: 0.9205\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3507 - accuracy: 0.8938 - val_loss: 0.2775 - val_accuracy: 0.9185\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3481 - accuracy: 0.8950 - val_loss: 0.2765 - val_accuracy: 0.9170\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.3445 - accuracy: 0.8962 - val_loss: 0.2714 - val_accuracy: 0.9208\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.3441 - accuracy: 0.8961 - val_loss: 0.2772 - val_accuracy: 0.9193\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3408 - accuracy: 0.8969 - val_loss: 0.2674 - val_accuracy: 0.9228\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3383 - accuracy: 0.8969 - val_loss: 0.2666 - val_accuracy: 0.9208\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3381 - accuracy: 0.8962 - val_loss: 0.2654 - val_accuracy: 0.9211\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3384 - accuracy: 0.8962 - val_loss: 0.2663 - val_accuracy: 0.9207\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3361 - accuracy: 0.8963 - val_loss: 0.2625 - val_accuracy: 0.9217\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3343 - accuracy: 0.8963 - val_loss: 0.2654 - val_accuracy: 0.9172\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3326 - accuracy: 0.8964 - val_loss: 0.2598 - val_accuracy: 0.9221\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3330 - accuracy: 0.8971 - val_loss: 0.2694 - val_accuracy: 0.9182\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3298 - accuracy: 0.8980 - val_loss: 0.2574 - val_accuracy: 0.9213\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3289 - accuracy: 0.8987 - val_loss: 0.2564 - val_accuracy: 0.9230\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3271 - accuracy: 0.8984 - val_loss: 0.2593 - val_accuracy: 0.9192\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3259 - accuracy: 0.8992 - val_loss: 0.2550 - val_accuracy: 0.9246\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3265 - accuracy: 0.8993 - val_loss: 0.2558 - val_accuracy: 0.9225\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3264 - accuracy: 0.9001 - val_loss: 0.2528 - val_accuracy: 0.9219\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3247 - accuracy: 0.8987 - val_loss: 0.2526 - val_accuracy: 0.9214\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 14s 5ms/step - loss: 0.3230 - accuracy: 0.8998 - val_loss: 0.2570 - val_accuracy: 0.9207\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 32s 12ms/step - loss: 0.3238 - accuracy: 0.8990 - val_loss: 0.2529 - val_accuracy: 0.9203\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3237 - accuracy: 0.8990 - val_loss: 0.2559 - val_accuracy: 0.9221\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3223 - accuracy: 0.9005 - val_loss: 0.2581 - val_accuracy: 0.9228\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3224 - accuracy: 0.8992 - val_loss: 0.2516 - val_accuracy: 0.9189\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3221 - accuracy: 0.8985 - val_loss: 0.2547 - val_accuracy: 0.9129\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3215 - accuracy: 0.8982 - val_loss: 0.2567 - val_accuracy: 0.9215\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3227 - accuracy: 0.8981 - val_loss: 0.2508 - val_accuracy: 0.9202\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 6s 3ms/step - loss: 0.3218 - accuracy: 0.8991 - val_loss: 0.2488 - val_accuracy: 0.9228\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3206 - accuracy: 0.8990 - val_loss: 0.2487 - val_accuracy: 0.9212\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3216 - accuracy: 0.8983 - val_loss: 0.2516 - val_accuracy: 0.9181\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3193 - accuracy: 0.9011 - val_loss: 0.2502 - val_accuracy: 0.9179\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3199 - accuracy: 0.8991 - val_loss: 0.2480 - val_accuracy: 0.9226\n",
      "Epoch 38/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3192 - accuracy: 0.8995 - val_loss: 0.2524 - val_accuracy: 0.9221\n",
      "Epoch 39/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3191 - accuracy: 0.9002 - val_loss: 0.2493 - val_accuracy: 0.9207\n",
      "Epoch 40/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3189 - accuracy: 0.8995 - val_loss: 0.2462 - val_accuracy: 0.9254\n",
      "Epoch 41/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3209 - accuracy: 0.8999 - val_loss: 0.2515 - val_accuracy: 0.9158\n",
      "Epoch 42/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3188 - accuracy: 0.9050 - val_loss: 0.2534 - val_accuracy: 0.9202\n",
      "Epoch 43/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3160 - accuracy: 0.9043 - val_loss: 0.2513 - val_accuracy: 0.9212\n",
      "Epoch 44/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3193 - accuracy: 0.9001 - val_loss: 0.2521 - val_accuracy: 0.9180\n",
      "Epoch 45/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3184 - accuracy: 0.8999 - val_loss: 0.2524 - val_accuracy: 0.9167\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.2462 - accuracy: 0.9254\n",
      "Accuracy: 92.54%\n",
      "Tiempo total de entrenamiento: 327.82 segundos\n",
      "Pérdida: 0.31838178634643555\n",
      "Accuracy: 89.98733162879944\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Type of Travel', 'Class','Flight Distance', 'Inflight wifi service', 'Online boarding','Seat comfort','Inflight entertainment','On-board service', 'Leg room service', 'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "    Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "    Dropout(0.5),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "    Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo6.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 7: Nuevos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 3s 929us/step - loss: 0.3657 - accuracy: 0.8487 - val_loss: 0.3417 - val_accuracy: 0.8570\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 2s 905us/step - loss: 0.3330 - accuracy: 0.8617 - val_loss: 0.3223 - val_accuracy: 0.8664\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 2s 888us/step - loss: 0.3211 - accuracy: 0.8664 - val_loss: 0.3235 - val_accuracy: 0.8669\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 2s 946us/step - loss: 0.3144 - accuracy: 0.8701 - val_loss: 0.3123 - val_accuracy: 0.8726\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 2s 891us/step - loss: 0.3102 - accuracy: 0.8721 - val_loss: 0.3071 - val_accuracy: 0.8724\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 2s 834us/step - loss: 0.3070 - accuracy: 0.8730 - val_loss: 0.3030 - val_accuracy: 0.8741\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 2s 897us/step - loss: 0.3051 - accuracy: 0.8746 - val_loss: 0.3037 - val_accuracy: 0.8728\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.3031 - accuracy: 0.8757 - val_loss: 0.3033 - val_accuracy: 0.8750\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 2s 930us/step - loss: 0.3018 - accuracy: 0.8759 - val_loss: 0.3068 - val_accuracy: 0.8748\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 2s 926us/step - loss: 0.3011 - accuracy: 0.8760 - val_loss: 0.2996 - val_accuracy: 0.8752\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 2s 912us/step - loss: 0.2993 - accuracy: 0.8779 - val_loss: 0.2978 - val_accuracy: 0.8771\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 3s 993us/step - loss: 0.2982 - accuracy: 0.8775 - val_loss: 0.3003 - val_accuracy: 0.8754\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 2s 894us/step - loss: 0.2979 - accuracy: 0.8778 - val_loss: 0.2986 - val_accuracy: 0.8771\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 2s 888us/step - loss: 0.2969 - accuracy: 0.8774 - val_loss: 0.2981 - val_accuracy: 0.8771\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 2s 930us/step - loss: 0.2965 - accuracy: 0.8779 - val_loss: 0.2980 - val_accuracy: 0.8782\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 2s 906us/step - loss: 0.2953 - accuracy: 0.8787 - val_loss: 0.2960 - val_accuracy: 0.8765\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 3s 997us/step - loss: 0.2953 - accuracy: 0.8789 - val_loss: 0.2950 - val_accuracy: 0.8766\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 2s 898us/step - loss: 0.2944 - accuracy: 0.8779 - val_loss: 0.2932 - val_accuracy: 0.8781\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2940 - accuracy: 0.8786 - val_loss: 0.2955 - val_accuracy: 0.8763\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.2938 - accuracy: 0.8785 - val_loss: 0.2926 - val_accuracy: 0.8779\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 2s 877us/step - loss: 0.2929 - accuracy: 0.8795 - val_loss: 0.2941 - val_accuracy: 0.8769\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 2s 914us/step - loss: 0.2923 - accuracy: 0.8788 - val_loss: 0.2957 - val_accuracy: 0.8754\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 2s 938us/step - loss: 0.2917 - accuracy: 0.8790 - val_loss: 0.2936 - val_accuracy: 0.8777\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 2s 848us/step - loss: 0.2917 - accuracy: 0.8798 - val_loss: 0.2948 - val_accuracy: 0.8778\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 2s 888us/step - loss: 0.2910 - accuracy: 0.8797 - val_loss: 0.2922 - val_accuracy: 0.8782\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 2s 911us/step - loss: 0.2901 - accuracy: 0.8805 - val_loss: 0.2932 - val_accuracy: 0.8764\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 2s 917us/step - loss: 0.2898 - accuracy: 0.8800 - val_loss: 0.2948 - val_accuracy: 0.8771\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 2s 880us/step - loss: 0.2899 - accuracy: 0.8800 - val_loss: 0.2933 - val_accuracy: 0.8776\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 2s 885us/step - loss: 0.2892 - accuracy: 0.8803 - val_loss: 0.2955 - val_accuracy: 0.8758\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 3s 975us/step - loss: 0.2888 - accuracy: 0.8808 - val_loss: 0.2904 - val_accuracy: 0.8785\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 2s 875us/step - loss: 0.2883 - accuracy: 0.8798 - val_loss: 0.2928 - val_accuracy: 0.8770\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 2s 902us/step - loss: 0.2885 - accuracy: 0.8803 - val_loss: 0.2945 - val_accuracy: 0.8774\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 2s 888us/step - loss: 0.2876 - accuracy: 0.8815 - val_loss: 0.2896 - val_accuracy: 0.8790\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 2s 843us/step - loss: 0.2874 - accuracy: 0.8816 - val_loss: 0.2993 - val_accuracy: 0.8742\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 2s 869us/step - loss: 0.2874 - accuracy: 0.8809 - val_loss: 0.2941 - val_accuracy: 0.8755\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 2s 874us/step - loss: 0.2872 - accuracy: 0.8814 - val_loss: 0.2924 - val_accuracy: 0.8779\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 2s 841us/step - loss: 0.2866 - accuracy: 0.8803 - val_loss: 0.2910 - val_accuracy: 0.8775\n",
      "Epoch 38/100\n",
      "2590/2590 [==============================] - 2s 894us/step - loss: 0.2865 - accuracy: 0.8815 - val_loss: 0.2884 - val_accuracy: 0.8777\n",
      "Epoch 39/100\n",
      "2590/2590 [==============================] - 2s 866us/step - loss: 0.2859 - accuracy: 0.8825 - val_loss: 0.2945 - val_accuracy: 0.8778\n",
      "Epoch 40/100\n",
      "2590/2590 [==============================] - 2s 839us/step - loss: 0.2856 - accuracy: 0.8819 - val_loss: 0.2886 - val_accuracy: 0.8807\n",
      "Epoch 41/100\n",
      "2590/2590 [==============================] - 2s 871us/step - loss: 0.2857 - accuracy: 0.8818 - val_loss: 0.2889 - val_accuracy: 0.8793\n",
      "Epoch 42/100\n",
      "2590/2590 [==============================] - 2s 882us/step - loss: 0.2854 - accuracy: 0.8817 - val_loss: 0.2882 - val_accuracy: 0.8807\n",
      "Epoch 43/100\n",
      "2590/2590 [==============================] - 2s 847us/step - loss: 0.2851 - accuracy: 0.8820 - val_loss: 0.2895 - val_accuracy: 0.8797\n",
      "Epoch 44/100\n",
      "2590/2590 [==============================] - 2s 906us/step - loss: 0.2852 - accuracy: 0.8824 - val_loss: 0.2875 - val_accuracy: 0.8805\n",
      "Epoch 45/100\n",
      "2590/2590 [==============================] - 2s 938us/step - loss: 0.2844 - accuracy: 0.8818 - val_loss: 0.2880 - val_accuracy: 0.8804\n",
      "Epoch 46/100\n",
      "2590/2590 [==============================] - 2s 903us/step - loss: 0.2844 - accuracy: 0.8819 - val_loss: 0.2882 - val_accuracy: 0.8795\n",
      "Epoch 47/100\n",
      "2590/2590 [==============================] - 2s 902us/step - loss: 0.2842 - accuracy: 0.8824 - val_loss: 0.2872 - val_accuracy: 0.8793\n",
      "Epoch 48/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2842 - accuracy: 0.8822 - val_loss: 0.2903 - val_accuracy: 0.8798\n",
      "Epoch 49/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2839 - accuracy: 0.8823 - val_loss: 0.2872 - val_accuracy: 0.8808\n",
      "Epoch 50/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2835 - accuracy: 0.8833 - val_loss: 0.2856 - val_accuracy: 0.8818\n",
      "Epoch 51/100\n",
      "2590/2590 [==============================] - 2s 873us/step - loss: 0.2831 - accuracy: 0.8830 - val_loss: 0.2893 - val_accuracy: 0.8792\n",
      "Epoch 52/100\n",
      "2590/2590 [==============================] - 2s 903us/step - loss: 0.2831 - accuracy: 0.8828 - val_loss: 0.2864 - val_accuracy: 0.8801\n",
      "Epoch 53/100\n",
      "2590/2590 [==============================] - 3s 984us/step - loss: 0.2828 - accuracy: 0.8831 - val_loss: 0.2894 - val_accuracy: 0.8823\n",
      "Epoch 54/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2828 - accuracy: 0.8829 - val_loss: 0.2854 - val_accuracy: 0.8815\n",
      "Epoch 55/100\n",
      "2590/2590 [==============================] - 2s 942us/step - loss: 0.2826 - accuracy: 0.8832 - val_loss: 0.2861 - val_accuracy: 0.8814\n",
      "Epoch 56/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2817 - accuracy: 0.8836 - val_loss: 0.2870 - val_accuracy: 0.8797\n",
      "Epoch 57/100\n",
      "2590/2590 [==============================] - 3s 983us/step - loss: 0.2820 - accuracy: 0.8838 - val_loss: 0.2850 - val_accuracy: 0.8805\n",
      "Epoch 58/100\n",
      "2590/2590 [==============================] - 3s 976us/step - loss: 0.2820 - accuracy: 0.8833 - val_loss: 0.2895 - val_accuracy: 0.8805\n",
      "Epoch 59/100\n",
      "2590/2590 [==============================] - 3s 974us/step - loss: 0.2815 - accuracy: 0.8836 - val_loss: 0.2880 - val_accuracy: 0.8789\n",
      "Epoch 60/100\n",
      "2590/2590 [==============================] - 2s 954us/step - loss: 0.2816 - accuracy: 0.8839 - val_loss: 0.2871 - val_accuracy: 0.8825\n",
      "Epoch 61/100\n",
      "2590/2590 [==============================] - 2s 933us/step - loss: 0.2811 - accuracy: 0.8842 - val_loss: 0.2876 - val_accuracy: 0.8800\n",
      "Epoch 62/100\n",
      "2590/2590 [==============================] - 3s 991us/step - loss: 0.2812 - accuracy: 0.8840 - val_loss: 0.2854 - val_accuracy: 0.8817\n",
      "648/648 [==============================] - 1s 837us/step - loss: 0.2850 - accuracy: 0.8805\n",
      "Accuracy: 88.05%\n",
      "Tiempo total de entrenamiento: 152.04 segundos\n",
      "Pérdida: 0.281152606010437\n",
      "Accuracy: 88.40060234069824\n"
     ]
    }
   ],
   "source": [
    "X = df_train_combined[['Age Cluster', 'Weight Comfort Seats', 'Mean Satisfaction Services',\n",
    "       'Sum Inflight Services', 'Space Seat and Class',\n",
    "       'Weight Basic Services']]\n",
    "y = df_train_combined['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('Modelo7.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 8: Nuevos features (+1 capa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 3s 927us/step - loss: 0.3635 - accuracy: 0.8479 - val_loss: 0.3420 - val_accuracy: 0.8553\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 2s 959us/step - loss: 0.3295 - accuracy: 0.8612 - val_loss: 0.3243 - val_accuracy: 0.8644\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 2s 846us/step - loss: 0.3188 - accuracy: 0.8660 - val_loss: 0.3149 - val_accuracy: 0.8693\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 2s 910us/step - loss: 0.3117 - accuracy: 0.8703 - val_loss: 0.3060 - val_accuracy: 0.8741\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 2s 921us/step - loss: 0.3072 - accuracy: 0.8724 - val_loss: 0.3023 - val_accuracy: 0.8732\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 2s 897us/step - loss: 0.3041 - accuracy: 0.8737 - val_loss: 0.3098 - val_accuracy: 0.8707\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 2s 917us/step - loss: 0.3012 - accuracy: 0.8756 - val_loss: 0.3026 - val_accuracy: 0.8759\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 2s 830us/step - loss: 0.2999 - accuracy: 0.8758 - val_loss: 0.3028 - val_accuracy: 0.8725\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 2s 875us/step - loss: 0.2979 - accuracy: 0.8766 - val_loss: 0.3045 - val_accuracy: 0.8727\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 2s 922us/step - loss: 0.2968 - accuracy: 0.8770 - val_loss: 0.2964 - val_accuracy: 0.8765\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 3s 986us/step - loss: 0.2952 - accuracy: 0.8789 - val_loss: 0.2977 - val_accuracy: 0.8779\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2948 - accuracy: 0.8782 - val_loss: 0.2941 - val_accuracy: 0.8795\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2933 - accuracy: 0.8785 - val_loss: 0.2961 - val_accuracy: 0.8767\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2925 - accuracy: 0.8788 - val_loss: 0.2911 - val_accuracy: 0.8779\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2921 - accuracy: 0.8789 - val_loss: 0.2919 - val_accuracy: 0.8775\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2913 - accuracy: 0.8793 - val_loss: 0.2911 - val_accuracy: 0.8785\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2903 - accuracy: 0.8794 - val_loss: 0.2918 - val_accuracy: 0.8801\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2903 - accuracy: 0.8797 - val_loss: 0.2946 - val_accuracy: 0.8769\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.2892 - accuracy: 0.8802 - val_loss: 0.2902 - val_accuracy: 0.8784\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2891 - accuracy: 0.8794 - val_loss: 0.2929 - val_accuracy: 0.8786\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2888 - accuracy: 0.8797 - val_loss: 0.2887 - val_accuracy: 0.8799\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2879 - accuracy: 0.8805 - val_loss: 0.2997 - val_accuracy: 0.8758\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2874 - accuracy: 0.8814 - val_loss: 0.2907 - val_accuracy: 0.8789\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2863 - accuracy: 0.8812 - val_loss: 0.2888 - val_accuracy: 0.8788\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2861 - accuracy: 0.8814 - val_loss: 0.2909 - val_accuracy: 0.8798\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2859 - accuracy: 0.8816 - val_loss: 0.2873 - val_accuracy: 0.8804\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2850 - accuracy: 0.8819 - val_loss: 0.2860 - val_accuracy: 0.8815\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2847 - accuracy: 0.8820 - val_loss: 0.2897 - val_accuracy: 0.8803\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2842 - accuracy: 0.8822 - val_loss: 0.2863 - val_accuracy: 0.8802\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2842 - accuracy: 0.8818 - val_loss: 0.2857 - val_accuracy: 0.8812\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2833 - accuracy: 0.8827 - val_loss: 0.2906 - val_accuracy: 0.8798\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2834 - accuracy: 0.8826 - val_loss: 0.2870 - val_accuracy: 0.8802\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2824 - accuracy: 0.8828 - val_loss: 0.2867 - val_accuracy: 0.8810\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2821 - accuracy: 0.8824 - val_loss: 0.2881 - val_accuracy: 0.8808\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2825 - accuracy: 0.8829 - val_loss: 0.2884 - val_accuracy: 0.8812\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.2857 - accuracy: 0.8812\n",
      "Accuracy: 88.12%\n",
      "Tiempo total de entrenamiento: 133.50 segundos\n",
      "Pérdida: 0.28246909379959106\n",
      "Accuracy: 88.29200863838196\n"
     ]
    }
   ],
   "source": [
    "X = df_train_combined[['Age Cluster', 'Weight Comfort Seats', 'Mean Satisfaction Services',\n",
    "       'Sum Inflight Services', 'Space Seat and Class',\n",
    "       'Weight Basic Services']]\n",
    "y = df_train_combined['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo8.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Customer Type', 'Age', 'Type of Travel', 'Class',\n",
       "       'Flight Distance', 'Inflight wifi service',\n",
       "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
       "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
       "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
       "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
       "       'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes',\n",
       "       'satisfaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dummie.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/2590 [..............................] - ETA: 24:53 - loss: 0.6950 - accuracy: 0.4688WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2449 - accuracy: 0.8973 - val_loss: 0.1939 - val_accuracy: 0.9196\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1804 - accuracy: 0.9260 - val_loss: 0.1632 - val_accuracy: 0.9346\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1565 - accuracy: 0.9355 - val_loss: 0.1502 - val_accuracy: 0.9392\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1434 - accuracy: 0.9400 - val_loss: 0.1430 - val_accuracy: 0.9421\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1367 - accuracy: 0.9429 - val_loss: 0.1379 - val_accuracy: 0.9441\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1327 - accuracy: 0.9438 - val_loss: 0.1352 - val_accuracy: 0.9426\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1292 - accuracy: 0.9456 - val_loss: 0.1318 - val_accuracy: 0.9456\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1263 - accuracy: 0.9465 - val_loss: 0.1326 - val_accuracy: 0.9452\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1246 - accuracy: 0.9479 - val_loss: 0.1285 - val_accuracy: 0.9463\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1222 - accuracy: 0.9491 - val_loss: 0.1279 - val_accuracy: 0.9442\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1213 - accuracy: 0.9488 - val_loss: 0.1264 - val_accuracy: 0.9468\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1191 - accuracy: 0.9504 - val_loss: 0.1274 - val_accuracy: 0.9469\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1177 - accuracy: 0.9498 - val_loss: 0.1251 - val_accuracy: 0.9472\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1159 - accuracy: 0.9510 - val_loss: 0.1224 - val_accuracy: 0.9478\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1150 - accuracy: 0.9507 - val_loss: 0.1276 - val_accuracy: 0.9466\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1141 - accuracy: 0.9519 - val_loss: 0.1219 - val_accuracy: 0.9496\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1129 - accuracy: 0.9520 - val_loss: 0.1231 - val_accuracy: 0.9463\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1126 - accuracy: 0.9523 - val_loss: 0.1229 - val_accuracy: 0.9474\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1109 - accuracy: 0.9530 - val_loss: 0.1210 - val_accuracy: 0.9493\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1102 - accuracy: 0.9532 - val_loss: 0.1240 - val_accuracy: 0.9465\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1090 - accuracy: 0.9536 - val_loss: 0.1222 - val_accuracy: 0.9487\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1081 - accuracy: 0.9540 - val_loss: 0.1216 - val_accuracy: 0.9489\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1078 - accuracy: 0.9539 - val_loss: 0.1174 - val_accuracy: 0.9509\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1074 - accuracy: 0.9540 - val_loss: 0.1204 - val_accuracy: 0.9484\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1057 - accuracy: 0.9553 - val_loss: 0.1200 - val_accuracy: 0.9478\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1053 - accuracy: 0.9550 - val_loss: 0.1176 - val_accuracy: 0.9503\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1047 - accuracy: 0.9555 - val_loss: 0.1179 - val_accuracy: 0.9509\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1041 - accuracy: 0.9554 - val_loss: 0.1194 - val_accuracy: 0.9492\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.9509\n",
      "Accuracy: 95.09%\n",
      "Tiempo total de entrenamiento: 149.59 segundos\n",
      "Pérdida: 0.10411404073238373\n",
      "Accuracy: 95.54389119148254\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Class','Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo9.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2652 - accuracy: 0.8879 - val_loss: 0.1960 - val_accuracy: 0.9184\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1820 - accuracy: 0.9258 - val_loss: 0.1674 - val_accuracy: 0.9316\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1584 - accuracy: 0.9348 - val_loss: 0.1504 - val_accuracy: 0.9363\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1483 - accuracy: 0.9379 - val_loss: 0.1436 - val_accuracy: 0.9402\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1428 - accuracy: 0.9403 - val_loss: 0.1408 - val_accuracy: 0.9398\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1398 - accuracy: 0.9413 - val_loss: 0.1390 - val_accuracy: 0.9412\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1377 - accuracy: 0.9419 - val_loss: 0.1402 - val_accuracy: 0.9390\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1350 - accuracy: 0.9431 - val_loss: 0.1372 - val_accuracy: 0.9428\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1335 - accuracy: 0.9437 - val_loss: 0.1349 - val_accuracy: 0.9431\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1319 - accuracy: 0.9441 - val_loss: 0.1341 - val_accuracy: 0.9433\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1301 - accuracy: 0.9452 - val_loss: 0.1344 - val_accuracy: 0.9427\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1289 - accuracy: 0.9452 - val_loss: 0.1304 - val_accuracy: 0.9448\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1280 - accuracy: 0.9459 - val_loss: 0.1314 - val_accuracy: 0.9439\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1265 - accuracy: 0.9464 - val_loss: 0.1321 - val_accuracy: 0.9431\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1258 - accuracy: 0.9467 - val_loss: 0.1310 - val_accuracy: 0.9437\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1251 - accuracy: 0.9467 - val_loss: 0.1307 - val_accuracy: 0.9447\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1236 - accuracy: 0.9466 - val_loss: 0.1264 - val_accuracy: 0.9464\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1230 - accuracy: 0.9477 - val_loss: 0.1258 - val_accuracy: 0.9464\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1225 - accuracy: 0.9478 - val_loss: 0.1267 - val_accuracy: 0.9461\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1220 - accuracy: 0.9476 - val_loss: 0.1274 - val_accuracy: 0.9460\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1213 - accuracy: 0.9488 - val_loss: 0.1268 - val_accuracy: 0.9464\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1203 - accuracy: 0.9490 - val_loss: 0.1254 - val_accuracy: 0.9470\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1199 - accuracy: 0.9490 - val_loss: 0.1258 - val_accuracy: 0.9459\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1191 - accuracy: 0.9495 - val_loss: 0.1255 - val_accuracy: 0.9461\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1183 - accuracy: 0.9500 - val_loss: 0.1260 - val_accuracy: 0.9462\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1176 - accuracy: 0.9497 - val_loss: 0.1243 - val_accuracy: 0.9459\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1170 - accuracy: 0.9501 - val_loss: 0.1254 - val_accuracy: 0.9472\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 12s 5ms/step - loss: 0.1166 - accuracy: 0.9500 - val_loss: 0.1240 - val_accuracy: 0.9478\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1159 - accuracy: 0.9505 - val_loss: 0.1232 - val_accuracy: 0.9464\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1154 - accuracy: 0.9505 - val_loss: 0.1225 - val_accuracy: 0.9472\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1154 - accuracy: 0.9506 - val_loss: 0.1235 - val_accuracy: 0.9485\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1145 - accuracy: 0.9509 - val_loss: 0.1221 - val_accuracy: 0.9473\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1137 - accuracy: 0.9516 - val_loss: 0.1250 - val_accuracy: 0.9459\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1139 - accuracy: 0.9517 - val_loss: 0.1238 - val_accuracy: 0.9470\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1134 - accuracy: 0.9515 - val_loss: 0.1221 - val_accuracy: 0.9480\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1127 - accuracy: 0.9516 - val_loss: 0.1237 - val_accuracy: 0.9477\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1125 - accuracy: 0.9520 - val_loss: 0.1249 - val_accuracy: 0.9482\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.1221 - accuracy: 0.9473\n",
      "Accuracy: 94.73%\n",
      "Tiempo total de entrenamiento: 196.39 segundos\n",
      "Pérdida: 0.11252495646476746\n",
      "Accuracy: 95.20120620727539\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Class','Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo10.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2311 - accuracy: 0.9050 - val_loss: 0.1773 - val_accuracy: 0.9270\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1653 - accuracy: 0.9319 - val_loss: 0.1510 - val_accuracy: 0.9391\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1466 - accuracy: 0.9391 - val_loss: 0.1383 - val_accuracy: 0.9428\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1375 - accuracy: 0.9433 - val_loss: 0.1329 - val_accuracy: 0.9460\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1310 - accuracy: 0.9452 - val_loss: 0.1274 - val_accuracy: 0.9471\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1258 - accuracy: 0.9476 - val_loss: 0.1266 - val_accuracy: 0.9468\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1224 - accuracy: 0.9485 - val_loss: 0.1271 - val_accuracy: 0.9447\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1193 - accuracy: 0.9495 - val_loss: 0.1316 - val_accuracy: 0.9403\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1167 - accuracy: 0.9506 - val_loss: 0.1241 - val_accuracy: 0.9460\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1147 - accuracy: 0.9510 - val_loss: 0.1185 - val_accuracy: 0.9492\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1130 - accuracy: 0.9520 - val_loss: 0.1184 - val_accuracy: 0.9491\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1109 - accuracy: 0.9530 - val_loss: 0.1180 - val_accuracy: 0.9488\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1094 - accuracy: 0.9531 - val_loss: 0.1198 - val_accuracy: 0.9491\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1080 - accuracy: 0.9538 - val_loss: 0.1176 - val_accuracy: 0.9478\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1064 - accuracy: 0.9553 - val_loss: 0.1184 - val_accuracy: 0.9491\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1049 - accuracy: 0.9552 - val_loss: 0.1153 - val_accuracy: 0.9511\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1046 - accuracy: 0.9548 - val_loss: 0.1137 - val_accuracy: 0.9515\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1029 - accuracy: 0.9556 - val_loss: 0.1147 - val_accuracy: 0.9509\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1019 - accuracy: 0.9564 - val_loss: 0.1179 - val_accuracy: 0.9511\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1005 - accuracy: 0.9574 - val_loss: 0.1135 - val_accuracy: 0.9501\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0997 - accuracy: 0.9571 - val_loss: 0.1148 - val_accuracy: 0.9511\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0989 - accuracy: 0.9583 - val_loss: 0.1124 - val_accuracy: 0.9507\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0987 - accuracy: 0.9575 - val_loss: 0.1121 - val_accuracy: 0.9525\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0979 - accuracy: 0.9580 - val_loss: 0.1132 - val_accuracy: 0.9486\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0964 - accuracy: 0.9589 - val_loss: 0.1175 - val_accuracy: 0.9515\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0966 - accuracy: 0.9582 - val_loss: 0.1145 - val_accuracy: 0.9524\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0959 - accuracy: 0.9587 - val_loss: 0.1134 - val_accuracy: 0.9522\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0954 - accuracy: 0.9593 - val_loss: 0.1130 - val_accuracy: 0.9498\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.1121 - accuracy: 0.9525\n",
      "Accuracy: 95.25%\n",
      "Tiempo total de entrenamiento: 144.97 segundos\n",
      "Pérdida: 0.09539733827114105\n",
      "Accuracy: 95.930016040802\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Class','Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo11.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2179 - accuracy: 0.9095 - val_loss: 0.1655 - val_accuracy: 0.9333\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1519 - accuracy: 0.9371 - val_loss: 0.1426 - val_accuracy: 0.9414\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1382 - accuracy: 0.9421 - val_loss: 0.1391 - val_accuracy: 0.9406\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1316 - accuracy: 0.9443 - val_loss: 0.1304 - val_accuracy: 0.9432\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1268 - accuracy: 0.9461 - val_loss: 0.1280 - val_accuracy: 0.9448\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1226 - accuracy: 0.9482 - val_loss: 0.1255 - val_accuracy: 0.9480\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1185 - accuracy: 0.9494 - val_loss: 0.1218 - val_accuracy: 0.9480\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1161 - accuracy: 0.9505 - val_loss: 0.1234 - val_accuracy: 0.9484\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1137 - accuracy: 0.9514 - val_loss: 0.1201 - val_accuracy: 0.9473\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1116 - accuracy: 0.9533 - val_loss: 0.1185 - val_accuracy: 0.9499\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1096 - accuracy: 0.9532 - val_loss: 0.1196 - val_accuracy: 0.9499\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1077 - accuracy: 0.9534 - val_loss: 0.1217 - val_accuracy: 0.9500\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1069 - accuracy: 0.9536 - val_loss: 0.1257 - val_accuracy: 0.9499\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1042 - accuracy: 0.9554 - val_loss: 0.1199 - val_accuracy: 0.9477\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1039 - accuracy: 0.9558 - val_loss: 0.1183 - val_accuracy: 0.9479\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1028 - accuracy: 0.9558 - val_loss: 0.1172 - val_accuracy: 0.9502\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1011 - accuracy: 0.9565 - val_loss: 0.1187 - val_accuracy: 0.9493\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0993 - accuracy: 0.9572 - val_loss: 0.1197 - val_accuracy: 0.9505\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0993 - accuracy: 0.9578 - val_loss: 0.1156 - val_accuracy: 0.9524\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0982 - accuracy: 0.9576 - val_loss: 0.1175 - val_accuracy: 0.9523\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0962 - accuracy: 0.9588 - val_loss: 0.1287 - val_accuracy: 0.9509\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0956 - accuracy: 0.9590 - val_loss: 0.1179 - val_accuracy: 0.9506\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0942 - accuracy: 0.9598 - val_loss: 0.1167 - val_accuracy: 0.9516\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0937 - accuracy: 0.9600 - val_loss: 0.1191 - val_accuracy: 0.9528\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.9524\n",
      "Accuracy: 95.24%\n",
      "Tiempo total de entrenamiento: 122.22 segundos\n",
      "Pérdida: 0.09372900426387787\n",
      "Accuracy: 96.00241184234619\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Class','Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo12.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorenviron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
