{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks, optimizers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('valoracion_aerolineas.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/dataset')\n",
    "\n",
    "df_train = pd.read_csv('/content/dataset/train.csv')\n",
    "df_test = pd.read_csv('/content/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>...</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Inflight service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>13</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco Plus</td>\n",
       "      <td>460</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>18.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>26</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1142</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>562</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>61</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103899</th>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>23</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103900</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>2347</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103901</th>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>30</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103902</th>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>22</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103903</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>27</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1723</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103594 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender      Customer Type  Age   Type of Travel     Class  \\\n",
       "0         Male     Loyal Customer   13  Personal Travel  Eco Plus   \n",
       "1         Male  disloyal Customer   25  Business travel  Business   \n",
       "2       Female     Loyal Customer   26  Business travel  Business   \n",
       "3       Female     Loyal Customer   25  Business travel  Business   \n",
       "4         Male     Loyal Customer   61  Business travel  Business   \n",
       "...        ...                ...  ...              ...       ...   \n",
       "103899  Female  disloyal Customer   23  Business travel       Eco   \n",
       "103900    Male     Loyal Customer   49  Business travel  Business   \n",
       "103901    Male  disloyal Customer   30  Business travel  Business   \n",
       "103902  Female  disloyal Customer   22  Business travel       Eco   \n",
       "103903    Male     Loyal Customer   27  Business travel  Business   \n",
       "\n",
       "        Flight Distance  Inflight wifi service  \\\n",
       "0                   460                      3   \n",
       "1                   235                      3   \n",
       "2                  1142                      2   \n",
       "3                   562                      2   \n",
       "4                   214                      3   \n",
       "...                 ...                    ...   \n",
       "103899              192                      2   \n",
       "103900             2347                      4   \n",
       "103901             1995                      1   \n",
       "103902             1000                      1   \n",
       "103903             1723                      1   \n",
       "\n",
       "        Departure/Arrival time convenient  Ease of Online booking  \\\n",
       "0                                       4                       3   \n",
       "1                                       2                       3   \n",
       "2                                       2                       2   \n",
       "3                                       5                       5   \n",
       "4                                       3                       3   \n",
       "...                                   ...                     ...   \n",
       "103899                                  1                       2   \n",
       "103900                                  4                       4   \n",
       "103901                                  1                       1   \n",
       "103902                                  1                       1   \n",
       "103903                                  3                       3   \n",
       "\n",
       "        Gate location  ...  Inflight entertainment  On-board service  \\\n",
       "0                   1  ...                       5                 4   \n",
       "1                   3  ...                       1                 1   \n",
       "2                   2  ...                       5                 4   \n",
       "3                   5  ...                       2                 2   \n",
       "4                   3  ...                       3                 3   \n",
       "...               ...  ...                     ...               ...   \n",
       "103899              3  ...                       2                 3   \n",
       "103900              4  ...                       5                 5   \n",
       "103901              3  ...                       4                 3   \n",
       "103902              5  ...                       1                 4   \n",
       "103903              3  ...                       1                 1   \n",
       "\n",
       "        Leg room service  Baggage handling  Checkin service  Inflight service  \\\n",
       "0                      3                 4                4                 5   \n",
       "1                      5                 3                1                 4   \n",
       "2                      3                 4                4                 4   \n",
       "3                      5                 3                1                 4   \n",
       "4                      4                 4                3                 3   \n",
       "...                  ...               ...              ...               ...   \n",
       "103899                 1                 4                2                 3   \n",
       "103900                 5                 5                5                 5   \n",
       "103901                 2                 4                5                 5   \n",
       "103902                 5                 1                5                 4   \n",
       "103903                 1                 4                4                 3   \n",
       "\n",
       "        Cleanliness  Departure Delay in Minutes  Arrival Delay in Minutes  \\\n",
       "0                 5                          25                      18.0   \n",
       "1                 1                           1                       6.0   \n",
       "2                 5                           0                       0.0   \n",
       "3                 2                          11                       9.0   \n",
       "4                 3                           0                       0.0   \n",
       "...             ...                         ...                       ...   \n",
       "103899            2                           3                       0.0   \n",
       "103900            4                           0                       0.0   \n",
       "103901            4                           7                      14.0   \n",
       "103902            1                           0                       0.0   \n",
       "103903            1                           0                       0.0   \n",
       "\n",
       "                   satisfaction  \n",
       "0       neutral or dissatisfied  \n",
       "1       neutral or dissatisfied  \n",
       "2                     satisfied  \n",
       "3       neutral or dissatisfied  \n",
       "4                     satisfied  \n",
       "...                         ...  \n",
       "103899  neutral or dissatisfied  \n",
       "103900                satisfied  \n",
       "103901  neutral or dissatisfied  \n",
       "103902  neutral or dissatisfied  \n",
       "103903  neutral or dissatisfied  \n",
       "\n",
       "[103594 rows x 23 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_train = df_train.drop(columns=['Unnamed: 0', 'id'])\n",
    "df_test = df_test.dropna()\n",
    "df_test = df_test.drop(columns=['Unnamed: 0', 'id'])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dummie = df_train.copy()\n",
    "\n",
    "# Aplicar Label Encoding a las columnas categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df_train_dummie.select_dtypes(include=['object']).columns:\n",
    "    df_train_dummie[column] = label_encoder.fit_transform(df_train_dummie[column])\n",
    "\n",
    "df_test_dummie = df_test.copy()\n",
    "\n",
    "# Aplicar Label Encoding a las columnas categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df_test_dummie.select_dtypes(include=['object']).columns:\n",
    "    df_test_dummie[column] = label_encoder.fit_transform(df_test_dummie[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_selected = df_train_dummie[['Type of Travel','Class','Online boarding','satisfaction']]\n",
    "df_test_selected = df_test_dummie[['Type of Travel','Class','Online boarding','satisfaction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age cluster\n",
    "df_train_new_features = pd.DataFrame()\n",
    "age_bins = [7,18,26,33,40,47,54,63,86]\n",
    "df_train_new_features['Age Cluster'] = pd.cut(df_train_dummie['Age'], bins=age_bins, labels=False, right=False)\n",
    "\n",
    "# Weight Comfort Seats\n",
    "df_train_new_features['Weight Comfort Seats'] = (df_train_dummie['Seat comfort']/5 + df_train_dummie['Class'] + df_train_dummie['Type of Travel'])\n",
    "\n",
    "# Media de todos los servicios que tienen valor del 0-5\n",
    "df_train_new_features['Mean Satisfaction Services'] = df_train_dummie[['Inflight wifi service','Departure/Arrival time convenient','Ease of Online booking','Gate location','Food and drink',\n",
    "                                  'Online boarding','Seat comfort','Inflight entertainment','On-board service','Leg room service','Baggage handling','Checkin service','Inflight service','Cleanliness']].mean(axis=1)\n",
    "\n",
    "# Suma del Servicio en Vuelo\n",
    "df_train_new_features['Sum Inflight Services'] = df_train_dummie['Inflight wifi service'] + df_train_dummie['Inflight service'] + df_train_dummie['Inflight entertainment'] + df_train_dummie['Online boarding']\n",
    "\n",
    "# Peso sobre el espacio de los pies según la clase\n",
    "df_train_new_features['Space Seat and Class'] = (df_train_dummie['Class'] * df_train_dummie['Leg room service']) / 5\n",
    "\n",
    "# suma de servicios básicos\n",
    "df_train_new_features['Weight Basic Services'] = df_train_dummie['Class'] + (df_train_dummie['Food and drink'] + df_train_dummie['Cleanliness'])/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age clister\n",
    "df_test_new_features = pd.DataFrame()\n",
    "age_bins = [7,18,26,33,40,47,54,63,86]\n",
    "df_test_new_features['Age Cluster'] = pd.cut(df_test['Age'], bins=age_bins, labels=False, right=False)\n",
    "\n",
    "# Weight Comfort Seats\n",
    "df_test_new_features['Weight Comfort Seats'] = (df_test_dummie['Seat comfort']/5 + df_test_dummie['Class'] + df_test_dummie['Type of Travel'])\n",
    "\n",
    "# Media de todos los servicios que tienen valor del 0-5\n",
    "df_test_new_features['Mean Satisfaction Services'] = df_test_dummie[['Inflight wifi service','Departure/Arrival time convenient','Ease of Online booking','Gate location','Food and drink',\n",
    "                                  'Online boarding','Seat comfort','Inflight entertainment','On-board service','Leg room service','Baggage handling','Checkin service','Inflight service','Cleanliness']].mean(axis=1)\n",
    "\n",
    "# Suma del Servicio en Vuelo\n",
    "df_test_new_features['Sum Inflight Services'] = df_test_dummie['Inflight wifi service'] + df_test_dummie['Inflight service'] + df_test_dummie['Inflight entertainment'] + df_test_dummie['Online boarding']\n",
    "\n",
    "# Peso sobre el espacio de los pies según la clase\n",
    "df_test_new_features['Space Seat and Class'] = (df_test_dummie['Class'] * df_test_dummie['Leg room service']) / 5\n",
    "\n",
    "# suma de servicios básicos\n",
    "df_test_new_features['Weight Basic Services'] = df_test_dummie['Class'] + (df_test_dummie['Food and drink'] + df_test_dummie['Cleanliness'])/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined = pd.concat([df_train_selected, df_train_new_features], axis=1)\n",
    "\n",
    "# Eliminar las columnas duplicadas si es necesario\n",
    "df_train_combined = df_train_combined.loc[:, ~df_train_combined.columns.duplicated()]\n",
    "\n",
    "df_test_combined = pd.concat([df_test_selected, df_test_new_features], axis=1)\n",
    "df_test_combined = df_test_combined.loc[:, ~df_test_combined.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un callback personalizado para medir el tiempo de entrenamiento\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.times = []\n",
    "        self.train_start_time = time.time()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.times.append(time.time() - self.epoch_start_time)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.total_train_time = time.time() - self.train_start_time\n",
    "        \n",
    "time_callback = TimeHistory()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 1: Valores sin análisis previo\n",
    "- Inputs: Todo el data set (dummie)\n",
    "- Epochs = 100\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 relu\n",
    "- 3ra capa = 1 sigmoid\n",
    "- learning_rate=0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 3s 978us/step - loss: 0.1994 - accuracy: 0.9190 - val_loss: 0.1414 - val_accuracy: 0.9401 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 2s 895us/step - loss: 0.1358 - accuracy: 0.9442 - val_loss: 0.1196 - val_accuracy: 0.9499 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1173 - accuracy: 0.9513 - val_loss: 0.1120 - val_accuracy: 0.9547 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.1076 - accuracy: 0.9548 - val_loss: 0.1060 - val_accuracy: 0.9543 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 9s 4ms/step - loss: 0.1022 - accuracy: 0.9568 - val_loss: 0.1014 - val_accuracy: 0.9590 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0971 - accuracy: 0.9588 - val_loss: 0.0975 - val_accuracy: 0.9586 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 2s 843us/step - loss: 0.0942 - accuracy: 0.9594 - val_loss: 0.0977 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 2s 878us/step - loss: 0.0918 - accuracy: 0.9607 - val_loss: 0.0953 - val_accuracy: 0.9572 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 3s 989us/step - loss: 0.0899 - accuracy: 0.9616 - val_loss: 0.0920 - val_accuracy: 0.9611 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0876 - accuracy: 0.9617 - val_loss: 0.0964 - val_accuracy: 0.9604 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.0866 - accuracy: 0.9629 - val_loss: 0.0916 - val_accuracy: 0.9617 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.0848 - accuracy: 0.9632 - val_loss: 0.0926 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0838 - accuracy: 0.9633 - val_loss: 0.0929 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 4s 1ms/step - loss: 0.0832 - accuracy: 0.9632 - val_loss: 0.0993 - val_accuracy: 0.9540 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.0816 - accuracy: 0.9648 - val_loss: 0.0901 - val_accuracy: 0.9610 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.0808 - accuracy: 0.9642 - val_loss: 0.0909 - val_accuracy: 0.9619 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.0803 - accuracy: 0.9649 - val_loss: 0.0904 - val_accuracy: 0.9622 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 2s 855us/step - loss: 0.0794 - accuracy: 0.9653 - val_loss: 0.0914 - val_accuracy: 0.9603 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 2s 903us/step - loss: 0.0786 - accuracy: 0.9659 - val_loss: 0.0921 - val_accuracy: 0.9612 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 2s 846us/step - loss: 0.0779 - accuracy: 0.9660 - val_loss: 0.0928 - val_accuracy: 0.9615 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 2s 862us/step - loss: 0.0713 - accuracy: 0.9688 - val_loss: 0.0896 - val_accuracy: 0.9623 - lr: 2.0000e-04\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 2s 912us/step - loss: 0.0700 - accuracy: 0.9694 - val_loss: 0.0892 - val_accuracy: 0.9608 - lr: 2.0000e-04\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 2s 906us/step - loss: 0.0694 - accuracy: 0.9698 - val_loss: 0.0898 - val_accuracy: 0.9610 - lr: 2.0000e-04\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 2s 878us/step - loss: 0.0691 - accuracy: 0.9701 - val_loss: 0.0902 - val_accuracy: 0.9604 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 2s 827us/step - loss: 0.0686 - accuracy: 0.9697 - val_loss: 0.0914 - val_accuracy: 0.9593 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 2s 960us/step - loss: 0.0684 - accuracy: 0.9702 - val_loss: 0.0906 - val_accuracy: 0.9610 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 2s 913us/step - loss: 0.0682 - accuracy: 0.9700 - val_loss: 0.0905 - val_accuracy: 0.9603 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 2s 853us/step - loss: 0.0665 - accuracy: 0.9709 - val_loss: 0.0900 - val_accuracy: 0.9611 - lr: 4.0000e-05\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 2s 838us/step - loss: 0.0662 - accuracy: 0.9710 - val_loss: 0.0902 - val_accuracy: 0.9608 - lr: 4.0000e-05\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 2s 916us/step - loss: 0.0661 - accuracy: 0.9712 - val_loss: 0.0902 - val_accuracy: 0.9612 - lr: 4.0000e-05\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 3s 989us/step - loss: 0.0661 - accuracy: 0.9714 - val_loss: 0.0903 - val_accuracy: 0.9611 - lr: 4.0000e-05\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 2s 960us/step - loss: 0.0660 - accuracy: 0.9715 - val_loss: 0.0903 - val_accuracy: 0.9610 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_dummie.drop('satisfaction', axis=1)\n",
    "y_train = df_train_dummie['satisfaction']\n",
    "\n",
    "X_test = df_test_dummie.drop('satisfaction', axis=1)\n",
    "y_test = df_test_dummie['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Capas\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Hiperparámetros\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Recalls\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m1.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "# Modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 129.60 segundos\n",
      "Pérdida: 0.0660059005022049\n",
      "Accuracy Modelo: 97.14509844779968\n",
      "Recall: 0.9456225252969643\n",
      "Specificity: 0.5707334\n",
      "F1-Score: 0.9561387900355872\n",
      "Precisión: 0.9668915879442195\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m1.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 2: Correlativa Individual\n",
    "- Inputs: 'Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service',\"Cleanliness\"\n",
    "- Epochs = 50\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 relu\n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate=0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 3s 944us/step - loss: 0.2931 - accuracy: 0.8818 - val_loss: 0.2595 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 2s 888us/step - loss: 0.2601 - accuracy: 0.8950 - val_loss: 0.2463 - val_accuracy: 0.9022 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2514 - accuracy: 0.8979 - val_loss: 0.2415 - val_accuracy: 0.9021 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 2s 899us/step - loss: 0.2456 - accuracy: 0.9007 - val_loss: 0.2400 - val_accuracy: 0.9025 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 2s 915us/step - loss: 0.2404 - accuracy: 0.9016 - val_loss: 0.2357 - val_accuracy: 0.9044 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 2s 904us/step - loss: 0.2372 - accuracy: 0.9026 - val_loss: 0.2315 - val_accuracy: 0.9049 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 2s 950us/step - loss: 0.2342 - accuracy: 0.9041 - val_loss: 0.2296 - val_accuracy: 0.9045 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 2s 917us/step - loss: 0.2320 - accuracy: 0.9047 - val_loss: 0.2261 - val_accuracy: 0.9086 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 2s 900us/step - loss: 0.2302 - accuracy: 0.9049 - val_loss: 0.2244 - val_accuracy: 0.9077 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 2s 887us/step - loss: 0.2285 - accuracy: 0.9056 - val_loss: 0.2286 - val_accuracy: 0.9055 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 2s 858us/step - loss: 0.2274 - accuracy: 0.9067 - val_loss: 0.2223 - val_accuracy: 0.9088 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 2s 914us/step - loss: 0.2263 - accuracy: 0.9066 - val_loss: 0.2219 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 2s 918us/step - loss: 0.2250 - accuracy: 0.9072 - val_loss: 0.2203 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 2s 827us/step - loss: 0.2241 - accuracy: 0.9070 - val_loss: 0.2211 - val_accuracy: 0.9081 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 2s 887us/step - loss: 0.2231 - accuracy: 0.9069 - val_loss: 0.2232 - val_accuracy: 0.9066 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 2s 859us/step - loss: 0.2233 - accuracy: 0.9073 - val_loss: 0.2217 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 2s 859us/step - loss: 0.2220 - accuracy: 0.9077 - val_loss: 0.2204 - val_accuracy: 0.9079 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 2s 876us/step - loss: 0.2214 - accuracy: 0.9082 - val_loss: 0.2198 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 2s 858us/step - loss: 0.2206 - accuracy: 0.9077 - val_loss: 0.2203 - val_accuracy: 0.9072 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 2s 868us/step - loss: 0.2204 - accuracy: 0.9080 - val_loss: 0.2203 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 2s 829us/step - loss: 0.2200 - accuracy: 0.9086 - val_loss: 0.2189 - val_accuracy: 0.9086 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 2s 941us/step - loss: 0.2196 - accuracy: 0.9082 - val_loss: 0.2193 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 2s 952us/step - loss: 0.2193 - accuracy: 0.9087 - val_loss: 0.2187 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 2s 872us/step - loss: 0.2187 - accuracy: 0.9090 - val_loss: 0.2203 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 2s 807us/step - loss: 0.2183 - accuracy: 0.9094 - val_loss: 0.2168 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 2s 934us/step - loss: 0.2177 - accuracy: 0.9095 - val_loss: 0.2200 - val_accuracy: 0.9083 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 2s 932us/step - loss: 0.2173 - accuracy: 0.9095 - val_loss: 0.2176 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 2s 893us/step - loss: 0.2177 - accuracy: 0.9093 - val_loss: 0.2190 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 2s 851us/step - loss: 0.2165 - accuracy: 0.9095 - val_loss: 0.2159 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 2s 768us/step - loss: 0.2166 - accuracy: 0.9096 - val_loss: 0.2163 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 2s 823us/step - loss: 0.2159 - accuracy: 0.9105 - val_loss: 0.2168 - val_accuracy: 0.9086 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 2s 880us/step - loss: 0.2163 - accuracy: 0.9103 - val_loss: 0.2170 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 2s 835us/step - loss: 0.2157 - accuracy: 0.9103 - val_loss: 0.2175 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 2s 826us/step - loss: 0.2151 - accuracy: 0.9104 - val_loss: 0.2167 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 2s 887us/step - loss: 0.2097 - accuracy: 0.9130 - val_loss: 0.2138 - val_accuracy: 0.9111 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 2s 822us/step - loss: 0.2089 - accuracy: 0.9133 - val_loss: 0.2139 - val_accuracy: 0.9110 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 2s 881us/step - loss: 0.2087 - accuracy: 0.9130 - val_loss: 0.2135 - val_accuracy: 0.9113 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 2s 903us/step - loss: 0.2085 - accuracy: 0.9140 - val_loss: 0.2135 - val_accuracy: 0.9109 - lr: 2.0000e-04\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 2s 869us/step - loss: 0.2083 - accuracy: 0.9137 - val_loss: 0.2135 - val_accuracy: 0.9110 - lr: 2.0000e-04\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 2s 901us/step - loss: 0.2084 - accuracy: 0.9132 - val_loss: 0.2130 - val_accuracy: 0.9114 - lr: 2.0000e-04\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 3s 966us/step - loss: 0.2083 - accuracy: 0.9132 - val_loss: 0.2138 - val_accuracy: 0.9096 - lr: 2.0000e-04\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 3s 969us/step - loss: 0.2081 - accuracy: 0.9134 - val_loss: 0.2134 - val_accuracy: 0.9117 - lr: 2.0000e-04\n",
      "Epoch 43/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2081 - accuracy: 0.9134 - val_loss: 0.2133 - val_accuracy: 0.9112 - lr: 2.0000e-04\n",
      "Epoch 44/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2080 - accuracy: 0.9134 - val_loss: 0.2134 - val_accuracy: 0.9109 - lr: 2.0000e-04\n",
      "Epoch 45/50\n",
      "2590/2590 [==============================] - 2s 955us/step - loss: 0.2078 - accuracy: 0.9139 - val_loss: 0.2137 - val_accuracy: 0.9114 - lr: 2.0000e-04\n",
      "Epoch 46/50\n",
      "2590/2590 [==============================] - 2s 946us/step - loss: 0.2064 - accuracy: 0.9144 - val_loss: 0.2129 - val_accuracy: 0.9115 - lr: 4.0000e-05\n",
      "Epoch 47/50\n",
      "2590/2590 [==============================] - 2s 891us/step - loss: 0.2062 - accuracy: 0.9141 - val_loss: 0.2129 - val_accuracy: 0.9114 - lr: 4.0000e-05\n",
      "Epoch 48/50\n",
      "2590/2590 [==============================] - 2s 912us/step - loss: 0.2062 - accuracy: 0.9144 - val_loss: 0.2128 - val_accuracy: 0.9112 - lr: 4.0000e-05\n",
      "Epoch 49/50\n",
      "2590/2590 [==============================] - 2s 882us/step - loss: 0.2062 - accuracy: 0.9144 - val_loss: 0.2129 - val_accuracy: 0.9112 - lr: 4.0000e-05\n",
      "Epoch 50/50\n",
      "2590/2590 [==============================] - 2s 876us/step - loss: 0.2062 - accuracy: 0.9141 - val_loss: 0.2129 - val_accuracy: 0.9115 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_train = df_train_dummie['satisfaction']\n",
    "\n",
    "X_test = df_test_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_test = df_test_dummie['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m2.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 116.46 segundos\n",
      "Pérdida: 0.2061804085969925\n",
      "Accuracy Modelo: 91.41477942466736\n",
      "Recall: 0.8807743070831501\n",
      "Specificity: 0.57548374\n",
      "F1-Score: 0.8954689806324642\n",
      "Precisión: 0.9106622998544396\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m2.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 3: Correlaciones cercanas > 0.3 (+1 capa)\n",
    "- Inputs: 'Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service',\"Cleanliness\"\n",
    "- Epochs = 50\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 relu\n",
    "- 3ra capa = 16 relu\n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate = 0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 3s 981us/step - loss: 0.2894 - accuracy: 0.8826 - val_loss: 0.2538 - val_accuracy: 0.8986 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 2s 911us/step - loss: 0.2577 - accuracy: 0.8966 - val_loss: 0.2425 - val_accuracy: 0.9027 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 2s 932us/step - loss: 0.2478 - accuracy: 0.8998 - val_loss: 0.2486 - val_accuracy: 0.8993 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 2s 946us/step - loss: 0.2407 - accuracy: 0.9020 - val_loss: 0.2305 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2354 - accuracy: 0.9039 - val_loss: 0.2290 - val_accuracy: 0.9065 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 3s 994us/step - loss: 0.2323 - accuracy: 0.9049 - val_loss: 0.2243 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2288 - accuracy: 0.9052 - val_loss: 0.2240 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 2s 914us/step - loss: 0.2264 - accuracy: 0.9065 - val_loss: 0.2292 - val_accuracy: 0.9080 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 2s 962us/step - loss: 0.2242 - accuracy: 0.9082 - val_loss: 0.2220 - val_accuracy: 0.9088 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 2s 948us/step - loss: 0.2228 - accuracy: 0.9077 - val_loss: 0.2199 - val_accuracy: 0.9092 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 3s 971us/step - loss: 0.2217 - accuracy: 0.9086 - val_loss: 0.2201 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 3s 979us/step - loss: 0.2203 - accuracy: 0.9093 - val_loss: 0.2202 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 3s 978us/step - loss: 0.2196 - accuracy: 0.9093 - val_loss: 0.2204 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 2s 960us/step - loss: 0.2191 - accuracy: 0.9095 - val_loss: 0.2209 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 2s 900us/step - loss: 0.2182 - accuracy: 0.9096 - val_loss: 0.2163 - val_accuracy: 0.9092 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 3s 989us/step - loss: 0.2177 - accuracy: 0.9100 - val_loss: 0.2182 - val_accuracy: 0.9088 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 2s 892us/step - loss: 0.2173 - accuracy: 0.9094 - val_loss: 0.2194 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 2s 920us/step - loss: 0.2167 - accuracy: 0.9104 - val_loss: 0.2160 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 2s 909us/step - loss: 0.2159 - accuracy: 0.9102 - val_loss: 0.2175 - val_accuracy: 0.9097 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 3s 979us/step - loss: 0.2158 - accuracy: 0.9102 - val_loss: 0.2205 - val_accuracy: 0.9076 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 3s 975us/step - loss: 0.2153 - accuracy: 0.9104 - val_loss: 0.2209 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 2s 928us/step - loss: 0.2150 - accuracy: 0.9113 - val_loss: 0.2182 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 2s 881us/step - loss: 0.2148 - accuracy: 0.9106 - val_loss: 0.2158 - val_accuracy: 0.9105 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 2s 865us/step - loss: 0.2145 - accuracy: 0.9107 - val_loss: 0.2169 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 2s 895us/step - loss: 0.2142 - accuracy: 0.9112 - val_loss: 0.2176 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 2s 943us/step - loss: 0.2137 - accuracy: 0.9115 - val_loss: 0.2153 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 2s 938us/step - loss: 0.2133 - accuracy: 0.9115 - val_loss: 0.2155 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 3s 972us/step - loss: 0.2132 - accuracy: 0.9112 - val_loss: 0.2169 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 2s 962us/step - loss: 0.2129 - accuracy: 0.9111 - val_loss: 0.2160 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 3s 972us/step - loss: 0.2126 - accuracy: 0.9116 - val_loss: 0.2156 - val_accuracy: 0.9098 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 2s 913us/step - loss: 0.2119 - accuracy: 0.9120 - val_loss: 0.2156 - val_accuracy: 0.9101 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 3s 965us/step - loss: 0.2065 - accuracy: 0.9138 - val_loss: 0.2125 - val_accuracy: 0.9120 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 2s 955us/step - loss: 0.2057 - accuracy: 0.9144 - val_loss: 0.2128 - val_accuracy: 0.9119 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 3s 967us/step - loss: 0.2052 - accuracy: 0.9145 - val_loss: 0.2130 - val_accuracy: 0.9119 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 2s 962us/step - loss: 0.2050 - accuracy: 0.9144 - val_loss: 0.2127 - val_accuracy: 0.9116 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 2s 882us/step - loss: 0.2048 - accuracy: 0.9142 - val_loss: 0.2128 - val_accuracy: 0.9121 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 2s 904us/step - loss: 0.2048 - accuracy: 0.9145 - val_loss: 0.2130 - val_accuracy: 0.9126 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 2s 962us/step - loss: 0.2032 - accuracy: 0.9150 - val_loss: 0.2128 - val_accuracy: 0.9125 - lr: 4.0000e-05\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 2s 939us/step - loss: 0.2030 - accuracy: 0.9152 - val_loss: 0.2129 - val_accuracy: 0.9124 - lr: 4.0000e-05\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2030 - accuracy: 0.9151 - val_loss: 0.2128 - val_accuracy: 0.9124 - lr: 4.0000e-05\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2029 - accuracy: 0.9152 - val_loss: 0.2130 - val_accuracy: 0.9127 - lr: 4.0000e-05\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 3s 994us/step - loss: 0.2029 - accuracy: 0.9150 - val_loss: 0.2129 - val_accuracy: 0.9123 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_train = df_train_dummie['satisfaction']\n",
    "\n",
    "X_test = df_test_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_test = df_test_dummie['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m3.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 103.97 segundos\n",
      "Pérdida: 0.20288875699043274\n",
      "Accuracy Modelo: 91.50407314300537\n",
      "Recall: 0.8815662120545534\n",
      "Specificity: 0.5758699\n",
      "F1-Score: 0.8966751689264779\n",
      "Precisión: 0.9123110544527409\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m3.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 4: Correlaciones > 0.3 (Other activations)\n",
    "- Inputs: 'Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service',\"Cleanliness\"\n",
    "- Epochs = 50\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 tanh\n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate = 0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 3s 885us/step - loss: 0.2997 - accuracy: 0.8778 - val_loss: 0.2665 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 2s 890us/step - loss: 0.2654 - accuracy: 0.8923 - val_loss: 0.2490 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2541 - accuracy: 0.8969 - val_loss: 0.2430 - val_accuracy: 0.9012 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2462 - accuracy: 0.9006 - val_loss: 0.2363 - val_accuracy: 0.9046 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 2s 883us/step - loss: 0.2411 - accuracy: 0.9016 - val_loss: 0.2343 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 2s 860us/step - loss: 0.2376 - accuracy: 0.9028 - val_loss: 0.2301 - val_accuracy: 0.9049 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 2s 880us/step - loss: 0.2350 - accuracy: 0.9029 - val_loss: 0.2278 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 2s 879us/step - loss: 0.2325 - accuracy: 0.9038 - val_loss: 0.2329 - val_accuracy: 0.9013 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 2s 943us/step - loss: 0.2310 - accuracy: 0.9042 - val_loss: 0.2279 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 2s 863us/step - loss: 0.2295 - accuracy: 0.9060 - val_loss: 0.2313 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 2s 864us/step - loss: 0.2282 - accuracy: 0.9051 - val_loss: 0.2235 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 2s 857us/step - loss: 0.2268 - accuracy: 0.9065 - val_loss: 0.2200 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 2s 844us/step - loss: 0.2258 - accuracy: 0.9070 - val_loss: 0.2227 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2247 - accuracy: 0.9064 - val_loss: 0.2255 - val_accuracy: 0.9068 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2238 - accuracy: 0.9074 - val_loss: 0.2205 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2230 - accuracy: 0.9076 - val_loss: 0.2210 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 4s 1ms/step - loss: 0.2223 - accuracy: 0.9083 - val_loss: 0.2231 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2170 - accuracy: 0.9101 - val_loss: 0.2166 - val_accuracy: 0.9113 - lr: 2.0000e-04\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2162 - accuracy: 0.9107 - val_loss: 0.2160 - val_accuracy: 0.9115 - lr: 2.0000e-04\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2159 - accuracy: 0.9105 - val_loss: 0.2167 - val_accuracy: 0.9121 - lr: 2.0000e-04\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.2157 - accuracy: 0.9108 - val_loss: 0.2160 - val_accuracy: 0.9109 - lr: 2.0000e-04\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2156 - accuracy: 0.9109 - val_loss: 0.2153 - val_accuracy: 0.9109 - lr: 2.0000e-04\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2152 - accuracy: 0.9107 - val_loss: 0.2165 - val_accuracy: 0.9111 - lr: 2.0000e-04\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2151 - accuracy: 0.9112 - val_loss: 0.2161 - val_accuracy: 0.9108 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2150 - accuracy: 0.9110 - val_loss: 0.2161 - val_accuracy: 0.9108 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 2s 808us/step - loss: 0.2148 - accuracy: 0.9110 - val_loss: 0.2160 - val_accuracy: 0.9106 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 3s 981us/step - loss: 0.2148 - accuracy: 0.9113 - val_loss: 0.2150 - val_accuracy: 0.9118 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2146 - accuracy: 0.9111 - val_loss: 0.2154 - val_accuracy: 0.9111 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.2144 - accuracy: 0.9112 - val_loss: 0.2149 - val_accuracy: 0.9100 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2142 - accuracy: 0.9112 - val_loss: 0.2162 - val_accuracy: 0.9099 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2142 - accuracy: 0.9118 - val_loss: 0.2149 - val_accuracy: 0.9116 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.2140 - accuracy: 0.9115 - val_loss: 0.2155 - val_accuracy: 0.9117 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2126 - accuracy: 0.9121 - val_loss: 0.2147 - val_accuracy: 0.9109 - lr: 4.0000e-05\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 2s 941us/step - loss: 0.2126 - accuracy: 0.9119 - val_loss: 0.2147 - val_accuracy: 0.9113 - lr: 4.0000e-05\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 2s 920us/step - loss: 0.2125 - accuracy: 0.9117 - val_loss: 0.2148 - val_accuracy: 0.9113 - lr: 4.0000e-05\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 2s 920us/step - loss: 0.2124 - accuracy: 0.9123 - val_loss: 0.2145 - val_accuracy: 0.9113 - lr: 4.0000e-05\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 2s 880us/step - loss: 0.2124 - accuracy: 0.9121 - val_loss: 0.2147 - val_accuracy: 0.9121 - lr: 4.0000e-05\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 2s 874us/step - loss: 0.2124 - accuracy: 0.9121 - val_loss: 0.2148 - val_accuracy: 0.9114 - lr: 4.0000e-05\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 2s 889us/step - loss: 0.2123 - accuracy: 0.9120 - val_loss: 0.2151 - val_accuracy: 0.9111 - lr: 4.0000e-05\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 2s 946us/step - loss: 0.2123 - accuracy: 0.9120 - val_loss: 0.2146 - val_accuracy: 0.9113 - lr: 4.0000e-05\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 2s 964us/step - loss: 0.2123 - accuracy: 0.9120 - val_loss: 0.2148 - val_accuracy: 0.9112 - lr: 4.0000e-05\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2120 - accuracy: 0.9125 - val_loss: 0.2146 - val_accuracy: 0.9111 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "2590/2590 [==============================] - 2s 941us/step - loss: 0.2120 - accuracy: 0.9121 - val_loss: 0.2146 - val_accuracy: 0.9111 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "2590/2590 [==============================] - 2s 882us/step - loss: 0.2120 - accuracy: 0.9122 - val_loss: 0.2147 - val_accuracy: 0.9111 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "2590/2590 [==============================] - 2s 934us/step - loss: 0.2120 - accuracy: 0.9122 - val_loss: 0.2146 - val_accuracy: 0.9115 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "2590/2590 [==============================] - 2s 914us/step - loss: 0.2119 - accuracy: 0.9123 - val_loss: 0.2146 - val_accuracy: 0.9115 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_train = df_train_dummie['satisfaction']\n",
    "\n",
    "X_test = df_test_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_test = df_test_dummie['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='tanh'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m4.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 165.34 segundos\n",
      "Pérdida: 0.2119370996952057\n",
      "Accuracy Modelo: 91.231369972229\n",
      "Recall: 0.8745270567531896\n",
      "Specificity: 0.5805816\n",
      "F1-Score: 0.894398200224972\n",
      "Precisión: 0.9151933701657459\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m4.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 5: Correlaciones > 0.3 (Más nodos, más capas, nuevas funciones activación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 3s 945us/step - loss: 0.2755 - accuracy: 0.8882 - val_loss: 0.2439 - val_accuracy: 0.9001 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 2s 909us/step - loss: 0.2461 - accuracy: 0.8996 - val_loss: 0.2320 - val_accuracy: 0.9072 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2365 - accuracy: 0.9021 - val_loss: 0.2259 - val_accuracy: 0.9047 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 2s 953us/step - loss: 0.2311 - accuracy: 0.9042 - val_loss: 0.2223 - val_accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 2s 952us/step - loss: 0.2266 - accuracy: 0.9060 - val_loss: 0.2205 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 3s 974us/step - loss: 0.2241 - accuracy: 0.9074 - val_loss: 0.2194 - val_accuracy: 0.9102 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2221 - accuracy: 0.9080 - val_loss: 0.2156 - val_accuracy: 0.9092 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 3s 989us/step - loss: 0.2197 - accuracy: 0.9094 - val_loss: 0.2169 - val_accuracy: 0.9094 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 2s 916us/step - loss: 0.2185 - accuracy: 0.9091 - val_loss: 0.2134 - val_accuracy: 0.9124 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 3s 980us/step - loss: 0.2173 - accuracy: 0.9094 - val_loss: 0.2154 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2165 - accuracy: 0.9098 - val_loss: 0.2152 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 3s 966us/step - loss: 0.2158 - accuracy: 0.9104 - val_loss: 0.2151 - val_accuracy: 0.9115 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2145 - accuracy: 0.9107 - val_loss: 0.2173 - val_accuracy: 0.9109 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 2s 886us/step - loss: 0.2139 - accuracy: 0.9108 - val_loss: 0.2127 - val_accuracy: 0.9117 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 3s 983us/step - loss: 0.2133 - accuracy: 0.9115 - val_loss: 0.2154 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 2s 918us/step - loss: 0.2125 - accuracy: 0.9119 - val_loss: 0.2137 - val_accuracy: 0.9104 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 2s 933us/step - loss: 0.2121 - accuracy: 0.9120 - val_loss: 0.2159 - val_accuracy: 0.9117 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2118 - accuracy: 0.9113 - val_loss: 0.2142 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2107 - accuracy: 0.9120 - val_loss: 0.2137 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.2039 - accuracy: 0.9146 - val_loss: 0.2111 - val_accuracy: 0.9120 - lr: 2.0000e-04\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2027 - accuracy: 0.9147 - val_loss: 0.2107 - val_accuracy: 0.9116 - lr: 2.0000e-04\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2022 - accuracy: 0.9152 - val_loss: 0.2114 - val_accuracy: 0.9130 - lr: 2.0000e-04\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.2018 - accuracy: 0.9156 - val_loss: 0.2118 - val_accuracy: 0.9111 - lr: 2.0000e-04\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.2014 - accuracy: 0.9157 - val_loss: 0.2113 - val_accuracy: 0.9118 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.2011 - accuracy: 0.9161 - val_loss: 0.2119 - val_accuracy: 0.9122 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2010 - accuracy: 0.9162 - val_loss: 0.2111 - val_accuracy: 0.9121 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.1989 - accuracy: 0.9167 - val_loss: 0.2112 - val_accuracy: 0.9115 - lr: 4.0000e-05\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.1987 - accuracy: 0.9165 - val_loss: 0.2115 - val_accuracy: 0.9124 - lr: 4.0000e-05\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.1986 - accuracy: 0.9165 - val_loss: 0.2113 - val_accuracy: 0.9121 - lr: 4.0000e-05\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 11s 4ms/step - loss: 0.1985 - accuracy: 0.9168 - val_loss: 0.2115 - val_accuracy: 0.9119 - lr: 4.0000e-05\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 2s 925us/step - loss: 0.1984 - accuracy: 0.9166 - val_loss: 0.2114 - val_accuracy: 0.9123 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_train = df_train_dummie['satisfaction']\n",
    "\n",
    "X_test = df_test_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_test = df_test_dummie['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(16, activation='tanh'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m5.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 146.32 segundos\n",
      "Pérdida: 0.19842857122421265\n",
      "Accuracy Modelo: 91.65852069854736\n",
      "Recall: 0.8780466344038715\n",
      "Specificity: 0.5789982\n",
      "F1-Score: 0.8963442019222132\n",
      "Precisión: 0.9154206036143473\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m5.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 5: Mayores niveles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.4468 - accuracy: 0.8810 - val_loss: 0.2991 - val_accuracy: 0.9167\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3252 - accuracy: 0.9028 - val_loss: 0.2694 - val_accuracy: 0.9214\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3031 - accuracy: 0.9080 - val_loss: 0.2549 - val_accuracy: 0.9268\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2893 - accuracy: 0.9113 - val_loss: 0.2418 - val_accuracy: 0.9324\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2803 - accuracy: 0.9141 - val_loss: 0.2338 - val_accuracy: 0.9342\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2749 - accuracy: 0.9153 - val_loss: 0.2318 - val_accuracy: 0.9290\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2709 - accuracy: 0.9159 - val_loss: 0.2256 - val_accuracy: 0.9310\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2660 - accuracy: 0.9165 - val_loss: 0.2230 - val_accuracy: 0.9349\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2615 - accuracy: 0.9172 - val_loss: 0.2218 - val_accuracy: 0.9319\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2616 - accuracy: 0.9172 - val_loss: 0.2167 - val_accuracy: 0.9330\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 6s 3ms/step - loss: 0.2600 - accuracy: 0.9174 - val_loss: 0.2192 - val_accuracy: 0.9333\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2575 - accuracy: 0.9176 - val_loss: 0.2196 - val_accuracy: 0.9341\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2575 - accuracy: 0.9172 - val_loss: 0.2154 - val_accuracy: 0.9346\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2546 - accuracy: 0.9189 - val_loss: 0.2151 - val_accuracy: 0.9319\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2525 - accuracy: 0.9188 - val_loss: 0.2177 - val_accuracy: 0.9325\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2527 - accuracy: 0.9191 - val_loss: 0.2145 - val_accuracy: 0.9344\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2523 - accuracy: 0.9194 - val_loss: 0.2140 - val_accuracy: 0.9341\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2508 - accuracy: 0.9201 - val_loss: 0.2109 - val_accuracy: 0.9363\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2517 - accuracy: 0.9200 - val_loss: 0.2149 - val_accuracy: 0.9347\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2504 - accuracy: 0.9194 - val_loss: 0.2113 - val_accuracy: 0.9305\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2490 - accuracy: 0.9195 - val_loss: 0.2090 - val_accuracy: 0.9324\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2498 - accuracy: 0.9199 - val_loss: 0.2221 - val_accuracy: 0.9272\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2474 - accuracy: 0.9210 - val_loss: 0.2091 - val_accuracy: 0.9353\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2471 - accuracy: 0.9195 - val_loss: 0.2075 - val_accuracy: 0.9359\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2493 - accuracy: 0.9194 - val_loss: 0.2070 - val_accuracy: 0.9339\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2475 - accuracy: 0.9193 - val_loss: 0.2071 - val_accuracy: 0.9324\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2464 - accuracy: 0.9189 - val_loss: 0.2105 - val_accuracy: 0.9348\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2461 - accuracy: 0.9195 - val_loss: 0.2083 - val_accuracy: 0.9343\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2463 - accuracy: 0.9201 - val_loss: 0.2088 - val_accuracy: 0.9350\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2462 - accuracy: 0.9207 - val_loss: 0.2054 - val_accuracy: 0.9360\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2458 - accuracy: 0.9203 - val_loss: 0.2073 - val_accuracy: 0.9342\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2435 - accuracy: 0.9208 - val_loss: 0.2064 - val_accuracy: 0.9346\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2447 - accuracy: 0.9209 - val_loss: 0.2131 - val_accuracy: 0.9313\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2458 - accuracy: 0.9215 - val_loss: 0.2019 - val_accuracy: 0.9379\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2447 - accuracy: 0.9200 - val_loss: 0.2113 - val_accuracy: 0.9342\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2433 - accuracy: 0.9211 - val_loss: 0.2066 - val_accuracy: 0.9357\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2427 - accuracy: 0.9216 - val_loss: 0.2065 - val_accuracy: 0.9371\n",
      "Epoch 38/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2462 - accuracy: 0.9205 - val_loss: 0.2049 - val_accuracy: 0.9351\n",
      "Epoch 39/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2438 - accuracy: 0.9200 - val_loss: 0.2080 - val_accuracy: 0.9313\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.2019 - accuracy: 0.9379\n",
      "Accuracy: 93.79%\n",
      "Tiempo total de entrenamiento: 235.77 segundos\n",
      "Pérdida: 0.24376218020915985\n",
      "Accuracy: 92.00241565704346\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Online boarding','Inflight wifi service','Class','Type of Travel','Inflight entertainment','Seat comfort','Leg room service','Customer Type','Ease of Online booking']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "    Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "    Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo5.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 6: Mayor correlación individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.5796 - accuracy: 0.8434 - val_loss: 0.3475 - val_accuracy: 0.9034\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 6s 3ms/step - loss: 0.3963 - accuracy: 0.8817 - val_loss: 0.3128 - val_accuracy: 0.9106\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3729 - accuracy: 0.8893 - val_loss: 0.2986 - val_accuracy: 0.9198\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3656 - accuracy: 0.8914 - val_loss: 0.2865 - val_accuracy: 0.9199\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3552 - accuracy: 0.8938 - val_loss: 0.2780 - val_accuracy: 0.9205\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3507 - accuracy: 0.8938 - val_loss: 0.2775 - val_accuracy: 0.9185\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3481 - accuracy: 0.8950 - val_loss: 0.2765 - val_accuracy: 0.9170\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.3445 - accuracy: 0.8962 - val_loss: 0.2714 - val_accuracy: 0.9208\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.3441 - accuracy: 0.8961 - val_loss: 0.2772 - val_accuracy: 0.9193\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3408 - accuracy: 0.8969 - val_loss: 0.2674 - val_accuracy: 0.9228\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3383 - accuracy: 0.8969 - val_loss: 0.2666 - val_accuracy: 0.9208\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3381 - accuracy: 0.8962 - val_loss: 0.2654 - val_accuracy: 0.9211\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3384 - accuracy: 0.8962 - val_loss: 0.2663 - val_accuracy: 0.9207\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3361 - accuracy: 0.8963 - val_loss: 0.2625 - val_accuracy: 0.9217\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3343 - accuracy: 0.8963 - val_loss: 0.2654 - val_accuracy: 0.9172\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3326 - accuracy: 0.8964 - val_loss: 0.2598 - val_accuracy: 0.9221\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3330 - accuracy: 0.8971 - val_loss: 0.2694 - val_accuracy: 0.9182\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3298 - accuracy: 0.8980 - val_loss: 0.2574 - val_accuracy: 0.9213\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3289 - accuracy: 0.8987 - val_loss: 0.2564 - val_accuracy: 0.9230\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3271 - accuracy: 0.8984 - val_loss: 0.2593 - val_accuracy: 0.9192\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3259 - accuracy: 0.8992 - val_loss: 0.2550 - val_accuracy: 0.9246\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3265 - accuracy: 0.8993 - val_loss: 0.2558 - val_accuracy: 0.9225\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3264 - accuracy: 0.9001 - val_loss: 0.2528 - val_accuracy: 0.9219\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3247 - accuracy: 0.8987 - val_loss: 0.2526 - val_accuracy: 0.9214\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 14s 5ms/step - loss: 0.3230 - accuracy: 0.8998 - val_loss: 0.2570 - val_accuracy: 0.9207\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 32s 12ms/step - loss: 0.3238 - accuracy: 0.8990 - val_loss: 0.2529 - val_accuracy: 0.9203\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3237 - accuracy: 0.8990 - val_loss: 0.2559 - val_accuracy: 0.9221\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3223 - accuracy: 0.9005 - val_loss: 0.2581 - val_accuracy: 0.9228\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3224 - accuracy: 0.8992 - val_loss: 0.2516 - val_accuracy: 0.9189\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3221 - accuracy: 0.8985 - val_loss: 0.2547 - val_accuracy: 0.9129\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3215 - accuracy: 0.8982 - val_loss: 0.2567 - val_accuracy: 0.9215\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3227 - accuracy: 0.8981 - val_loss: 0.2508 - val_accuracy: 0.9202\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 6s 3ms/step - loss: 0.3218 - accuracy: 0.8991 - val_loss: 0.2488 - val_accuracy: 0.9228\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3206 - accuracy: 0.8990 - val_loss: 0.2487 - val_accuracy: 0.9212\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3216 - accuracy: 0.8983 - val_loss: 0.2516 - val_accuracy: 0.9181\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3193 - accuracy: 0.9011 - val_loss: 0.2502 - val_accuracy: 0.9179\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3199 - accuracy: 0.8991 - val_loss: 0.2480 - val_accuracy: 0.9226\n",
      "Epoch 38/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3192 - accuracy: 0.8995 - val_loss: 0.2524 - val_accuracy: 0.9221\n",
      "Epoch 39/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3191 - accuracy: 0.9002 - val_loss: 0.2493 - val_accuracy: 0.9207\n",
      "Epoch 40/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3189 - accuracy: 0.8995 - val_loss: 0.2462 - val_accuracy: 0.9254\n",
      "Epoch 41/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3209 - accuracy: 0.8999 - val_loss: 0.2515 - val_accuracy: 0.9158\n",
      "Epoch 42/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3188 - accuracy: 0.9050 - val_loss: 0.2534 - val_accuracy: 0.9202\n",
      "Epoch 43/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3160 - accuracy: 0.9043 - val_loss: 0.2513 - val_accuracy: 0.9212\n",
      "Epoch 44/100\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.3193 - accuracy: 0.9001 - val_loss: 0.2521 - val_accuracy: 0.9180\n",
      "Epoch 45/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3184 - accuracy: 0.8999 - val_loss: 0.2524 - val_accuracy: 0.9167\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.2462 - accuracy: 0.9254\n",
      "Accuracy: 92.54%\n",
      "Tiempo total de entrenamiento: 327.82 segundos\n",
      "Pérdida: 0.31838178634643555\n",
      "Accuracy: 89.98733162879944\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Type of Travel', 'Class','Flight Distance', 'Inflight wifi service', 'Online boarding','Seat comfort','Inflight entertainment','On-board service', 'Leg room service', 'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "    Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "    Dropout(0.5),\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "    Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo6.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 7: Nuevos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 3s 929us/step - loss: 0.3657 - accuracy: 0.8487 - val_loss: 0.3417 - val_accuracy: 0.8570\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 2s 905us/step - loss: 0.3330 - accuracy: 0.8617 - val_loss: 0.3223 - val_accuracy: 0.8664\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 2s 888us/step - loss: 0.3211 - accuracy: 0.8664 - val_loss: 0.3235 - val_accuracy: 0.8669\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 2s 946us/step - loss: 0.3144 - accuracy: 0.8701 - val_loss: 0.3123 - val_accuracy: 0.8726\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 2s 891us/step - loss: 0.3102 - accuracy: 0.8721 - val_loss: 0.3071 - val_accuracy: 0.8724\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 2s 834us/step - loss: 0.3070 - accuracy: 0.8730 - val_loss: 0.3030 - val_accuracy: 0.8741\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 2s 897us/step - loss: 0.3051 - accuracy: 0.8746 - val_loss: 0.3037 - val_accuracy: 0.8728\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.3031 - accuracy: 0.8757 - val_loss: 0.3033 - val_accuracy: 0.8750\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 2s 930us/step - loss: 0.3018 - accuracy: 0.8759 - val_loss: 0.3068 - val_accuracy: 0.8748\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 2s 926us/step - loss: 0.3011 - accuracy: 0.8760 - val_loss: 0.2996 - val_accuracy: 0.8752\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 2s 912us/step - loss: 0.2993 - accuracy: 0.8779 - val_loss: 0.2978 - val_accuracy: 0.8771\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 3s 993us/step - loss: 0.2982 - accuracy: 0.8775 - val_loss: 0.3003 - val_accuracy: 0.8754\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 2s 894us/step - loss: 0.2979 - accuracy: 0.8778 - val_loss: 0.2986 - val_accuracy: 0.8771\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 2s 888us/step - loss: 0.2969 - accuracy: 0.8774 - val_loss: 0.2981 - val_accuracy: 0.8771\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 2s 930us/step - loss: 0.2965 - accuracy: 0.8779 - val_loss: 0.2980 - val_accuracy: 0.8782\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 2s 906us/step - loss: 0.2953 - accuracy: 0.8787 - val_loss: 0.2960 - val_accuracy: 0.8765\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 3s 997us/step - loss: 0.2953 - accuracy: 0.8789 - val_loss: 0.2950 - val_accuracy: 0.8766\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 2s 898us/step - loss: 0.2944 - accuracy: 0.8779 - val_loss: 0.2932 - val_accuracy: 0.8781\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2940 - accuracy: 0.8786 - val_loss: 0.2955 - val_accuracy: 0.8763\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.2938 - accuracy: 0.8785 - val_loss: 0.2926 - val_accuracy: 0.8779\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 2s 877us/step - loss: 0.2929 - accuracy: 0.8795 - val_loss: 0.2941 - val_accuracy: 0.8769\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 2s 914us/step - loss: 0.2923 - accuracy: 0.8788 - val_loss: 0.2957 - val_accuracy: 0.8754\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 2s 938us/step - loss: 0.2917 - accuracy: 0.8790 - val_loss: 0.2936 - val_accuracy: 0.8777\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 2s 848us/step - loss: 0.2917 - accuracy: 0.8798 - val_loss: 0.2948 - val_accuracy: 0.8778\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 2s 888us/step - loss: 0.2910 - accuracy: 0.8797 - val_loss: 0.2922 - val_accuracy: 0.8782\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 2s 911us/step - loss: 0.2901 - accuracy: 0.8805 - val_loss: 0.2932 - val_accuracy: 0.8764\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 2s 917us/step - loss: 0.2898 - accuracy: 0.8800 - val_loss: 0.2948 - val_accuracy: 0.8771\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 2s 880us/step - loss: 0.2899 - accuracy: 0.8800 - val_loss: 0.2933 - val_accuracy: 0.8776\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 2s 885us/step - loss: 0.2892 - accuracy: 0.8803 - val_loss: 0.2955 - val_accuracy: 0.8758\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 3s 975us/step - loss: 0.2888 - accuracy: 0.8808 - val_loss: 0.2904 - val_accuracy: 0.8785\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 2s 875us/step - loss: 0.2883 - accuracy: 0.8798 - val_loss: 0.2928 - val_accuracy: 0.8770\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 2s 902us/step - loss: 0.2885 - accuracy: 0.8803 - val_loss: 0.2945 - val_accuracy: 0.8774\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 2s 888us/step - loss: 0.2876 - accuracy: 0.8815 - val_loss: 0.2896 - val_accuracy: 0.8790\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 2s 843us/step - loss: 0.2874 - accuracy: 0.8816 - val_loss: 0.2993 - val_accuracy: 0.8742\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 2s 869us/step - loss: 0.2874 - accuracy: 0.8809 - val_loss: 0.2941 - val_accuracy: 0.8755\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 2s 874us/step - loss: 0.2872 - accuracy: 0.8814 - val_loss: 0.2924 - val_accuracy: 0.8779\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 2s 841us/step - loss: 0.2866 - accuracy: 0.8803 - val_loss: 0.2910 - val_accuracy: 0.8775\n",
      "Epoch 38/100\n",
      "2590/2590 [==============================] - 2s 894us/step - loss: 0.2865 - accuracy: 0.8815 - val_loss: 0.2884 - val_accuracy: 0.8777\n",
      "Epoch 39/100\n",
      "2590/2590 [==============================] - 2s 866us/step - loss: 0.2859 - accuracy: 0.8825 - val_loss: 0.2945 - val_accuracy: 0.8778\n",
      "Epoch 40/100\n",
      "2590/2590 [==============================] - 2s 839us/step - loss: 0.2856 - accuracy: 0.8819 - val_loss: 0.2886 - val_accuracy: 0.8807\n",
      "Epoch 41/100\n",
      "2590/2590 [==============================] - 2s 871us/step - loss: 0.2857 - accuracy: 0.8818 - val_loss: 0.2889 - val_accuracy: 0.8793\n",
      "Epoch 42/100\n",
      "2590/2590 [==============================] - 2s 882us/step - loss: 0.2854 - accuracy: 0.8817 - val_loss: 0.2882 - val_accuracy: 0.8807\n",
      "Epoch 43/100\n",
      "2590/2590 [==============================] - 2s 847us/step - loss: 0.2851 - accuracy: 0.8820 - val_loss: 0.2895 - val_accuracy: 0.8797\n",
      "Epoch 44/100\n",
      "2590/2590 [==============================] - 2s 906us/step - loss: 0.2852 - accuracy: 0.8824 - val_loss: 0.2875 - val_accuracy: 0.8805\n",
      "Epoch 45/100\n",
      "2590/2590 [==============================] - 2s 938us/step - loss: 0.2844 - accuracy: 0.8818 - val_loss: 0.2880 - val_accuracy: 0.8804\n",
      "Epoch 46/100\n",
      "2590/2590 [==============================] - 2s 903us/step - loss: 0.2844 - accuracy: 0.8819 - val_loss: 0.2882 - val_accuracy: 0.8795\n",
      "Epoch 47/100\n",
      "2590/2590 [==============================] - 2s 902us/step - loss: 0.2842 - accuracy: 0.8824 - val_loss: 0.2872 - val_accuracy: 0.8793\n",
      "Epoch 48/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2842 - accuracy: 0.8822 - val_loss: 0.2903 - val_accuracy: 0.8798\n",
      "Epoch 49/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2839 - accuracy: 0.8823 - val_loss: 0.2872 - val_accuracy: 0.8808\n",
      "Epoch 50/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2835 - accuracy: 0.8833 - val_loss: 0.2856 - val_accuracy: 0.8818\n",
      "Epoch 51/100\n",
      "2590/2590 [==============================] - 2s 873us/step - loss: 0.2831 - accuracy: 0.8830 - val_loss: 0.2893 - val_accuracy: 0.8792\n",
      "Epoch 52/100\n",
      "2590/2590 [==============================] - 2s 903us/step - loss: 0.2831 - accuracy: 0.8828 - val_loss: 0.2864 - val_accuracy: 0.8801\n",
      "Epoch 53/100\n",
      "2590/2590 [==============================] - 3s 984us/step - loss: 0.2828 - accuracy: 0.8831 - val_loss: 0.2894 - val_accuracy: 0.8823\n",
      "Epoch 54/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2828 - accuracy: 0.8829 - val_loss: 0.2854 - val_accuracy: 0.8815\n",
      "Epoch 55/100\n",
      "2590/2590 [==============================] - 2s 942us/step - loss: 0.2826 - accuracy: 0.8832 - val_loss: 0.2861 - val_accuracy: 0.8814\n",
      "Epoch 56/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2817 - accuracy: 0.8836 - val_loss: 0.2870 - val_accuracy: 0.8797\n",
      "Epoch 57/100\n",
      "2590/2590 [==============================] - 3s 983us/step - loss: 0.2820 - accuracy: 0.8838 - val_loss: 0.2850 - val_accuracy: 0.8805\n",
      "Epoch 58/100\n",
      "2590/2590 [==============================] - 3s 976us/step - loss: 0.2820 - accuracy: 0.8833 - val_loss: 0.2895 - val_accuracy: 0.8805\n",
      "Epoch 59/100\n",
      "2590/2590 [==============================] - 3s 974us/step - loss: 0.2815 - accuracy: 0.8836 - val_loss: 0.2880 - val_accuracy: 0.8789\n",
      "Epoch 60/100\n",
      "2590/2590 [==============================] - 2s 954us/step - loss: 0.2816 - accuracy: 0.8839 - val_loss: 0.2871 - val_accuracy: 0.8825\n",
      "Epoch 61/100\n",
      "2590/2590 [==============================] - 2s 933us/step - loss: 0.2811 - accuracy: 0.8842 - val_loss: 0.2876 - val_accuracy: 0.8800\n",
      "Epoch 62/100\n",
      "2590/2590 [==============================] - 3s 991us/step - loss: 0.2812 - accuracy: 0.8840 - val_loss: 0.2854 - val_accuracy: 0.8817\n",
      "648/648 [==============================] - 1s 837us/step - loss: 0.2850 - accuracy: 0.8805\n",
      "Accuracy: 88.05%\n",
      "Tiempo total de entrenamiento: 152.04 segundos\n",
      "Pérdida: 0.281152606010437\n",
      "Accuracy: 88.40060234069824\n"
     ]
    }
   ],
   "source": [
    "X = df_train_combined[['Age Cluster', 'Weight Comfort Seats', 'Mean Satisfaction Services',\n",
    "       'Sum Inflight Services', 'Space Seat and Class',\n",
    "       'Weight Basic Services']]\n",
    "y = df_train_combined['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('Modelo7.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 8: Nuevos features (+1 capa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 3s 927us/step - loss: 0.3635 - accuracy: 0.8479 - val_loss: 0.3420 - val_accuracy: 0.8553\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 2s 959us/step - loss: 0.3295 - accuracy: 0.8612 - val_loss: 0.3243 - val_accuracy: 0.8644\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 2s 846us/step - loss: 0.3188 - accuracy: 0.8660 - val_loss: 0.3149 - val_accuracy: 0.8693\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 2s 910us/step - loss: 0.3117 - accuracy: 0.8703 - val_loss: 0.3060 - val_accuracy: 0.8741\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 2s 921us/step - loss: 0.3072 - accuracy: 0.8724 - val_loss: 0.3023 - val_accuracy: 0.8732\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 2s 897us/step - loss: 0.3041 - accuracy: 0.8737 - val_loss: 0.3098 - val_accuracy: 0.8707\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 2s 917us/step - loss: 0.3012 - accuracy: 0.8756 - val_loss: 0.3026 - val_accuracy: 0.8759\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 2s 830us/step - loss: 0.2999 - accuracy: 0.8758 - val_loss: 0.3028 - val_accuracy: 0.8725\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 2s 875us/step - loss: 0.2979 - accuracy: 0.8766 - val_loss: 0.3045 - val_accuracy: 0.8727\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 2s 922us/step - loss: 0.2968 - accuracy: 0.8770 - val_loss: 0.2964 - val_accuracy: 0.8765\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 3s 986us/step - loss: 0.2952 - accuracy: 0.8789 - val_loss: 0.2977 - val_accuracy: 0.8779\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2948 - accuracy: 0.8782 - val_loss: 0.2941 - val_accuracy: 0.8795\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2933 - accuracy: 0.8785 - val_loss: 0.2961 - val_accuracy: 0.8767\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2925 - accuracy: 0.8788 - val_loss: 0.2911 - val_accuracy: 0.8779\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2921 - accuracy: 0.8789 - val_loss: 0.2919 - val_accuracy: 0.8775\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2913 - accuracy: 0.8793 - val_loss: 0.2911 - val_accuracy: 0.8785\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2903 - accuracy: 0.8794 - val_loss: 0.2918 - val_accuracy: 0.8801\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2903 - accuracy: 0.8797 - val_loss: 0.2946 - val_accuracy: 0.8769\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.2892 - accuracy: 0.8802 - val_loss: 0.2902 - val_accuracy: 0.8784\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2891 - accuracy: 0.8794 - val_loss: 0.2929 - val_accuracy: 0.8786\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2888 - accuracy: 0.8797 - val_loss: 0.2887 - val_accuracy: 0.8799\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2879 - accuracy: 0.8805 - val_loss: 0.2997 - val_accuracy: 0.8758\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2874 - accuracy: 0.8814 - val_loss: 0.2907 - val_accuracy: 0.8789\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2863 - accuracy: 0.8812 - val_loss: 0.2888 - val_accuracy: 0.8788\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2861 - accuracy: 0.8814 - val_loss: 0.2909 - val_accuracy: 0.8798\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2859 - accuracy: 0.8816 - val_loss: 0.2873 - val_accuracy: 0.8804\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2850 - accuracy: 0.8819 - val_loss: 0.2860 - val_accuracy: 0.8815\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2847 - accuracy: 0.8820 - val_loss: 0.2897 - val_accuracy: 0.8803\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2842 - accuracy: 0.8822 - val_loss: 0.2863 - val_accuracy: 0.8802\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2842 - accuracy: 0.8818 - val_loss: 0.2857 - val_accuracy: 0.8812\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2833 - accuracy: 0.8827 - val_loss: 0.2906 - val_accuracy: 0.8798\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2834 - accuracy: 0.8826 - val_loss: 0.2870 - val_accuracy: 0.8802\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2824 - accuracy: 0.8828 - val_loss: 0.2867 - val_accuracy: 0.8810\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2821 - accuracy: 0.8824 - val_loss: 0.2881 - val_accuracy: 0.8808\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2825 - accuracy: 0.8829 - val_loss: 0.2884 - val_accuracy: 0.8812\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.2857 - accuracy: 0.8812\n",
      "Accuracy: 88.12%\n",
      "Tiempo total de entrenamiento: 133.50 segundos\n",
      "Pérdida: 0.28246909379959106\n",
      "Accuracy: 88.29200863838196\n"
     ]
    }
   ],
   "source": [
    "X = df_train_combined[['Age Cluster', 'Weight Comfort Seats', 'Mean Satisfaction Services',\n",
    "       'Sum Inflight Services', 'Space Seat and Class',\n",
    "       'Weight Basic Services']]\n",
    "y = df_train_combined['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo8.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Customer Type', 'Age', 'Type of Travel', 'Class',\n",
       "       'Flight Distance', 'Inflight wifi service',\n",
       "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
       "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
       "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
       "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
       "       'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes',\n",
       "       'satisfaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dummie.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/2590 [..............................] - ETA: 24:53 - loss: 0.6950 - accuracy: 0.4688WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2449 - accuracy: 0.8973 - val_loss: 0.1939 - val_accuracy: 0.9196\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1804 - accuracy: 0.9260 - val_loss: 0.1632 - val_accuracy: 0.9346\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1565 - accuracy: 0.9355 - val_loss: 0.1502 - val_accuracy: 0.9392\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1434 - accuracy: 0.9400 - val_loss: 0.1430 - val_accuracy: 0.9421\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1367 - accuracy: 0.9429 - val_loss: 0.1379 - val_accuracy: 0.9441\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1327 - accuracy: 0.9438 - val_loss: 0.1352 - val_accuracy: 0.9426\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1292 - accuracy: 0.9456 - val_loss: 0.1318 - val_accuracy: 0.9456\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1263 - accuracy: 0.9465 - val_loss: 0.1326 - val_accuracy: 0.9452\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1246 - accuracy: 0.9479 - val_loss: 0.1285 - val_accuracy: 0.9463\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1222 - accuracy: 0.9491 - val_loss: 0.1279 - val_accuracy: 0.9442\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1213 - accuracy: 0.9488 - val_loss: 0.1264 - val_accuracy: 0.9468\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1191 - accuracy: 0.9504 - val_loss: 0.1274 - val_accuracy: 0.9469\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1177 - accuracy: 0.9498 - val_loss: 0.1251 - val_accuracy: 0.9472\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1159 - accuracy: 0.9510 - val_loss: 0.1224 - val_accuracy: 0.9478\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1150 - accuracy: 0.9507 - val_loss: 0.1276 - val_accuracy: 0.9466\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1141 - accuracy: 0.9519 - val_loss: 0.1219 - val_accuracy: 0.9496\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1129 - accuracy: 0.9520 - val_loss: 0.1231 - val_accuracy: 0.9463\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1126 - accuracy: 0.9523 - val_loss: 0.1229 - val_accuracy: 0.9474\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1109 - accuracy: 0.9530 - val_loss: 0.1210 - val_accuracy: 0.9493\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1102 - accuracy: 0.9532 - val_loss: 0.1240 - val_accuracy: 0.9465\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1090 - accuracy: 0.9536 - val_loss: 0.1222 - val_accuracy: 0.9487\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1081 - accuracy: 0.9540 - val_loss: 0.1216 - val_accuracy: 0.9489\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1078 - accuracy: 0.9539 - val_loss: 0.1174 - val_accuracy: 0.9509\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1074 - accuracy: 0.9540 - val_loss: 0.1204 - val_accuracy: 0.9484\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1057 - accuracy: 0.9553 - val_loss: 0.1200 - val_accuracy: 0.9478\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1053 - accuracy: 0.9550 - val_loss: 0.1176 - val_accuracy: 0.9503\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1047 - accuracy: 0.9555 - val_loss: 0.1179 - val_accuracy: 0.9509\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1041 - accuracy: 0.9554 - val_loss: 0.1194 - val_accuracy: 0.9492\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.1174 - accuracy: 0.9509\n",
      "Accuracy: 95.09%\n",
      "Tiempo total de entrenamiento: 149.59 segundos\n",
      "Pérdida: 0.10411404073238373\n",
      "Accuracy: 95.54389119148254\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Class','Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo9.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2652 - accuracy: 0.8879 - val_loss: 0.1960 - val_accuracy: 0.9184\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1820 - accuracy: 0.9258 - val_loss: 0.1674 - val_accuracy: 0.9316\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1584 - accuracy: 0.9348 - val_loss: 0.1504 - val_accuracy: 0.9363\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1483 - accuracy: 0.9379 - val_loss: 0.1436 - val_accuracy: 0.9402\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1428 - accuracy: 0.9403 - val_loss: 0.1408 - val_accuracy: 0.9398\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1398 - accuracy: 0.9413 - val_loss: 0.1390 - val_accuracy: 0.9412\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1377 - accuracy: 0.9419 - val_loss: 0.1402 - val_accuracy: 0.9390\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1350 - accuracy: 0.9431 - val_loss: 0.1372 - val_accuracy: 0.9428\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1335 - accuracy: 0.9437 - val_loss: 0.1349 - val_accuracy: 0.9431\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1319 - accuracy: 0.9441 - val_loss: 0.1341 - val_accuracy: 0.9433\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1301 - accuracy: 0.9452 - val_loss: 0.1344 - val_accuracy: 0.9427\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1289 - accuracy: 0.9452 - val_loss: 0.1304 - val_accuracy: 0.9448\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1280 - accuracy: 0.9459 - val_loss: 0.1314 - val_accuracy: 0.9439\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1265 - accuracy: 0.9464 - val_loss: 0.1321 - val_accuracy: 0.9431\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1258 - accuracy: 0.9467 - val_loss: 0.1310 - val_accuracy: 0.9437\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1251 - accuracy: 0.9467 - val_loss: 0.1307 - val_accuracy: 0.9447\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1236 - accuracy: 0.9466 - val_loss: 0.1264 - val_accuracy: 0.9464\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1230 - accuracy: 0.9477 - val_loss: 0.1258 - val_accuracy: 0.9464\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1225 - accuracy: 0.9478 - val_loss: 0.1267 - val_accuracy: 0.9461\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1220 - accuracy: 0.9476 - val_loss: 0.1274 - val_accuracy: 0.9460\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1213 - accuracy: 0.9488 - val_loss: 0.1268 - val_accuracy: 0.9464\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1203 - accuracy: 0.9490 - val_loss: 0.1254 - val_accuracy: 0.9470\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1199 - accuracy: 0.9490 - val_loss: 0.1258 - val_accuracy: 0.9459\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1191 - accuracy: 0.9495 - val_loss: 0.1255 - val_accuracy: 0.9461\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1183 - accuracy: 0.9500 - val_loss: 0.1260 - val_accuracy: 0.9462\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1176 - accuracy: 0.9497 - val_loss: 0.1243 - val_accuracy: 0.9459\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1170 - accuracy: 0.9501 - val_loss: 0.1254 - val_accuracy: 0.9472\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 12s 5ms/step - loss: 0.1166 - accuracy: 0.9500 - val_loss: 0.1240 - val_accuracy: 0.9478\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1159 - accuracy: 0.9505 - val_loss: 0.1232 - val_accuracy: 0.9464\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1154 - accuracy: 0.9505 - val_loss: 0.1225 - val_accuracy: 0.9472\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1154 - accuracy: 0.9506 - val_loss: 0.1235 - val_accuracy: 0.9485\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1145 - accuracy: 0.9509 - val_loss: 0.1221 - val_accuracy: 0.9473\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1137 - accuracy: 0.9516 - val_loss: 0.1250 - val_accuracy: 0.9459\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1139 - accuracy: 0.9517 - val_loss: 0.1238 - val_accuracy: 0.9470\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1134 - accuracy: 0.9515 - val_loss: 0.1221 - val_accuracy: 0.9480\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1127 - accuracy: 0.9516 - val_loss: 0.1237 - val_accuracy: 0.9477\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1125 - accuracy: 0.9520 - val_loss: 0.1249 - val_accuracy: 0.9482\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.1221 - accuracy: 0.9473\n",
      "Accuracy: 94.73%\n",
      "Tiempo total de entrenamiento: 196.39 segundos\n",
      "Pérdida: 0.11252495646476746\n",
      "Accuracy: 95.20120620727539\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Class','Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo10.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2311 - accuracy: 0.9050 - val_loss: 0.1773 - val_accuracy: 0.9270\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1653 - accuracy: 0.9319 - val_loss: 0.1510 - val_accuracy: 0.9391\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1466 - accuracy: 0.9391 - val_loss: 0.1383 - val_accuracy: 0.9428\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1375 - accuracy: 0.9433 - val_loss: 0.1329 - val_accuracy: 0.9460\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1310 - accuracy: 0.9452 - val_loss: 0.1274 - val_accuracy: 0.9471\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1258 - accuracy: 0.9476 - val_loss: 0.1266 - val_accuracy: 0.9468\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1224 - accuracy: 0.9485 - val_loss: 0.1271 - val_accuracy: 0.9447\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1193 - accuracy: 0.9495 - val_loss: 0.1316 - val_accuracy: 0.9403\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1167 - accuracy: 0.9506 - val_loss: 0.1241 - val_accuracy: 0.9460\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1147 - accuracy: 0.9510 - val_loss: 0.1185 - val_accuracy: 0.9492\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1130 - accuracy: 0.9520 - val_loss: 0.1184 - val_accuracy: 0.9491\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1109 - accuracy: 0.9530 - val_loss: 0.1180 - val_accuracy: 0.9488\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1094 - accuracy: 0.9531 - val_loss: 0.1198 - val_accuracy: 0.9491\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1080 - accuracy: 0.9538 - val_loss: 0.1176 - val_accuracy: 0.9478\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1064 - accuracy: 0.9553 - val_loss: 0.1184 - val_accuracy: 0.9491\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1049 - accuracy: 0.9552 - val_loss: 0.1153 - val_accuracy: 0.9511\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1046 - accuracy: 0.9548 - val_loss: 0.1137 - val_accuracy: 0.9515\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1029 - accuracy: 0.9556 - val_loss: 0.1147 - val_accuracy: 0.9509\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1019 - accuracy: 0.9564 - val_loss: 0.1179 - val_accuracy: 0.9511\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1005 - accuracy: 0.9574 - val_loss: 0.1135 - val_accuracy: 0.9501\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0997 - accuracy: 0.9571 - val_loss: 0.1148 - val_accuracy: 0.9511\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0989 - accuracy: 0.9583 - val_loss: 0.1124 - val_accuracy: 0.9507\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0987 - accuracy: 0.9575 - val_loss: 0.1121 - val_accuracy: 0.9525\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0979 - accuracy: 0.9580 - val_loss: 0.1132 - val_accuracy: 0.9486\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0964 - accuracy: 0.9589 - val_loss: 0.1175 - val_accuracy: 0.9515\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0966 - accuracy: 0.9582 - val_loss: 0.1145 - val_accuracy: 0.9524\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0959 - accuracy: 0.9587 - val_loss: 0.1134 - val_accuracy: 0.9522\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0954 - accuracy: 0.9593 - val_loss: 0.1130 - val_accuracy: 0.9498\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.1121 - accuracy: 0.9525\n",
      "Accuracy: 95.25%\n",
      "Tiempo total de entrenamiento: 144.97 segundos\n",
      "Pérdida: 0.09539733827114105\n",
      "Accuracy: 95.930016040802\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Class','Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo11.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2179 - accuracy: 0.9095 - val_loss: 0.1655 - val_accuracy: 0.9333\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1519 - accuracy: 0.9371 - val_loss: 0.1426 - val_accuracy: 0.9414\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1382 - accuracy: 0.9421 - val_loss: 0.1391 - val_accuracy: 0.9406\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1316 - accuracy: 0.9443 - val_loss: 0.1304 - val_accuracy: 0.9432\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1268 - accuracy: 0.9461 - val_loss: 0.1280 - val_accuracy: 0.9448\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1226 - accuracy: 0.9482 - val_loss: 0.1255 - val_accuracy: 0.9480\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1185 - accuracy: 0.9494 - val_loss: 0.1218 - val_accuracy: 0.9480\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1161 - accuracy: 0.9505 - val_loss: 0.1234 - val_accuracy: 0.9484\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1137 - accuracy: 0.9514 - val_loss: 0.1201 - val_accuracy: 0.9473\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1116 - accuracy: 0.9533 - val_loss: 0.1185 - val_accuracy: 0.9499\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1096 - accuracy: 0.9532 - val_loss: 0.1196 - val_accuracy: 0.9499\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1077 - accuracy: 0.9534 - val_loss: 0.1217 - val_accuracy: 0.9500\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1069 - accuracy: 0.9536 - val_loss: 0.1257 - val_accuracy: 0.9499\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1042 - accuracy: 0.9554 - val_loss: 0.1199 - val_accuracy: 0.9477\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1039 - accuracy: 0.9558 - val_loss: 0.1183 - val_accuracy: 0.9479\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1028 - accuracy: 0.9558 - val_loss: 0.1172 - val_accuracy: 0.9502\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1011 - accuracy: 0.9565 - val_loss: 0.1187 - val_accuracy: 0.9493\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0993 - accuracy: 0.9572 - val_loss: 0.1197 - val_accuracy: 0.9505\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0993 - accuracy: 0.9578 - val_loss: 0.1156 - val_accuracy: 0.9524\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0982 - accuracy: 0.9576 - val_loss: 0.1175 - val_accuracy: 0.9523\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0962 - accuracy: 0.9588 - val_loss: 0.1287 - val_accuracy: 0.9509\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0956 - accuracy: 0.9590 - val_loss: 0.1179 - val_accuracy: 0.9506\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0942 - accuracy: 0.9598 - val_loss: 0.1167 - val_accuracy: 0.9516\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0937 - accuracy: 0.9600 - val_loss: 0.1191 - val_accuracy: 0.9528\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.1156 - accuracy: 0.9524\n",
      "Accuracy: 95.24%\n",
      "Tiempo total de entrenamiento: 122.22 segundos\n",
      "Pérdida: 0.09372900426387787\n",
      "Accuracy: 96.00241184234619\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Class','Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo12.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2129 - accuracy: 0.9140 - val_loss: 0.1621 - val_accuracy: 0.9332\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1481 - accuracy: 0.9400 - val_loss: 0.1412 - val_accuracy: 0.9438\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1337 - accuracy: 0.9451 - val_loss: 0.1279 - val_accuracy: 0.9466\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1256 - accuracy: 0.9485 - val_loss: 0.1231 - val_accuracy: 0.9485\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1205 - accuracy: 0.9498 - val_loss: 0.1209 - val_accuracy: 0.9485\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1168 - accuracy: 0.9518 - val_loss: 0.1201 - val_accuracy: 0.9483\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.1145 - accuracy: 0.9525 - val_loss: 0.1164 - val_accuracy: 0.9503\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1122 - accuracy: 0.9535 - val_loss: 0.1154 - val_accuracy: 0.9482\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1098 - accuracy: 0.9543 - val_loss: 0.1145 - val_accuracy: 0.9495\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1089 - accuracy: 0.9544 - val_loss: 0.1157 - val_accuracy: 0.9508\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1075 - accuracy: 0.9556 - val_loss: 0.1149 - val_accuracy: 0.9508\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1060 - accuracy: 0.9556 - val_loss: 0.1125 - val_accuracy: 0.9521\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1049 - accuracy: 0.9561 - val_loss: 0.1113 - val_accuracy: 0.9528\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9562 - val_loss: 0.1154 - val_accuracy: 0.9531\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1031 - accuracy: 0.9565 - val_loss: 0.1101 - val_accuracy: 0.9547\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1021 - accuracy: 0.9568 - val_loss: 0.1129 - val_accuracy: 0.9538\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1010 - accuracy: 0.9572 - val_loss: 0.1116 - val_accuracy: 0.9504\n",
      "Epoch 18/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1006 - accuracy: 0.9577 - val_loss: 0.1120 - val_accuracy: 0.9531\n",
      "Epoch 19/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0993 - accuracy: 0.9587 - val_loss: 0.1091 - val_accuracy: 0.9538\n",
      "Epoch 20/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0990 - accuracy: 0.9579 - val_loss: 0.1093 - val_accuracy: 0.9551\n",
      "Epoch 21/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0978 - accuracy: 0.9591 - val_loss: 0.1101 - val_accuracy: 0.9555\n",
      "Epoch 22/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0974 - accuracy: 0.9589 - val_loss: 0.1074 - val_accuracy: 0.9545\n",
      "Epoch 23/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0967 - accuracy: 0.9593 - val_loss: 0.1159 - val_accuracy: 0.9501\n",
      "Epoch 24/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0962 - accuracy: 0.9596 - val_loss: 0.1079 - val_accuracy: 0.9565\n",
      "Epoch 25/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0958 - accuracy: 0.9599 - val_loss: 0.1083 - val_accuracy: 0.9547\n",
      "Epoch 26/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0957 - accuracy: 0.9600 - val_loss: 0.1055 - val_accuracy: 0.9552\n",
      "Epoch 27/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0947 - accuracy: 0.9597 - val_loss: 0.1070 - val_accuracy: 0.9533\n",
      "Epoch 28/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0942 - accuracy: 0.9600 - val_loss: 0.1080 - val_accuracy: 0.9558\n",
      "Epoch 29/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0941 - accuracy: 0.9601 - val_loss: 0.1084 - val_accuracy: 0.9551\n",
      "Epoch 30/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0935 - accuracy: 0.9604 - val_loss: 0.1054 - val_accuracy: 0.9551\n",
      "Epoch 31/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0923 - accuracy: 0.9607 - val_loss: 0.1067 - val_accuracy: 0.9547\n",
      "Epoch 32/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0919 - accuracy: 0.9615 - val_loss: 0.1094 - val_accuracy: 0.9553\n",
      "Epoch 33/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0920 - accuracy: 0.9610 - val_loss: 0.1078 - val_accuracy: 0.9525\n",
      "Epoch 34/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0915 - accuracy: 0.9613 - val_loss: 0.1050 - val_accuracy: 0.9563\n",
      "Epoch 35/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0906 - accuracy: 0.9613 - val_loss: 0.1138 - val_accuracy: 0.9535\n",
      "Epoch 36/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0902 - accuracy: 0.9618 - val_loss: 0.1063 - val_accuracy: 0.9531\n",
      "Epoch 37/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0900 - accuracy: 0.9623 - val_loss: 0.1057 - val_accuracy: 0.9569\n",
      "Epoch 38/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0897 - accuracy: 0.9619 - val_loss: 0.1047 - val_accuracy: 0.9575\n",
      "Epoch 39/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0891 - accuracy: 0.9619 - val_loss: 0.1075 - val_accuracy: 0.9566\n",
      "Epoch 40/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0884 - accuracy: 0.9623 - val_loss: 0.1059 - val_accuracy: 0.9557\n",
      "Epoch 41/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0886 - accuracy: 0.9620 - val_loss: 0.1075 - val_accuracy: 0.9563\n",
      "Epoch 42/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0876 - accuracy: 0.9623 - val_loss: 0.1051 - val_accuracy: 0.9554\n",
      "Epoch 43/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0874 - accuracy: 0.9629 - val_loss: 0.1038 - val_accuracy: 0.9545\n",
      "Epoch 44/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0872 - accuracy: 0.9625 - val_loss: 0.1049 - val_accuracy: 0.9559\n",
      "Epoch 45/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0867 - accuracy: 0.9626 - val_loss: 0.1086 - val_accuracy: 0.9544\n",
      "Epoch 46/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0861 - accuracy: 0.9631 - val_loss: 0.1067 - val_accuracy: 0.9564\n",
      "Epoch 47/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0860 - accuracy: 0.9634 - val_loss: 0.1057 - val_accuracy: 0.9556\n",
      "Epoch 48/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0858 - accuracy: 0.9635 - val_loss: 0.1061 - val_accuracy: 0.9570\n",
      "648/648 [==============================] - 1s 986us/step - loss: 0.1038 - accuracy: 0.9545\n",
      "Accuracy: 95.45%\n",
      "Tiempo total de entrenamiento: 223.02 segundos\n",
      "Pérdida: 0.08579139411449432\n",
      "Accuracy: 96.34509682655334\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Class','Type of Travel','Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo13.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1982 - accuracy: 0.9200 - val_loss: 0.1505 - val_accuracy: 0.9396\n",
      "Epoch 2/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1434 - accuracy: 0.9414 - val_loss: 0.1318 - val_accuracy: 0.9474\n",
      "Epoch 3/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1280 - accuracy: 0.9472 - val_loss: 0.1241 - val_accuracy: 0.9498\n",
      "Epoch 4/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1200 - accuracy: 0.9504 - val_loss: 0.1202 - val_accuracy: 0.9502\n",
      "Epoch 5/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1141 - accuracy: 0.9528 - val_loss: 0.1190 - val_accuracy: 0.9514\n",
      "Epoch 6/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1105 - accuracy: 0.9543 - val_loss: 0.1171 - val_accuracy: 0.9525\n",
      "Epoch 7/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1070 - accuracy: 0.9561 - val_loss: 0.1146 - val_accuracy: 0.9544\n",
      "Epoch 8/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1043 - accuracy: 0.9563 - val_loss: 0.1120 - val_accuracy: 0.9532\n",
      "Epoch 9/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1019 - accuracy: 0.9574 - val_loss: 0.1064 - val_accuracy: 0.9567\n",
      "Epoch 10/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0996 - accuracy: 0.9590 - val_loss: 0.1038 - val_accuracy: 0.9563\n",
      "Epoch 11/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0979 - accuracy: 0.9592 - val_loss: 0.1039 - val_accuracy: 0.9568\n",
      "Epoch 12/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0959 - accuracy: 0.9598 - val_loss: 0.1037 - val_accuracy: 0.9581\n",
      "Epoch 13/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0944 - accuracy: 0.9603 - val_loss: 0.1040 - val_accuracy: 0.9576\n",
      "Epoch 14/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0927 - accuracy: 0.9609 - val_loss: 0.1055 - val_accuracy: 0.9565\n",
      "Epoch 15/100\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0914 - accuracy: 0.9615 - val_loss: 0.1046 - val_accuracy: 0.9569\n",
      "Epoch 16/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0901 - accuracy: 0.9618 - val_loss: 0.1051 - val_accuracy: 0.9575\n",
      "Epoch 17/100\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0888 - accuracy: 0.9621 - val_loss: 0.1046 - val_accuracy: 0.9595\n",
      "648/648 [==============================] - 1s 1ms/step - loss: 0.1037 - accuracy: 0.9581\n",
      "Accuracy: 95.81%\n",
      "Tiempo total de entrenamiento: 76.00 segundos\n",
      "Pérdida: 0.08881107717752457\n",
      "Accuracy: 96.21115922927856\n"
     ]
    }
   ],
   "source": [
    "X = df_train_dummie[['Class','Type of Travel','Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness']]\n",
    "y = df_train_dummie['satisfaction']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[time_callback, early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "model.save('../Modelos/Modelo14.h5')\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy: {accuracy[-1]*100}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorenviron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
