{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks, optimizers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('valoracion_aerolineas.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/dataset')\n",
    "\n",
    "df_train = pd.read_csv('/content/dataset/train.csv')\n",
    "df_test = pd.read_csv('/content/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>...</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Inflight service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>13</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco Plus</td>\n",
       "      <td>460</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>18.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>26</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1142</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>562</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>61</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103899</th>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>23</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103900</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>2347</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103901</th>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>30</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103902</th>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>22</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103903</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>27</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1723</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103594 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender      Customer Type  Age   Type of Travel     Class  \\\n",
       "0         Male     Loyal Customer   13  Personal Travel  Eco Plus   \n",
       "1         Male  disloyal Customer   25  Business travel  Business   \n",
       "2       Female     Loyal Customer   26  Business travel  Business   \n",
       "3       Female     Loyal Customer   25  Business travel  Business   \n",
       "4         Male     Loyal Customer   61  Business travel  Business   \n",
       "...        ...                ...  ...              ...       ...   \n",
       "103899  Female  disloyal Customer   23  Business travel       Eco   \n",
       "103900    Male     Loyal Customer   49  Business travel  Business   \n",
       "103901    Male  disloyal Customer   30  Business travel  Business   \n",
       "103902  Female  disloyal Customer   22  Business travel       Eco   \n",
       "103903    Male     Loyal Customer   27  Business travel  Business   \n",
       "\n",
       "        Flight Distance  Inflight wifi service  \\\n",
       "0                   460                      3   \n",
       "1                   235                      3   \n",
       "2                  1142                      2   \n",
       "3                   562                      2   \n",
       "4                   214                      3   \n",
       "...                 ...                    ...   \n",
       "103899              192                      2   \n",
       "103900             2347                      4   \n",
       "103901             1995                      1   \n",
       "103902             1000                      1   \n",
       "103903             1723                      1   \n",
       "\n",
       "        Departure/Arrival time convenient  Ease of Online booking  \\\n",
       "0                                       4                       3   \n",
       "1                                       2                       3   \n",
       "2                                       2                       2   \n",
       "3                                       5                       5   \n",
       "4                                       3                       3   \n",
       "...                                   ...                     ...   \n",
       "103899                                  1                       2   \n",
       "103900                                  4                       4   \n",
       "103901                                  1                       1   \n",
       "103902                                  1                       1   \n",
       "103903                                  3                       3   \n",
       "\n",
       "        Gate location  ...  Inflight entertainment  On-board service  \\\n",
       "0                   1  ...                       5                 4   \n",
       "1                   3  ...                       1                 1   \n",
       "2                   2  ...                       5                 4   \n",
       "3                   5  ...                       2                 2   \n",
       "4                   3  ...                       3                 3   \n",
       "...               ...  ...                     ...               ...   \n",
       "103899              3  ...                       2                 3   \n",
       "103900              4  ...                       5                 5   \n",
       "103901              3  ...                       4                 3   \n",
       "103902              5  ...                       1                 4   \n",
       "103903              3  ...                       1                 1   \n",
       "\n",
       "        Leg room service  Baggage handling  Checkin service  Inflight service  \\\n",
       "0                      3                 4                4                 5   \n",
       "1                      5                 3                1                 4   \n",
       "2                      3                 4                4                 4   \n",
       "3                      5                 3                1                 4   \n",
       "4                      4                 4                3                 3   \n",
       "...                  ...               ...              ...               ...   \n",
       "103899                 1                 4                2                 3   \n",
       "103900                 5                 5                5                 5   \n",
       "103901                 2                 4                5                 5   \n",
       "103902                 5                 1                5                 4   \n",
       "103903                 1                 4                4                 3   \n",
       "\n",
       "        Cleanliness  Departure Delay in Minutes  Arrival Delay in Minutes  \\\n",
       "0                 5                          25                      18.0   \n",
       "1                 1                           1                       6.0   \n",
       "2                 5                           0                       0.0   \n",
       "3                 2                          11                       9.0   \n",
       "4                 3                           0                       0.0   \n",
       "...             ...                         ...                       ...   \n",
       "103899            2                           3                       0.0   \n",
       "103900            4                           0                       0.0   \n",
       "103901            4                           7                      14.0   \n",
       "103902            1                           0                       0.0   \n",
       "103903            1                           0                       0.0   \n",
       "\n",
       "                   satisfaction  \n",
       "0       neutral or dissatisfied  \n",
       "1       neutral or dissatisfied  \n",
       "2                     satisfied  \n",
       "3       neutral or dissatisfied  \n",
       "4                     satisfied  \n",
       "...                         ...  \n",
       "103899  neutral or dissatisfied  \n",
       "103900                satisfied  \n",
       "103901  neutral or dissatisfied  \n",
       "103902  neutral or dissatisfied  \n",
       "103903  neutral or dissatisfied  \n",
       "\n",
       "[103594 rows x 23 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_train = df_train.drop(columns=['Unnamed: 0', 'id'])\n",
    "df_test = df_test.dropna()\n",
    "df_test = df_test.drop(columns=['Unnamed: 0', 'id'])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dummie = df_train.copy()\n",
    "\n",
    "# Aplicar Label Encoding a las columnas categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df_train_dummie.select_dtypes(include=['object']).columns:\n",
    "    df_train_dummie[column] = label_encoder.fit_transform(df_train_dummie[column])\n",
    "\n",
    "df_test_dummie = df_test.copy()\n",
    "\n",
    "# Aplicar Label Encoding a las columnas categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df_test_dummie.select_dtypes(include=['object']).columns:\n",
    "    df_test_dummie[column] = label_encoder.fit_transform(df_test_dummie[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_selected = df_train_dummie[['Type of Travel','Class','Online boarding','satisfaction']]\n",
    "df_test_selected = df_test_dummie[['Type of Travel','Class','Online boarding','satisfaction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age cluster\n",
    "df_train_new_features = pd.DataFrame()\n",
    "age_bins = [7,18,26,33,40,47,54,63,86]\n",
    "df_train_new_features['Age Cluster'] = pd.cut(df_train_dummie['Age'], bins=age_bins, labels=False, right=False)\n",
    "\n",
    "# Weight Comfort Seats\n",
    "df_train_new_features['Weight Comfort Seats'] = (df_train_dummie['Seat comfort']/5 + df_train_dummie['Class'] + df_train_dummie['Type of Travel'])\n",
    "\n",
    "# Media de todos los servicios que tienen valor del 0-5\n",
    "df_train_new_features['Mean Satisfaction Services'] = df_train_dummie[['Inflight wifi service','Departure/Arrival time convenient','Ease of Online booking','Gate location','Food and drink',\n",
    "                                  'Online boarding','Seat comfort','Inflight entertainment','On-board service','Leg room service','Baggage handling','Checkin service','Inflight service','Cleanliness']].mean(axis=1)\n",
    "\n",
    "# Suma del Servicio en Vuelo\n",
    "df_train_new_features['Sum Inflight Services'] = df_train_dummie['Inflight wifi service'] + df_train_dummie['Inflight service'] + df_train_dummie['Inflight entertainment'] + df_train_dummie['Online boarding']\n",
    "\n",
    "# Peso sobre el espacio de los pies según la clase\n",
    "df_train_new_features['Space Seat and Class'] = (df_train_dummie['Class'] * df_train_dummie['Leg room service']) / 5\n",
    "\n",
    "# suma de servicios básicos\n",
    "df_train_new_features['Weight Basic Services'] = df_train_dummie['Class'] + (df_train_dummie['Food and drink'] + df_train_dummie['Cleanliness'])/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age clister\n",
    "df_test_new_features = pd.DataFrame()\n",
    "age_bins = [7,18,26,33,40,47,54,63,86]\n",
    "df_test_new_features['Age Cluster'] = pd.cut(df_test['Age'], bins=age_bins, labels=False, right=False)\n",
    "\n",
    "# Weight Comfort Seats\n",
    "df_test_new_features['Weight Comfort Seats'] = (df_test_dummie['Seat comfort']/5 + df_test_dummie['Class'] + df_test_dummie['Type of Travel'])\n",
    "\n",
    "# Media de todos los servicios que tienen valor del 0-5\n",
    "df_test_new_features['Mean Satisfaction Services'] = df_test_dummie[['Inflight wifi service','Departure/Arrival time convenient','Ease of Online booking','Gate location','Food and drink',\n",
    "                                  'Online boarding','Seat comfort','Inflight entertainment','On-board service','Leg room service','Baggage handling','Checkin service','Inflight service','Cleanliness']].mean(axis=1)\n",
    "\n",
    "# Suma del Servicio en Vuelo\n",
    "df_test_new_features['Sum Inflight Services'] = df_test_dummie['Inflight wifi service'] + df_test_dummie['Inflight service'] + df_test_dummie['Inflight entertainment'] + df_test_dummie['Online boarding']\n",
    "\n",
    "# Peso sobre el espacio de los pies según la clase\n",
    "df_test_new_features['Space Seat and Class'] = (df_test_dummie['Class'] * df_test_dummie['Leg room service']) / 5\n",
    "\n",
    "# suma de servicios básicos\n",
    "df_test_new_features['Weight Basic Services'] = df_test_dummie['Class'] + (df_test_dummie['Food and drink'] + df_test_dummie['Cleanliness'])/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined = pd.concat([df_train_selected, df_train_new_features], axis=1)\n",
    "\n",
    "# Eliminar las columnas duplicadas si es necesario\n",
    "df_train_combined = df_train_combined.loc[:, ~df_train_combined.columns.duplicated()]\n",
    "\n",
    "df_test_combined = pd.concat([df_test_selected, df_test_new_features], axis=1)\n",
    "df_test_combined = df_test_combined.loc[:, ~df_test_combined.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un callback personalizado para medir el tiempo de entrenamiento\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.times = []\n",
    "        self.train_start_time = time.time()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.times.append(time.time() - self.epoch_start_time)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.total_train_time = time.time() - self.train_start_time\n",
    "        \n",
    "time_callback = TimeHistory()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 1: Valores sin análisis previo\n",
    "- Inputs: Todo el data set (dummie)\n",
    "- Epochs = 100\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 relu\n",
    "- 3ra capa = 1 sigmoid\n",
    "- learning_rate=0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 3s 978us/step - loss: 0.1994 - accuracy: 0.9190 - val_loss: 0.1414 - val_accuracy: 0.9401 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 2s 895us/step - loss: 0.1358 - accuracy: 0.9442 - val_loss: 0.1196 - val_accuracy: 0.9499 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.1173 - accuracy: 0.9513 - val_loss: 0.1120 - val_accuracy: 0.9547 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.1076 - accuracy: 0.9548 - val_loss: 0.1060 - val_accuracy: 0.9543 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 9s 4ms/step - loss: 0.1022 - accuracy: 0.9568 - val_loss: 0.1014 - val_accuracy: 0.9590 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0971 - accuracy: 0.9588 - val_loss: 0.0975 - val_accuracy: 0.9586 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 2s 843us/step - loss: 0.0942 - accuracy: 0.9594 - val_loss: 0.0977 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 2s 878us/step - loss: 0.0918 - accuracy: 0.9607 - val_loss: 0.0953 - val_accuracy: 0.9572 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 3s 989us/step - loss: 0.0899 - accuracy: 0.9616 - val_loss: 0.0920 - val_accuracy: 0.9611 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0876 - accuracy: 0.9617 - val_loss: 0.0964 - val_accuracy: 0.9604 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.0866 - accuracy: 0.9629 - val_loss: 0.0916 - val_accuracy: 0.9617 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.0848 - accuracy: 0.9632 - val_loss: 0.0926 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.0838 - accuracy: 0.9633 - val_loss: 0.0929 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 4s 1ms/step - loss: 0.0832 - accuracy: 0.9632 - val_loss: 0.0993 - val_accuracy: 0.9540 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.0816 - accuracy: 0.9648 - val_loss: 0.0901 - val_accuracy: 0.9610 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.0808 - accuracy: 0.9642 - val_loss: 0.0909 - val_accuracy: 0.9619 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.0803 - accuracy: 0.9649 - val_loss: 0.0904 - val_accuracy: 0.9622 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 2s 855us/step - loss: 0.0794 - accuracy: 0.9653 - val_loss: 0.0914 - val_accuracy: 0.9603 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 2s 903us/step - loss: 0.0786 - accuracy: 0.9659 - val_loss: 0.0921 - val_accuracy: 0.9612 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 2s 846us/step - loss: 0.0779 - accuracy: 0.9660 - val_loss: 0.0928 - val_accuracy: 0.9615 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 2s 862us/step - loss: 0.0713 - accuracy: 0.9688 - val_loss: 0.0896 - val_accuracy: 0.9623 - lr: 2.0000e-04\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 2s 912us/step - loss: 0.0700 - accuracy: 0.9694 - val_loss: 0.0892 - val_accuracy: 0.9608 - lr: 2.0000e-04\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 2s 906us/step - loss: 0.0694 - accuracy: 0.9698 - val_loss: 0.0898 - val_accuracy: 0.9610 - lr: 2.0000e-04\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 2s 878us/step - loss: 0.0691 - accuracy: 0.9701 - val_loss: 0.0902 - val_accuracy: 0.9604 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 2s 827us/step - loss: 0.0686 - accuracy: 0.9697 - val_loss: 0.0914 - val_accuracy: 0.9593 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 2s 960us/step - loss: 0.0684 - accuracy: 0.9702 - val_loss: 0.0906 - val_accuracy: 0.9610 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 2s 913us/step - loss: 0.0682 - accuracy: 0.9700 - val_loss: 0.0905 - val_accuracy: 0.9603 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 2s 853us/step - loss: 0.0665 - accuracy: 0.9709 - val_loss: 0.0900 - val_accuracy: 0.9611 - lr: 4.0000e-05\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 2s 838us/step - loss: 0.0662 - accuracy: 0.9710 - val_loss: 0.0902 - val_accuracy: 0.9608 - lr: 4.0000e-05\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 2s 916us/step - loss: 0.0661 - accuracy: 0.9712 - val_loss: 0.0902 - val_accuracy: 0.9612 - lr: 4.0000e-05\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 3s 989us/step - loss: 0.0661 - accuracy: 0.9714 - val_loss: 0.0903 - val_accuracy: 0.9611 - lr: 4.0000e-05\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 2s 960us/step - loss: 0.0660 - accuracy: 0.9715 - val_loss: 0.0903 - val_accuracy: 0.9610 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_dummie.drop('satisfaction', axis=1)\n",
    "y_train = df_train_dummie['satisfaction']\n",
    "\n",
    "X_test = df_test_dummie.drop('satisfaction', axis=1)\n",
    "y_test = df_test_dummie['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Capas\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Hiperparámetros\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Recalls\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m1.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "# Modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 129.60 segundos\n",
      "Pérdida: 0.0660059005022049\n",
      "Accuracy Modelo: 97.14509844779968\n",
      "Recall: 0.9456225252969643\n",
      "Specificity: 0.5707334\n",
      "F1-Score: 0.9561387900355872\n",
      "Precisión: 0.9668915879442195\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m1.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 2: Correlativa Individual\n",
    "- Inputs: 'Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service',\"Cleanliness\"\n",
    "- Epochs = 50\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 relu\n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate=0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 3s 944us/step - loss: 0.2931 - accuracy: 0.8818 - val_loss: 0.2595 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 2s 888us/step - loss: 0.2601 - accuracy: 0.8950 - val_loss: 0.2463 - val_accuracy: 0.9022 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2514 - accuracy: 0.8979 - val_loss: 0.2415 - val_accuracy: 0.9021 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 2s 899us/step - loss: 0.2456 - accuracy: 0.9007 - val_loss: 0.2400 - val_accuracy: 0.9025 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 2s 915us/step - loss: 0.2404 - accuracy: 0.9016 - val_loss: 0.2357 - val_accuracy: 0.9044 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 2s 904us/step - loss: 0.2372 - accuracy: 0.9026 - val_loss: 0.2315 - val_accuracy: 0.9049 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 2s 950us/step - loss: 0.2342 - accuracy: 0.9041 - val_loss: 0.2296 - val_accuracy: 0.9045 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 2s 917us/step - loss: 0.2320 - accuracy: 0.9047 - val_loss: 0.2261 - val_accuracy: 0.9086 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 2s 900us/step - loss: 0.2302 - accuracy: 0.9049 - val_loss: 0.2244 - val_accuracy: 0.9077 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 2s 887us/step - loss: 0.2285 - accuracy: 0.9056 - val_loss: 0.2286 - val_accuracy: 0.9055 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 2s 858us/step - loss: 0.2274 - accuracy: 0.9067 - val_loss: 0.2223 - val_accuracy: 0.9088 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 2s 914us/step - loss: 0.2263 - accuracy: 0.9066 - val_loss: 0.2219 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 2s 918us/step - loss: 0.2250 - accuracy: 0.9072 - val_loss: 0.2203 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 2s 827us/step - loss: 0.2241 - accuracy: 0.9070 - val_loss: 0.2211 - val_accuracy: 0.9081 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 2s 887us/step - loss: 0.2231 - accuracy: 0.9069 - val_loss: 0.2232 - val_accuracy: 0.9066 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 2s 859us/step - loss: 0.2233 - accuracy: 0.9073 - val_loss: 0.2217 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 2s 859us/step - loss: 0.2220 - accuracy: 0.9077 - val_loss: 0.2204 - val_accuracy: 0.9079 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 2s 876us/step - loss: 0.2214 - accuracy: 0.9082 - val_loss: 0.2198 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 2s 858us/step - loss: 0.2206 - accuracy: 0.9077 - val_loss: 0.2203 - val_accuracy: 0.9072 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 2s 868us/step - loss: 0.2204 - accuracy: 0.9080 - val_loss: 0.2203 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 2s 829us/step - loss: 0.2200 - accuracy: 0.9086 - val_loss: 0.2189 - val_accuracy: 0.9086 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 2s 941us/step - loss: 0.2196 - accuracy: 0.9082 - val_loss: 0.2193 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 2s 952us/step - loss: 0.2193 - accuracy: 0.9087 - val_loss: 0.2187 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 2s 872us/step - loss: 0.2187 - accuracy: 0.9090 - val_loss: 0.2203 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 2s 807us/step - loss: 0.2183 - accuracy: 0.9094 - val_loss: 0.2168 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 2s 934us/step - loss: 0.2177 - accuracy: 0.9095 - val_loss: 0.2200 - val_accuracy: 0.9083 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 2s 932us/step - loss: 0.2173 - accuracy: 0.9095 - val_loss: 0.2176 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 2s 893us/step - loss: 0.2177 - accuracy: 0.9093 - val_loss: 0.2190 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 2s 851us/step - loss: 0.2165 - accuracy: 0.9095 - val_loss: 0.2159 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 2s 768us/step - loss: 0.2166 - accuracy: 0.9096 - val_loss: 0.2163 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 2s 823us/step - loss: 0.2159 - accuracy: 0.9105 - val_loss: 0.2168 - val_accuracy: 0.9086 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 2s 880us/step - loss: 0.2163 - accuracy: 0.9103 - val_loss: 0.2170 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 2s 835us/step - loss: 0.2157 - accuracy: 0.9103 - val_loss: 0.2175 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 2s 826us/step - loss: 0.2151 - accuracy: 0.9104 - val_loss: 0.2167 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 2s 887us/step - loss: 0.2097 - accuracy: 0.9130 - val_loss: 0.2138 - val_accuracy: 0.9111 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 2s 822us/step - loss: 0.2089 - accuracy: 0.9133 - val_loss: 0.2139 - val_accuracy: 0.9110 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 2s 881us/step - loss: 0.2087 - accuracy: 0.9130 - val_loss: 0.2135 - val_accuracy: 0.9113 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 2s 903us/step - loss: 0.2085 - accuracy: 0.9140 - val_loss: 0.2135 - val_accuracy: 0.9109 - lr: 2.0000e-04\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 2s 869us/step - loss: 0.2083 - accuracy: 0.9137 - val_loss: 0.2135 - val_accuracy: 0.9110 - lr: 2.0000e-04\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 2s 901us/step - loss: 0.2084 - accuracy: 0.9132 - val_loss: 0.2130 - val_accuracy: 0.9114 - lr: 2.0000e-04\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 3s 966us/step - loss: 0.2083 - accuracy: 0.9132 - val_loss: 0.2138 - val_accuracy: 0.9096 - lr: 2.0000e-04\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 3s 969us/step - loss: 0.2081 - accuracy: 0.9134 - val_loss: 0.2134 - val_accuracy: 0.9117 - lr: 2.0000e-04\n",
      "Epoch 43/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2081 - accuracy: 0.9134 - val_loss: 0.2133 - val_accuracy: 0.9112 - lr: 2.0000e-04\n",
      "Epoch 44/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2080 - accuracy: 0.9134 - val_loss: 0.2134 - val_accuracy: 0.9109 - lr: 2.0000e-04\n",
      "Epoch 45/50\n",
      "2590/2590 [==============================] - 2s 955us/step - loss: 0.2078 - accuracy: 0.9139 - val_loss: 0.2137 - val_accuracy: 0.9114 - lr: 2.0000e-04\n",
      "Epoch 46/50\n",
      "2590/2590 [==============================] - 2s 946us/step - loss: 0.2064 - accuracy: 0.9144 - val_loss: 0.2129 - val_accuracy: 0.9115 - lr: 4.0000e-05\n",
      "Epoch 47/50\n",
      "2590/2590 [==============================] - 2s 891us/step - loss: 0.2062 - accuracy: 0.9141 - val_loss: 0.2129 - val_accuracy: 0.9114 - lr: 4.0000e-05\n",
      "Epoch 48/50\n",
      "2590/2590 [==============================] - 2s 912us/step - loss: 0.2062 - accuracy: 0.9144 - val_loss: 0.2128 - val_accuracy: 0.9112 - lr: 4.0000e-05\n",
      "Epoch 49/50\n",
      "2590/2590 [==============================] - 2s 882us/step - loss: 0.2062 - accuracy: 0.9144 - val_loss: 0.2129 - val_accuracy: 0.9112 - lr: 4.0000e-05\n",
      "Epoch 50/50\n",
      "2590/2590 [==============================] - 2s 876us/step - loss: 0.2062 - accuracy: 0.9141 - val_loss: 0.2129 - val_accuracy: 0.9115 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_train = df_train_dummie['satisfaction']\n",
    "\n",
    "X_test = df_test_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_test = df_test_dummie['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m2.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 116.46 segundos\n",
      "Pérdida: 0.2061804085969925\n",
      "Accuracy Modelo: 91.41477942466736\n",
      "Recall: 0.8807743070831501\n",
      "Specificity: 0.57548374\n",
      "F1-Score: 0.8954689806324642\n",
      "Precisión: 0.9106622998544396\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m2.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 3: Correlaciones cercanas > 0.3 (+1 capa)\n",
    "- Inputs: 'Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service',\"Cleanliness\"\n",
    "- Epochs = 50\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 relu\n",
    "- 3ra capa = 16 relu\n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate = 0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 3s 981us/step - loss: 0.2894 - accuracy: 0.8826 - val_loss: 0.2538 - val_accuracy: 0.8986 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 2s 911us/step - loss: 0.2577 - accuracy: 0.8966 - val_loss: 0.2425 - val_accuracy: 0.9027 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 2s 932us/step - loss: 0.2478 - accuracy: 0.8998 - val_loss: 0.2486 - val_accuracy: 0.8993 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 2s 946us/step - loss: 0.2407 - accuracy: 0.9020 - val_loss: 0.2305 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2354 - accuracy: 0.9039 - val_loss: 0.2290 - val_accuracy: 0.9065 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 3s 994us/step - loss: 0.2323 - accuracy: 0.9049 - val_loss: 0.2243 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2288 - accuracy: 0.9052 - val_loss: 0.2240 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 2s 914us/step - loss: 0.2264 - accuracy: 0.9065 - val_loss: 0.2292 - val_accuracy: 0.9080 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 2s 962us/step - loss: 0.2242 - accuracy: 0.9082 - val_loss: 0.2220 - val_accuracy: 0.9088 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 2s 948us/step - loss: 0.2228 - accuracy: 0.9077 - val_loss: 0.2199 - val_accuracy: 0.9092 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 3s 971us/step - loss: 0.2217 - accuracy: 0.9086 - val_loss: 0.2201 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 3s 979us/step - loss: 0.2203 - accuracy: 0.9093 - val_loss: 0.2202 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 3s 978us/step - loss: 0.2196 - accuracy: 0.9093 - val_loss: 0.2204 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 2s 960us/step - loss: 0.2191 - accuracy: 0.9095 - val_loss: 0.2209 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 2s 900us/step - loss: 0.2182 - accuracy: 0.9096 - val_loss: 0.2163 - val_accuracy: 0.9092 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 3s 989us/step - loss: 0.2177 - accuracy: 0.9100 - val_loss: 0.2182 - val_accuracy: 0.9088 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 2s 892us/step - loss: 0.2173 - accuracy: 0.9094 - val_loss: 0.2194 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 2s 920us/step - loss: 0.2167 - accuracy: 0.9104 - val_loss: 0.2160 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 2s 909us/step - loss: 0.2159 - accuracy: 0.9102 - val_loss: 0.2175 - val_accuracy: 0.9097 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 3s 979us/step - loss: 0.2158 - accuracy: 0.9102 - val_loss: 0.2205 - val_accuracy: 0.9076 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 3s 975us/step - loss: 0.2153 - accuracy: 0.9104 - val_loss: 0.2209 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 2s 928us/step - loss: 0.2150 - accuracy: 0.9113 - val_loss: 0.2182 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 2s 881us/step - loss: 0.2148 - accuracy: 0.9106 - val_loss: 0.2158 - val_accuracy: 0.9105 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 2s 865us/step - loss: 0.2145 - accuracy: 0.9107 - val_loss: 0.2169 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 2s 895us/step - loss: 0.2142 - accuracy: 0.9112 - val_loss: 0.2176 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 2s 943us/step - loss: 0.2137 - accuracy: 0.9115 - val_loss: 0.2153 - val_accuracy: 0.9095 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 2s 938us/step - loss: 0.2133 - accuracy: 0.9115 - val_loss: 0.2155 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 3s 972us/step - loss: 0.2132 - accuracy: 0.9112 - val_loss: 0.2169 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 2s 962us/step - loss: 0.2129 - accuracy: 0.9111 - val_loss: 0.2160 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 3s 972us/step - loss: 0.2126 - accuracy: 0.9116 - val_loss: 0.2156 - val_accuracy: 0.9098 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 2s 913us/step - loss: 0.2119 - accuracy: 0.9120 - val_loss: 0.2156 - val_accuracy: 0.9101 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 3s 965us/step - loss: 0.2065 - accuracy: 0.9138 - val_loss: 0.2125 - val_accuracy: 0.9120 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 2s 955us/step - loss: 0.2057 - accuracy: 0.9144 - val_loss: 0.2128 - val_accuracy: 0.9119 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 3s 967us/step - loss: 0.2052 - accuracy: 0.9145 - val_loss: 0.2130 - val_accuracy: 0.9119 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 2s 962us/step - loss: 0.2050 - accuracy: 0.9144 - val_loss: 0.2127 - val_accuracy: 0.9116 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 2s 882us/step - loss: 0.2048 - accuracy: 0.9142 - val_loss: 0.2128 - val_accuracy: 0.9121 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 2s 904us/step - loss: 0.2048 - accuracy: 0.9145 - val_loss: 0.2130 - val_accuracy: 0.9126 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 2s 962us/step - loss: 0.2032 - accuracy: 0.9150 - val_loss: 0.2128 - val_accuracy: 0.9125 - lr: 4.0000e-05\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 2s 939us/step - loss: 0.2030 - accuracy: 0.9152 - val_loss: 0.2129 - val_accuracy: 0.9124 - lr: 4.0000e-05\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2030 - accuracy: 0.9151 - val_loss: 0.2128 - val_accuracy: 0.9124 - lr: 4.0000e-05\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2029 - accuracy: 0.9152 - val_loss: 0.2130 - val_accuracy: 0.9127 - lr: 4.0000e-05\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 3s 994us/step - loss: 0.2029 - accuracy: 0.9150 - val_loss: 0.2129 - val_accuracy: 0.9123 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_train = df_train_dummie['satisfaction']\n",
    "\n",
    "X_test = df_test_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_test = df_test_dummie['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m3.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 103.97 segundos\n",
      "Pérdida: 0.20288875699043274\n",
      "Accuracy Modelo: 91.50407314300537\n",
      "Recall: 0.8815662120545534\n",
      "Specificity: 0.5758699\n",
      "F1-Score: 0.8966751689264779\n",
      "Precisión: 0.9123110544527409\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m3.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 4: Correlaciones > 0.3 (Other activations)\n",
    "- Inputs: 'Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service',\"Cleanliness\"\n",
    "- Epochs = 50\n",
    "- 1ra capa = 64, relu\n",
    "- 2da capa = 32 tanh\n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate = 0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 3s 885us/step - loss: 0.2997 - accuracy: 0.8778 - val_loss: 0.2665 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 2s 890us/step - loss: 0.2654 - accuracy: 0.8923 - val_loss: 0.2490 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2541 - accuracy: 0.8969 - val_loss: 0.2430 - val_accuracy: 0.9012 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2462 - accuracy: 0.9006 - val_loss: 0.2363 - val_accuracy: 0.9046 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 2s 883us/step - loss: 0.2411 - accuracy: 0.9016 - val_loss: 0.2343 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 2s 860us/step - loss: 0.2376 - accuracy: 0.9028 - val_loss: 0.2301 - val_accuracy: 0.9049 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 2s 880us/step - loss: 0.2350 - accuracy: 0.9029 - val_loss: 0.2278 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 2s 879us/step - loss: 0.2325 - accuracy: 0.9038 - val_loss: 0.2329 - val_accuracy: 0.9013 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 2s 943us/step - loss: 0.2310 - accuracy: 0.9042 - val_loss: 0.2279 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 2s 863us/step - loss: 0.2295 - accuracy: 0.9060 - val_loss: 0.2313 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 2s 864us/step - loss: 0.2282 - accuracy: 0.9051 - val_loss: 0.2235 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 2s 857us/step - loss: 0.2268 - accuracy: 0.9065 - val_loss: 0.2200 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 2s 844us/step - loss: 0.2258 - accuracy: 0.9070 - val_loss: 0.2227 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2247 - accuracy: 0.9064 - val_loss: 0.2255 - val_accuracy: 0.9068 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2238 - accuracy: 0.9074 - val_loss: 0.2205 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2230 - accuracy: 0.9076 - val_loss: 0.2210 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 4s 1ms/step - loss: 0.2223 - accuracy: 0.9083 - val_loss: 0.2231 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2170 - accuracy: 0.9101 - val_loss: 0.2166 - val_accuracy: 0.9113 - lr: 2.0000e-04\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2162 - accuracy: 0.9107 - val_loss: 0.2160 - val_accuracy: 0.9115 - lr: 2.0000e-04\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2159 - accuracy: 0.9105 - val_loss: 0.2167 - val_accuracy: 0.9121 - lr: 2.0000e-04\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.2157 - accuracy: 0.9108 - val_loss: 0.2160 - val_accuracy: 0.9109 - lr: 2.0000e-04\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2156 - accuracy: 0.9109 - val_loss: 0.2153 - val_accuracy: 0.9109 - lr: 2.0000e-04\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2152 - accuracy: 0.9107 - val_loss: 0.2165 - val_accuracy: 0.9111 - lr: 2.0000e-04\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2151 - accuracy: 0.9112 - val_loss: 0.2161 - val_accuracy: 0.9108 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2150 - accuracy: 0.9110 - val_loss: 0.2161 - val_accuracy: 0.9108 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 2s 808us/step - loss: 0.2148 - accuracy: 0.9110 - val_loss: 0.2160 - val_accuracy: 0.9106 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 3s 981us/step - loss: 0.2148 - accuracy: 0.9113 - val_loss: 0.2150 - val_accuracy: 0.9118 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2146 - accuracy: 0.9111 - val_loss: 0.2154 - val_accuracy: 0.9111 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.2144 - accuracy: 0.9112 - val_loss: 0.2149 - val_accuracy: 0.9100 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2142 - accuracy: 0.9112 - val_loss: 0.2162 - val_accuracy: 0.9099 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2142 - accuracy: 0.9118 - val_loss: 0.2149 - val_accuracy: 0.9116 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.2140 - accuracy: 0.9115 - val_loss: 0.2155 - val_accuracy: 0.9117 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2126 - accuracy: 0.9121 - val_loss: 0.2147 - val_accuracy: 0.9109 - lr: 4.0000e-05\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 2s 941us/step - loss: 0.2126 - accuracy: 0.9119 - val_loss: 0.2147 - val_accuracy: 0.9113 - lr: 4.0000e-05\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 2s 920us/step - loss: 0.2125 - accuracy: 0.9117 - val_loss: 0.2148 - val_accuracy: 0.9113 - lr: 4.0000e-05\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 2s 920us/step - loss: 0.2124 - accuracy: 0.9123 - val_loss: 0.2145 - val_accuracy: 0.9113 - lr: 4.0000e-05\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 2s 880us/step - loss: 0.2124 - accuracy: 0.9121 - val_loss: 0.2147 - val_accuracy: 0.9121 - lr: 4.0000e-05\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 2s 874us/step - loss: 0.2124 - accuracy: 0.9121 - val_loss: 0.2148 - val_accuracy: 0.9114 - lr: 4.0000e-05\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 2s 889us/step - loss: 0.2123 - accuracy: 0.9120 - val_loss: 0.2151 - val_accuracy: 0.9111 - lr: 4.0000e-05\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 2s 946us/step - loss: 0.2123 - accuracy: 0.9120 - val_loss: 0.2146 - val_accuracy: 0.9113 - lr: 4.0000e-05\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 2s 964us/step - loss: 0.2123 - accuracy: 0.9120 - val_loss: 0.2148 - val_accuracy: 0.9112 - lr: 4.0000e-05\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2120 - accuracy: 0.9125 - val_loss: 0.2146 - val_accuracy: 0.9111 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "2590/2590 [==============================] - 2s 941us/step - loss: 0.2120 - accuracy: 0.9121 - val_loss: 0.2146 - val_accuracy: 0.9111 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "2590/2590 [==============================] - 2s 882us/step - loss: 0.2120 - accuracy: 0.9122 - val_loss: 0.2147 - val_accuracy: 0.9111 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "2590/2590 [==============================] - 2s 934us/step - loss: 0.2120 - accuracy: 0.9122 - val_loss: 0.2146 - val_accuracy: 0.9115 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "2590/2590 [==============================] - 2s 914us/step - loss: 0.2119 - accuracy: 0.9123 - val_loss: 0.2146 - val_accuracy: 0.9115 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_train = df_train_dummie['satisfaction']\n",
    "\n",
    "X_test = df_test_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_test = df_test_dummie['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='tanh'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m4.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 165.34 segundos\n",
      "Pérdida: 0.2119370996952057\n",
      "Accuracy Modelo: 91.231369972229\n",
      "Recall: 0.8745270567531896\n",
      "Specificity: 0.5805816\n",
      "F1-Score: 0.894398200224972\n",
      "Precisión: 0.9151933701657459\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m4.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 5: Correlaciones > 0.3 (Más nodos, más capas, nuevas funciones activación)\n",
    "- Inputs: 'Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service',\"Cleanliness\"\n",
    "- Epochs = 50\n",
    "- 1ra capa = 128, relu\n",
    "- 2da capa = 64 relu\n",
    "- 3ra capa = 32 tanh\n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate = 0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 3s 945us/step - loss: 0.2755 - accuracy: 0.8882 - val_loss: 0.2439 - val_accuracy: 0.9001 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 2s 909us/step - loss: 0.2461 - accuracy: 0.8996 - val_loss: 0.2320 - val_accuracy: 0.9072 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2365 - accuracy: 0.9021 - val_loss: 0.2259 - val_accuracy: 0.9047 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 2s 953us/step - loss: 0.2311 - accuracy: 0.9042 - val_loss: 0.2223 - val_accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 2s 952us/step - loss: 0.2266 - accuracy: 0.9060 - val_loss: 0.2205 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 3s 974us/step - loss: 0.2241 - accuracy: 0.9074 - val_loss: 0.2194 - val_accuracy: 0.9102 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2221 - accuracy: 0.9080 - val_loss: 0.2156 - val_accuracy: 0.9092 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 3s 989us/step - loss: 0.2197 - accuracy: 0.9094 - val_loss: 0.2169 - val_accuracy: 0.9094 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 2s 916us/step - loss: 0.2185 - accuracy: 0.9091 - val_loss: 0.2134 - val_accuracy: 0.9124 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 3s 980us/step - loss: 0.2173 - accuracy: 0.9094 - val_loss: 0.2154 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2165 - accuracy: 0.9098 - val_loss: 0.2152 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 3s 966us/step - loss: 0.2158 - accuracy: 0.9104 - val_loss: 0.2151 - val_accuracy: 0.9115 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2145 - accuracy: 0.9107 - val_loss: 0.2173 - val_accuracy: 0.9109 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 2s 886us/step - loss: 0.2139 - accuracy: 0.9108 - val_loss: 0.2127 - val_accuracy: 0.9117 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 3s 983us/step - loss: 0.2133 - accuracy: 0.9115 - val_loss: 0.2154 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 2s 918us/step - loss: 0.2125 - accuracy: 0.9119 - val_loss: 0.2137 - val_accuracy: 0.9104 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 2s 933us/step - loss: 0.2121 - accuracy: 0.9120 - val_loss: 0.2159 - val_accuracy: 0.9117 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2118 - accuracy: 0.9113 - val_loss: 0.2142 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2107 - accuracy: 0.9120 - val_loss: 0.2137 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.2039 - accuracy: 0.9146 - val_loss: 0.2111 - val_accuracy: 0.9120 - lr: 2.0000e-04\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2027 - accuracy: 0.9147 - val_loss: 0.2107 - val_accuracy: 0.9116 - lr: 2.0000e-04\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2022 - accuracy: 0.9152 - val_loss: 0.2114 - val_accuracy: 0.9130 - lr: 2.0000e-04\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.2018 - accuracy: 0.9156 - val_loss: 0.2118 - val_accuracy: 0.9111 - lr: 2.0000e-04\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.2014 - accuracy: 0.9157 - val_loss: 0.2113 - val_accuracy: 0.9118 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.2011 - accuracy: 0.9161 - val_loss: 0.2119 - val_accuracy: 0.9122 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2010 - accuracy: 0.9162 - val_loss: 0.2111 - val_accuracy: 0.9121 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.1989 - accuracy: 0.9167 - val_loss: 0.2112 - val_accuracy: 0.9115 - lr: 4.0000e-05\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.1987 - accuracy: 0.9165 - val_loss: 0.2115 - val_accuracy: 0.9124 - lr: 4.0000e-05\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.1986 - accuracy: 0.9165 - val_loss: 0.2113 - val_accuracy: 0.9121 - lr: 4.0000e-05\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 11s 4ms/step - loss: 0.1985 - accuracy: 0.9168 - val_loss: 0.2115 - val_accuracy: 0.9119 - lr: 4.0000e-05\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 2s 925us/step - loss: 0.1984 - accuracy: 0.9166 - val_loss: 0.2114 - val_accuracy: 0.9123 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_train = df_train_dummie['satisfaction']\n",
    "\n",
    "X_test = df_test_dummie[['Type of Travel', 'Class','Online boarding', 'Seat comfort', 'Inflight entertainment','On-board service','Leg room service','Cleanliness']]\n",
    "y_test = df_test_dummie['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='tanh'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m5.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 146.32 segundos\n",
      "Pérdida: 0.19842857122421265\n",
      "Accuracy Modelo: 91.65852069854736\n",
      "Recall: 0.8780466344038715\n",
      "Specificity: 0.5789982\n",
      "F1-Score: 0.8963442019222132\n",
      "Precisión: 0.9154206036143473\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m5.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 6: Nuevos features\n",
    "- Epochs = 50\n",
    "- 1raa capa = 64 relu\n",
    "- 2da capa = 32 relu\n",
    "- 3ra capa = 1 sigmoid\n",
    "- learning_rate = 0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.3700 - accuracy: 0.8458 - val_loss: 0.3453 - val_accuracy: 0.8609 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 2s 952us/step - loss: 0.3387 - accuracy: 0.8585 - val_loss: 0.3236 - val_accuracy: 0.8642 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 2s 912us/step - loss: 0.3259 - accuracy: 0.8637 - val_loss: 0.3109 - val_accuracy: 0.8698 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 2s 881us/step - loss: 0.3183 - accuracy: 0.8672 - val_loss: 0.3056 - val_accuracy: 0.8736 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 2s 866us/step - loss: 0.3129 - accuracy: 0.8703 - val_loss: 0.3051 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 2s 922us/step - loss: 0.3090 - accuracy: 0.8714 - val_loss: 0.2966 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 3s 972us/step - loss: 0.3055 - accuracy: 0.8730 - val_loss: 0.2976 - val_accuracy: 0.8790 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 2s 857us/step - loss: 0.3034 - accuracy: 0.8737 - val_loss: 0.2968 - val_accuracy: 0.8774 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 2s 834us/step - loss: 0.3018 - accuracy: 0.8751 - val_loss: 0.2953 - val_accuracy: 0.8789 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 2s 914us/step - loss: 0.3005 - accuracy: 0.8747 - val_loss: 0.2931 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 2s 855us/step - loss: 0.2990 - accuracy: 0.8757 - val_loss: 0.3000 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 2s 916us/step - loss: 0.2978 - accuracy: 0.8760 - val_loss: 0.2909 - val_accuracy: 0.8807 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 2s 929us/step - loss: 0.2970 - accuracy: 0.8768 - val_loss: 0.2885 - val_accuracy: 0.8810 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 3s 996us/step - loss: 0.2957 - accuracy: 0.8775 - val_loss: 0.2904 - val_accuracy: 0.8810 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 2s 908us/step - loss: 0.2956 - accuracy: 0.8767 - val_loss: 0.2891 - val_accuracy: 0.8832 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 2s 884us/step - loss: 0.2954 - accuracy: 0.8782 - val_loss: 0.2897 - val_accuracy: 0.8807 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 3s 987us/step - loss: 0.2937 - accuracy: 0.8776 - val_loss: 0.2920 - val_accuracy: 0.8778 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 2s 894us/step - loss: 0.2936 - accuracy: 0.8768 - val_loss: 0.2871 - val_accuracy: 0.8818 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 2s 931us/step - loss: 0.2929 - accuracy: 0.8785 - val_loss: 0.2901 - val_accuracy: 0.8787 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 2s 837us/step - loss: 0.2930 - accuracy: 0.8781 - val_loss: 0.2856 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 2s 862us/step - loss: 0.2917 - accuracy: 0.8793 - val_loss: 0.2957 - val_accuracy: 0.8784 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 2s 891us/step - loss: 0.2914 - accuracy: 0.8788 - val_loss: 0.2892 - val_accuracy: 0.8807 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 2s 890us/step - loss: 0.2910 - accuracy: 0.8790 - val_loss: 0.2850 - val_accuracy: 0.8828 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 2s 959us/step - loss: 0.2907 - accuracy: 0.8786 - val_loss: 0.2888 - val_accuracy: 0.8781 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 2s 939us/step - loss: 0.2898 - accuracy: 0.8796 - val_loss: 0.2906 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2901 - accuracy: 0.8784 - val_loss: 0.2886 - val_accuracy: 0.8795 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2894 - accuracy: 0.8790 - val_loss: 0.2934 - val_accuracy: 0.8774 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2895 - accuracy: 0.8791 - val_loss: 0.2855 - val_accuracy: 0.8831 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2834 - accuracy: 0.8818 - val_loss: 0.2809 - val_accuracy: 0.8824 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 3s 1ms/step - loss: 0.2826 - accuracy: 0.8820 - val_loss: 0.2803 - val_accuracy: 0.8839 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2823 - accuracy: 0.8825 - val_loss: 0.2803 - val_accuracy: 0.8833 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.2822 - accuracy: 0.8825 - val_loss: 0.2795 - val_accuracy: 0.8843 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 9s 4ms/step - loss: 0.2819 - accuracy: 0.8827 - val_loss: 0.2802 - val_accuracy: 0.8841 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2818 - accuracy: 0.8824 - val_loss: 0.2795 - val_accuracy: 0.8840 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2816 - accuracy: 0.8828 - val_loss: 0.2800 - val_accuracy: 0.8844 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.2816 - accuracy: 0.8821 - val_loss: 0.2808 - val_accuracy: 0.8835 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2815 - accuracy: 0.8826 - val_loss: 0.2791 - val_accuracy: 0.8849 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 11s 4ms/step - loss: 0.2812 - accuracy: 0.8825 - val_loss: 0.2796 - val_accuracy: 0.8845 - lr: 2.0000e-04\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 6s 3ms/step - loss: 0.2811 - accuracy: 0.8830 - val_loss: 0.2814 - val_accuracy: 0.8825 - lr: 2.0000e-04\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.2809 - accuracy: 0.8826 - val_loss: 0.2807 - val_accuracy: 0.8831 - lr: 2.0000e-04\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2808 - accuracy: 0.8825 - val_loss: 0.2801 - val_accuracy: 0.8832 - lr: 2.0000e-04\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2808 - accuracy: 0.8827 - val_loss: 0.2785 - val_accuracy: 0.8849 - lr: 2.0000e-04\n",
      "Epoch 43/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2806 - accuracy: 0.8824 - val_loss: 0.2792 - val_accuracy: 0.8854 - lr: 2.0000e-04\n",
      "Epoch 44/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.2803 - accuracy: 0.8826 - val_loss: 0.2798 - val_accuracy: 0.8837 - lr: 2.0000e-04\n",
      "Epoch 45/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.2802 - accuracy: 0.8832 - val_loss: 0.2801 - val_accuracy: 0.8842 - lr: 2.0000e-04\n",
      "Epoch 46/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2802 - accuracy: 0.8834 - val_loss: 0.2795 - val_accuracy: 0.8848 - lr: 2.0000e-04\n",
      "Epoch 47/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.2801 - accuracy: 0.8829 - val_loss: 0.2790 - val_accuracy: 0.8840 - lr: 2.0000e-04\n",
      "Epoch 48/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.2786 - accuracy: 0.8837 - val_loss: 0.2784 - val_accuracy: 0.8842 - lr: 4.0000e-05\n",
      "Epoch 49/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2785 - accuracy: 0.8833 - val_loss: 0.2784 - val_accuracy: 0.8846 - lr: 4.0000e-05\n",
      "Epoch 50/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2784 - accuracy: 0.8837 - val_loss: 0.2785 - val_accuracy: 0.8846 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_combined[['Age Cluster', 'Weight Comfort Seats', 'Mean Satisfaction Services',\n",
    "       'Sum Inflight Services', 'Space Seat and Class',\n",
    "       'Weight Basic Services']]\n",
    "y_train = df_train_combined['satisfaction']\n",
    "\n",
    "X_test = df_test_combined[['Age Cluster', 'Weight Comfort Seats', 'Mean Satisfaction Services',\n",
    "       'Sum Inflight Services', 'Space Seat and Class',\n",
    "       'Weight Basic Services']]\n",
    "y_test = df_test_combined['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m6.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 238.06 segundos\n",
      "Pérdida: 0.27842628955841064\n",
      "Accuracy Modelo: 88.37043642997742\n",
      "Recall: 0.8303563572371315\n",
      "Specificity: 0.5869153\n",
      "F1-Score: 0.8555369203571914\n",
      "Precisión: 0.8822924457741211\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m6.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 7: Nuevos Features (+1 capa)\n",
    "- Epochs = 50\n",
    "- 1ra capa = 64 relu\n",
    "- 2da capa = 64 relu\n",
    "- 3ra capa = 32 relu\n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate = 0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3537 - accuracy: 0.8528 - val_loss: 0.3221 - val_accuracy: 0.8665 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3197 - accuracy: 0.8675 - val_loss: 0.3166 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3095 - accuracy: 0.8718 - val_loss: 0.3004 - val_accuracy: 0.8768 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3044 - accuracy: 0.8734 - val_loss: 0.2934 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.3021 - accuracy: 0.8737 - val_loss: 0.2952 - val_accuracy: 0.8770 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2992 - accuracy: 0.8754 - val_loss: 0.2888 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2966 - accuracy: 0.8766 - val_loss: 0.2932 - val_accuracy: 0.8795 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2947 - accuracy: 0.8770 - val_loss: 0.2871 - val_accuracy: 0.8822 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2935 - accuracy: 0.8772 - val_loss: 0.2873 - val_accuracy: 0.8838 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2919 - accuracy: 0.8787 - val_loss: 0.2824 - val_accuracy: 0.8821 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2906 - accuracy: 0.8791 - val_loss: 0.2840 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2897 - accuracy: 0.8793 - val_loss: 0.2830 - val_accuracy: 0.8844 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2884 - accuracy: 0.8810 - val_loss: 0.2806 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2870 - accuracy: 0.8803 - val_loss: 0.2838 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2862 - accuracy: 0.8805 - val_loss: 0.2817 - val_accuracy: 0.8858 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2853 - accuracy: 0.8805 - val_loss: 0.2849 - val_accuracy: 0.8828 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2845 - accuracy: 0.8814 - val_loss: 0.2823 - val_accuracy: 0.8840 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2832 - accuracy: 0.8812 - val_loss: 0.2794 - val_accuracy: 0.8858 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2823 - accuracy: 0.8814 - val_loss: 0.2803 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2814 - accuracy: 0.8821 - val_loss: 0.2812 - val_accuracy: 0.8838 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2809 - accuracy: 0.8835 - val_loss: 0.2769 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2802 - accuracy: 0.8831 - val_loss: 0.2873 - val_accuracy: 0.8813 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2794 - accuracy: 0.8834 - val_loss: 0.2768 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2786 - accuracy: 0.8842 - val_loss: 0.2804 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2780 - accuracy: 0.8840 - val_loss: 0.2802 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2768 - accuracy: 0.8850 - val_loss: 0.2784 - val_accuracy: 0.8862 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2766 - accuracy: 0.8851 - val_loss: 0.2808 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2764 - accuracy: 0.8851 - val_loss: 0.2776 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2673 - accuracy: 0.8887 - val_loss: 0.2725 - val_accuracy: 0.8883 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2655 - accuracy: 0.8893 - val_loss: 0.2719 - val_accuracy: 0.8903 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2648 - accuracy: 0.8899 - val_loss: 0.2720 - val_accuracy: 0.8897 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2643 - accuracy: 0.8902 - val_loss: 0.2725 - val_accuracy: 0.8889 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2636 - accuracy: 0.8903 - val_loss: 0.2732 - val_accuracy: 0.8887 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2635 - accuracy: 0.8902 - val_loss: 0.2724 - val_accuracy: 0.8885 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2631 - accuracy: 0.8906 - val_loss: 0.2726 - val_accuracy: 0.8879 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2608 - accuracy: 0.8911 - val_loss: 0.2717 - val_accuracy: 0.8890 - lr: 4.0000e-05\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2603 - accuracy: 0.8916 - val_loss: 0.2717 - val_accuracy: 0.8893 - lr: 4.0000e-05\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2602 - accuracy: 0.8915 - val_loss: 0.2718 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2601 - accuracy: 0.8916 - val_loss: 0.2715 - val_accuracy: 0.8897 - lr: 4.0000e-05\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2600 - accuracy: 0.8918 - val_loss: 0.2717 - val_accuracy: 0.8892 - lr: 4.0000e-05\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2599 - accuracy: 0.8915 - val_loss: 0.2716 - val_accuracy: 0.8889 - lr: 4.0000e-05\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2598 - accuracy: 0.8919 - val_loss: 0.2716 - val_accuracy: 0.8892 - lr: 4.0000e-05\n",
      "Epoch 43/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2598 - accuracy: 0.8921 - val_loss: 0.2718 - val_accuracy: 0.8894 - lr: 4.0000e-05\n",
      "Epoch 44/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2596 - accuracy: 0.8918 - val_loss: 0.2721 - val_accuracy: 0.8894 - lr: 4.0000e-05\n",
      "Epoch 45/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2591 - accuracy: 0.8918 - val_loss: 0.2717 - val_accuracy: 0.8894 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2590 - accuracy: 0.8920 - val_loss: 0.2717 - val_accuracy: 0.8894 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2590 - accuracy: 0.8920 - val_loss: 0.2717 - val_accuracy: 0.8895 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2590 - accuracy: 0.8920 - val_loss: 0.2717 - val_accuracy: 0.8893 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2589 - accuracy: 0.8919 - val_loss: 0.2717 - val_accuracy: 0.8891 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_combined[['Age Cluster', 'Weight Comfort Seats', 'Mean Satisfaction Services',\n",
    "       'Sum Inflight Services', 'Space Seat and Class',\n",
    "       'Weight Basic Services']]\n",
    "y_train = df_train_combined['satisfaction']\n",
    "\n",
    "X_test = df_test_combined[['Age Cluster', 'Weight Comfort Seats', 'Mean Satisfaction Services',\n",
    "       'Sum Inflight Services', 'Space Seat and Class',\n",
    "       'Weight Basic Services']]\n",
    "y_test = df_test_combined['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m7.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 341.09 segundos\n",
      "Pérdida: 0.2589331567287445\n",
      "Accuracy Modelo: 89.18612599372864\n",
      "Recall: 0.834931808183018\n",
      "Specificity: 0.5864133\n",
      "F1-Score: 0.8597444957868986\n",
      "Precisión: 0.8860771313848165\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m7.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 8: Nuevos Features (+1 capa) (dif activación)\n",
    "- Epochs = 50\n",
    "- 1ra capa = 128 relu\n",
    "- 2da capa = 64 tanh\n",
    "- 3ra capa = 32 tanh\n",
    "- 4ta capa = 1 sigmoid\n",
    "- learning_rate = 0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3582 - accuracy: 0.8493 - val_loss: 0.3231 - val_accuracy: 0.8681 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3258 - accuracy: 0.8642 - val_loss: 0.3110 - val_accuracy: 0.8710 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3147 - accuracy: 0.8706 - val_loss: 0.3105 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3086 - accuracy: 0.8720 - val_loss: 0.3007 - val_accuracy: 0.8755 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3051 - accuracy: 0.8737 - val_loss: 0.2922 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3025 - accuracy: 0.8742 - val_loss: 0.2956 - val_accuracy: 0.8772 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2999 - accuracy: 0.8748 - val_loss: 0.2947 - val_accuracy: 0.8781 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2992 - accuracy: 0.8756 - val_loss: 0.2906 - val_accuracy: 0.8808 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2964 - accuracy: 0.8771 - val_loss: 0.2908 - val_accuracy: 0.8804 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 11s 4ms/step - loss: 0.2953 - accuracy: 0.8781 - val_loss: 0.2869 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2939 - accuracy: 0.8784 - val_loss: 0.2897 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2929 - accuracy: 0.8783 - val_loss: 0.2884 - val_accuracy: 0.8818 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2910 - accuracy: 0.8785 - val_loss: 0.2871 - val_accuracy: 0.8816 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2899 - accuracy: 0.8788 - val_loss: 0.2865 - val_accuracy: 0.8815 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2893 - accuracy: 0.8800 - val_loss: 0.2879 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2879 - accuracy: 0.8802 - val_loss: 0.2861 - val_accuracy: 0.8834 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2866 - accuracy: 0.8806 - val_loss: 0.2857 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2862 - accuracy: 0.8807 - val_loss: 0.2807 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2855 - accuracy: 0.8818 - val_loss: 0.2844 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2840 - accuracy: 0.8819 - val_loss: 0.2867 - val_accuracy: 0.8807 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2831 - accuracy: 0.8820 - val_loss: 0.2828 - val_accuracy: 0.8832 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2820 - accuracy: 0.8826 - val_loss: 0.2828 - val_accuracy: 0.8818 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2816 - accuracy: 0.8814 - val_loss: 0.2803 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2813 - accuracy: 0.8826 - val_loss: 0.2782 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2800 - accuracy: 0.8829 - val_loss: 0.2786 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2787 - accuracy: 0.8835 - val_loss: 0.2824 - val_accuracy: 0.8842 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2784 - accuracy: 0.8835 - val_loss: 0.2803 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2777 - accuracy: 0.8841 - val_loss: 0.2782 - val_accuracy: 0.8858 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2766 - accuracy: 0.8838 - val_loss: 0.2811 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2682 - accuracy: 0.8879 - val_loss: 0.2754 - val_accuracy: 0.8847 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2665 - accuracy: 0.8888 - val_loss: 0.2754 - val_accuracy: 0.8859 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2659 - accuracy: 0.8899 - val_loss: 0.2752 - val_accuracy: 0.8852 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2656 - accuracy: 0.8899 - val_loss: 0.2746 - val_accuracy: 0.8858 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2654 - accuracy: 0.8897 - val_loss: 0.2748 - val_accuracy: 0.8859 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2650 - accuracy: 0.8894 - val_loss: 0.2746 - val_accuracy: 0.8869 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2647 - accuracy: 0.8898 - val_loss: 0.2749 - val_accuracy: 0.8861 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.2643 - accuracy: 0.8900 - val_loss: 0.2748 - val_accuracy: 0.8855 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2640 - accuracy: 0.8902 - val_loss: 0.2747 - val_accuracy: 0.8860 - lr: 2.0000e-04\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2618 - accuracy: 0.8910 - val_loss: 0.2742 - val_accuracy: 0.8861 - lr: 4.0000e-05\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2615 - accuracy: 0.8911 - val_loss: 0.2739 - val_accuracy: 0.8855 - lr: 4.0000e-05\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 18s 7ms/step - loss: 0.2613 - accuracy: 0.8913 - val_loss: 0.2741 - val_accuracy: 0.8855 - lr: 4.0000e-05\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2613 - accuracy: 0.8917 - val_loss: 0.2741 - val_accuracy: 0.8855 - lr: 4.0000e-05\n",
      "Epoch 43/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2612 - accuracy: 0.8914 - val_loss: 0.2742 - val_accuracy: 0.8848 - lr: 4.0000e-05\n",
      "Epoch 44/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2612 - accuracy: 0.8912 - val_loss: 0.2740 - val_accuracy: 0.8858 - lr: 4.0000e-05\n",
      "Epoch 45/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2611 - accuracy: 0.8915 - val_loss: 0.2741 - val_accuracy: 0.8854 - lr: 4.0000e-05\n",
      "Epoch 46/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2605 - accuracy: 0.8916 - val_loss: 0.2739 - val_accuracy: 0.8855 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2605 - accuracy: 0.8917 - val_loss: 0.2739 - val_accuracy: 0.8855 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2604 - accuracy: 0.8918 - val_loss: 0.2740 - val_accuracy: 0.8855 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2604 - accuracy: 0.8918 - val_loss: 0.2739 - val_accuracy: 0.8852 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2604 - accuracy: 0.8917 - val_loss: 0.2739 - val_accuracy: 0.8857 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_combined[['Age Cluster', 'Weight Comfort Seats', 'Mean Satisfaction Services',\n",
    "       'Sum Inflight Services', 'Space Seat and Class',\n",
    "       'Weight Basic Services']]\n",
    "y_train = df_train_combined['satisfaction']\n",
    "\n",
    "X_test = df_test_combined[['Age Cluster', 'Weight Comfort Seats', 'Mean Satisfaction Services',\n",
    "       'Sum Inflight Services', 'Space Seat and Class',\n",
    "       'Weight Basic Services']]\n",
    "y_test = df_test_combined['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='tanh'),\n",
    "    layers.Dense(32, activation='tanh'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m8.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 334.95 segundos\n",
      "Pérdida: 0.2604016363620758\n",
      "Accuracy Modelo: 89.16682004928589\n",
      "Recall: 0.842146942366916\n",
      "Specificity: 0.5801954\n",
      "F1-Score: 0.8608949853834045\n",
      "Precisión: 0.8804967801287948\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m8.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 9: Nuevos features + Variables individuales\n",
    "- Epochs = 50\n",
    "- 1ra capa = 64 relu\n",
    "- 2da capa = 32 relu\n",
    "- 3ra capa = 1 sigmoid\n",
    "- learning_rate = 0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.3059 - accuracy: 0.8747 - val_loss: 0.2730 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2684 - accuracy: 0.8908 - val_loss: 0.2599 - val_accuracy: 0.8914 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2565 - accuracy: 0.8960 - val_loss: 0.2498 - val_accuracy: 0.8983 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2489 - accuracy: 0.9000 - val_loss: 0.2376 - val_accuracy: 0.9066 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2432 - accuracy: 0.9021 - val_loss: 0.2372 - val_accuracy: 0.9037 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2387 - accuracy: 0.9043 - val_loss: 0.2346 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2353 - accuracy: 0.9053 - val_loss: 0.2328 - val_accuracy: 0.9055 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2324 - accuracy: 0.9066 - val_loss: 0.2301 - val_accuracy: 0.9077 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2300 - accuracy: 0.9071 - val_loss: 0.2240 - val_accuracy: 0.9092 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2280 - accuracy: 0.9074 - val_loss: 0.2224 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2269 - accuracy: 0.9091 - val_loss: 0.2237 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2256 - accuracy: 0.9091 - val_loss: 0.2193 - val_accuracy: 0.9122 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2252 - accuracy: 0.9090 - val_loss: 0.2217 - val_accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2236 - accuracy: 0.9095 - val_loss: 0.2191 - val_accuracy: 0.9123 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2226 - accuracy: 0.9103 - val_loss: 0.2172 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2218 - accuracy: 0.9107 - val_loss: 0.2246 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2213 - accuracy: 0.9109 - val_loss: 0.2190 - val_accuracy: 0.9122 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2204 - accuracy: 0.9117 - val_loss: 0.2142 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2203 - accuracy: 0.9110 - val_loss: 0.2204 - val_accuracy: 0.9083 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2187 - accuracy: 0.9117 - val_loss: 0.2155 - val_accuracy: 0.9137 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2188 - accuracy: 0.9119 - val_loss: 0.2152 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2176 - accuracy: 0.9125 - val_loss: 0.2162 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2175 - accuracy: 0.9118 - val_loss: 0.2160 - val_accuracy: 0.9129 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2100 - accuracy: 0.9156 - val_loss: 0.2111 - val_accuracy: 0.9143 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2091 - accuracy: 0.9159 - val_loss: 0.2106 - val_accuracy: 0.9151 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2087 - accuracy: 0.9158 - val_loss: 0.2114 - val_accuracy: 0.9155 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2084 - accuracy: 0.9160 - val_loss: 0.2114 - val_accuracy: 0.9159 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2081 - accuracy: 0.9159 - val_loss: 0.2102 - val_accuracy: 0.9155 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2081 - accuracy: 0.9165 - val_loss: 0.2106 - val_accuracy: 0.9138 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2076 - accuracy: 0.9162 - val_loss: 0.2112 - val_accuracy: 0.9147 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2076 - accuracy: 0.9163 - val_loss: 0.2104 - val_accuracy: 0.9154 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2073 - accuracy: 0.9166 - val_loss: 0.2108 - val_accuracy: 0.9150 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2072 - accuracy: 0.9160 - val_loss: 0.2102 - val_accuracy: 0.9139 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2054 - accuracy: 0.9176 - val_loss: 0.2099 - val_accuracy: 0.9153 - lr: 4.0000e-05\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2052 - accuracy: 0.9177 - val_loss: 0.2091 - val_accuracy: 0.9161 - lr: 4.0000e-05\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2052 - accuracy: 0.9176 - val_loss: 0.2091 - val_accuracy: 0.9157 - lr: 4.0000e-05\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2051 - accuracy: 0.9175 - val_loss: 0.2095 - val_accuracy: 0.9154 - lr: 4.0000e-05\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2051 - accuracy: 0.9178 - val_loss: 0.2090 - val_accuracy: 0.9152 - lr: 4.0000e-05\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2050 - accuracy: 0.9178 - val_loss: 0.2093 - val_accuracy: 0.9155 - lr: 4.0000e-05\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2050 - accuracy: 0.9177 - val_loss: 0.2091 - val_accuracy: 0.9157 - lr: 4.0000e-05\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2049 - accuracy: 0.9177 - val_loss: 0.2092 - val_accuracy: 0.9157 - lr: 4.0000e-05\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2049 - accuracy: 0.9179 - val_loss: 0.2089 - val_accuracy: 0.9152 - lr: 4.0000e-05\n",
      "Epoch 43/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2048 - accuracy: 0.9179 - val_loss: 0.2102 - val_accuracy: 0.9151 - lr: 4.0000e-05\n",
      "Epoch 44/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2045 - accuracy: 0.9180 - val_loss: 0.2093 - val_accuracy: 0.9155 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2044 - accuracy: 0.9180 - val_loss: 0.2092 - val_accuracy: 0.9158 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2044 - accuracy: 0.9183 - val_loss: 0.2091 - val_accuracy: 0.9160 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "2590/2590 [==============================] - 15s 6ms/step - loss: 0.2044 - accuracy: 0.9184 - val_loss: 0.2091 - val_accuracy: 0.9157 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "2590/2590 [==============================] - 13s 5ms/step - loss: 0.2044 - accuracy: 0.9182 - val_loss: 0.2091 - val_accuracy: 0.9157 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2044 - accuracy: 0.9183 - val_loss: 0.2091 - val_accuracy: 0.9158 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2044 - accuracy: 0.9183 - val_loss: 0.2091 - val_accuracy: 0.9158 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_combined.drop(columns='satisfaction')\n",
    "y_train = df_train_combined['satisfaction']\n",
    "\n",
    "X_test = df_test_combined.drop(columns='satisfaction')\n",
    "y_test = df_test_combined['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m9.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 294.37 segundos\n",
      "Pérdida: 0.20435096323490143\n",
      "Accuracy Modelo: 91.82745218276978\n",
      "Recall: 0.873295204575451\n",
      "Specificity: 0.5826671\n",
      "F1-Score: 0.8953136980740607\n",
      "Precisión: 0.9184712196927632\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m9.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 10: Nuevos features + Variables individuales (Aumentando epochs)\n",
    "- Epochs = 100\n",
    "- 1ra capa = 64 relu\n",
    "- 2da capa = 32 relu\n",
    "- 3ra capa = 1 sigmoid\n",
    "- learning_rate = 0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 7s 2ms/step - loss: 0.3021 - accuracy: 0.8749 - val_loss: 0.2706 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2701 - accuracy: 0.8900 - val_loss: 0.2606 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2598 - accuracy: 0.8948 - val_loss: 0.2624 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2542 - accuracy: 0.8982 - val_loss: 0.2536 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2484 - accuracy: 0.9006 - val_loss: 0.2495 - val_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2439 - accuracy: 0.9019 - val_loss: 0.2331 - val_accuracy: 0.9058 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2398 - accuracy: 0.9039 - val_loss: 0.2315 - val_accuracy: 0.9084 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2366 - accuracy: 0.9054 - val_loss: 0.2312 - val_accuracy: 0.9058 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2335 - accuracy: 0.9061 - val_loss: 0.2264 - val_accuracy: 0.9101 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2320 - accuracy: 0.9062 - val_loss: 0.2273 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2306 - accuracy: 0.9071 - val_loss: 0.2310 - val_accuracy: 0.9076 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2289 - accuracy: 0.9079 - val_loss: 0.2296 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2270 - accuracy: 0.9079 - val_loss: 0.2231 - val_accuracy: 0.9104 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2256 - accuracy: 0.9097 - val_loss: 0.2238 - val_accuracy: 0.9098 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 14s 5ms/step - loss: 0.2239 - accuracy: 0.9095 - val_loss: 0.2212 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 14s 5ms/step - loss: 0.2229 - accuracy: 0.9104 - val_loss: 0.2224 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 16s 6ms/step - loss: 0.2215 - accuracy: 0.9098 - val_loss: 0.2173 - val_accuracy: 0.9124 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2207 - accuracy: 0.9112 - val_loss: 0.2209 - val_accuracy: 0.9101 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 13s 5ms/step - loss: 0.2201 - accuracy: 0.9106 - val_loss: 0.2173 - val_accuracy: 0.9115 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.2191 - accuracy: 0.9112 - val_loss: 0.2157 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2182 - accuracy: 0.9119 - val_loss: 0.2168 - val_accuracy: 0.9134 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.2169 - accuracy: 0.9117 - val_loss: 0.2182 - val_accuracy: 0.9109 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 9s 4ms/step - loss: 0.2164 - accuracy: 0.9128 - val_loss: 0.2122 - val_accuracy: 0.9145 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2156 - accuracy: 0.9131 - val_loss: 0.2127 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2150 - accuracy: 0.9130 - val_loss: 0.2137 - val_accuracy: 0.9149 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2145 - accuracy: 0.9135 - val_loss: 0.2117 - val_accuracy: 0.9156 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2134 - accuracy: 0.9135 - val_loss: 0.2180 - val_accuracy: 0.9127 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2132 - accuracy: 0.9137 - val_loss: 0.2134 - val_accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2123 - accuracy: 0.9145 - val_loss: 0.2172 - val_accuracy: 0.9102 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2119 - accuracy: 0.9145 - val_loss: 0.2128 - val_accuracy: 0.9132 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2115 - accuracy: 0.9143 - val_loss: 0.2137 - val_accuracy: 0.9140 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2050 - accuracy: 0.9167 - val_loss: 0.2073 - val_accuracy: 0.9176 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2041 - accuracy: 0.9177 - val_loss: 0.2073 - val_accuracy: 0.9166 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2038 - accuracy: 0.9175 - val_loss: 0.2069 - val_accuracy: 0.9170 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2035 - accuracy: 0.9177 - val_loss: 0.2073 - val_accuracy: 0.9166 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2034 - accuracy: 0.9176 - val_loss: 0.2067 - val_accuracy: 0.9170 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2032 - accuracy: 0.9180 - val_loss: 0.2067 - val_accuracy: 0.9173 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2030 - accuracy: 0.9178 - val_loss: 0.2087 - val_accuracy: 0.9154 - lr: 2.0000e-04\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2028 - accuracy: 0.9180 - val_loss: 0.2060 - val_accuracy: 0.9179 - lr: 2.0000e-04\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2028 - accuracy: 0.9178 - val_loss: 0.2070 - val_accuracy: 0.9162 - lr: 2.0000e-04\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2025 - accuracy: 0.9181 - val_loss: 0.2073 - val_accuracy: 0.9167 - lr: 2.0000e-04\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2025 - accuracy: 0.9181 - val_loss: 0.2075 - val_accuracy: 0.9164 - lr: 2.0000e-04\n",
      "Epoch 43/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2023 - accuracy: 0.9178 - val_loss: 0.2069 - val_accuracy: 0.9172 - lr: 2.0000e-04\n",
      "Epoch 44/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2022 - accuracy: 0.9180 - val_loss: 0.2061 - val_accuracy: 0.9175 - lr: 2.0000e-04\n",
      "Epoch 45/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2006 - accuracy: 0.9194 - val_loss: 0.2058 - val_accuracy: 0.9180 - lr: 4.0000e-05\n",
      "Epoch 46/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2004 - accuracy: 0.9192 - val_loss: 0.2061 - val_accuracy: 0.9176 - lr: 4.0000e-05\n",
      "Epoch 47/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2003 - accuracy: 0.9192 - val_loss: 0.2058 - val_accuracy: 0.9178 - lr: 4.0000e-05\n",
      "Epoch 48/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2003 - accuracy: 0.9191 - val_loss: 0.2060 - val_accuracy: 0.9175 - lr: 4.0000e-05\n",
      "Epoch 49/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2003 - accuracy: 0.9193 - val_loss: 0.2060 - val_accuracy: 0.9181 - lr: 4.0000e-05\n",
      "Epoch 50/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2002 - accuracy: 0.9192 - val_loss: 0.2059 - val_accuracy: 0.9178 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_combined.drop(columns='satisfaction')\n",
    "y_train = df_train_combined['satisfaction']\n",
    "\n",
    "X_test = df_test_combined.drop(columns='satisfaction')\n",
    "y_test = df_test_combined['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='tanh'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m10.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 355.78 segundos\n",
      "Pérdida: 0.2001865804195404\n",
      "Accuracy Modelo: 91.92277789115906\n",
      "Recall: 0.8763748350197976\n",
      "Specificity: 0.5817789\n",
      "F1-Score: 0.8975398756420654\n",
      "Precisión: 0.9197525163911718\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m10.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura 11: Nuevos features + Variables individuales (Aumentando epochs)\n",
    "- Epochs = 100\n",
    "- 1ra capa = 64 relu\n",
    "- 2da capa = 32 relu\n",
    "- 3ra capa = 1 sigmoid\n",
    "- learning_rate = 0.001\n",
    "- optimazador = Adam\n",
    "- loss = 'binary_crossentropy'\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2956 - accuracy: 0.8769 - val_loss: 0.2649 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2642 - accuracy: 0.8923 - val_loss: 0.2463 - val_accuracy: 0.9010 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2538 - accuracy: 0.8966 - val_loss: 0.2401 - val_accuracy: 0.9034 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2590/2590 [==============================] - 11s 4ms/step - loss: 0.2485 - accuracy: 0.8997 - val_loss: 0.2341 - val_accuracy: 0.9070 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2590/2590 [==============================] - 16s 6ms/step - loss: 0.2420 - accuracy: 0.9018 - val_loss: 0.2295 - val_accuracy: 0.9065 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2379 - accuracy: 0.9044 - val_loss: 0.2262 - val_accuracy: 0.9084 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2590/2590 [==============================] - 4s 2ms/step - loss: 0.2353 - accuracy: 0.9052 - val_loss: 0.2256 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2326 - accuracy: 0.9064 - val_loss: 0.2284 - val_accuracy: 0.9081 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2298 - accuracy: 0.9071 - val_loss: 0.2274 - val_accuracy: 0.9082 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2280 - accuracy: 0.9078 - val_loss: 0.2175 - val_accuracy: 0.9119 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2264 - accuracy: 0.9089 - val_loss: 0.2176 - val_accuracy: 0.9121 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2249 - accuracy: 0.9088 - val_loss: 0.2220 - val_accuracy: 0.9105 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.2232 - accuracy: 0.9095 - val_loss: 0.2163 - val_accuracy: 0.9123 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2214 - accuracy: 0.9105 - val_loss: 0.2269 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2204 - accuracy: 0.9106 - val_loss: 0.2182 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2189 - accuracy: 0.9111 - val_loss: 0.2164 - val_accuracy: 0.9116 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2181 - accuracy: 0.9120 - val_loss: 0.2187 - val_accuracy: 0.9116 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2590/2590 [==============================] - 8s 3ms/step - loss: 0.2167 - accuracy: 0.9121 - val_loss: 0.2160 - val_accuracy: 0.9123 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2590/2590 [==============================] - 11s 4ms/step - loss: 0.2158 - accuracy: 0.9120 - val_loss: 0.2175 - val_accuracy: 0.9135 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2151 - accuracy: 0.9126 - val_loss: 0.2176 - val_accuracy: 0.9141 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2138 - accuracy: 0.9135 - val_loss: 0.2145 - val_accuracy: 0.9118 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2133 - accuracy: 0.9141 - val_loss: 0.2164 - val_accuracy: 0.9122 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2123 - accuracy: 0.9137 - val_loss: 0.2142 - val_accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2110 - accuracy: 0.9149 - val_loss: 0.2145 - val_accuracy: 0.9141 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2104 - accuracy: 0.9142 - val_loss: 0.2220 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2099 - accuracy: 0.9147 - val_loss: 0.2096 - val_accuracy: 0.9148 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "2590/2590 [==============================] - 10s 4ms/step - loss: 0.2093 - accuracy: 0.9146 - val_loss: 0.2118 - val_accuracy: 0.9158 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.2085 - accuracy: 0.9151 - val_loss: 0.2089 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2081 - accuracy: 0.9156 - val_loss: 0.2095 - val_accuracy: 0.9158 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2074 - accuracy: 0.9155 - val_loss: 0.2092 - val_accuracy: 0.9138 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "2590/2590 [==============================] - 7s 3ms/step - loss: 0.2073 - accuracy: 0.9160 - val_loss: 0.2104 - val_accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "2590/2590 [==============================] - 11s 4ms/step - loss: 0.2064 - accuracy: 0.9162 - val_loss: 0.2096 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.2061 - accuracy: 0.9161 - val_loss: 0.2119 - val_accuracy: 0.9144 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1983 - accuracy: 0.9192 - val_loss: 0.2062 - val_accuracy: 0.9156 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1971 - accuracy: 0.9199 - val_loss: 0.2054 - val_accuracy: 0.9169 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1966 - accuracy: 0.9198 - val_loss: 0.2053 - val_accuracy: 0.9170 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1966 - accuracy: 0.9197 - val_loss: 0.2050 - val_accuracy: 0.9175 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1961 - accuracy: 0.9205 - val_loss: 0.2054 - val_accuracy: 0.9169 - lr: 2.0000e-04\n",
      "Epoch 39/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1960 - accuracy: 0.9204 - val_loss: 0.2053 - val_accuracy: 0.9173 - lr: 2.0000e-04\n",
      "Epoch 40/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1958 - accuracy: 0.9204 - val_loss: 0.2055 - val_accuracy: 0.9175 - lr: 2.0000e-04\n",
      "Epoch 41/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1956 - accuracy: 0.9200 - val_loss: 0.2048 - val_accuracy: 0.9176 - lr: 2.0000e-04\n",
      "Epoch 42/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1954 - accuracy: 0.9208 - val_loss: 0.2051 - val_accuracy: 0.9175 - lr: 2.0000e-04\n",
      "Epoch 43/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1951 - accuracy: 0.9209 - val_loss: 0.2053 - val_accuracy: 0.9176 - lr: 2.0000e-04\n",
      "Epoch 44/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1951 - accuracy: 0.9207 - val_loss: 0.2055 - val_accuracy: 0.9167 - lr: 2.0000e-04\n",
      "Epoch 45/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1947 - accuracy: 0.9206 - val_loss: 0.2063 - val_accuracy: 0.9174 - lr: 2.0000e-04\n",
      "Epoch 46/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1946 - accuracy: 0.9205 - val_loss: 0.2041 - val_accuracy: 0.9183 - lr: 2.0000e-04\n",
      "Epoch 47/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1946 - accuracy: 0.9207 - val_loss: 0.2053 - val_accuracy: 0.9165 - lr: 2.0000e-04\n",
      "Epoch 48/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1944 - accuracy: 0.9210 - val_loss: 0.2049 - val_accuracy: 0.9186 - lr: 2.0000e-04\n",
      "Epoch 49/50\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1941 - accuracy: 0.9209 - val_loss: 0.2045 - val_accuracy: 0.9178 - lr: 2.0000e-04\n",
      "Epoch 50/50\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1942 - accuracy: 0.9211 - val_loss: 0.2057 - val_accuracy: 0.9178 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_combined.drop(columns='satisfaction')\n",
    "y_train = df_train_combined['satisfaction']\n",
    "\n",
    "X_test = df_test_combined.drop(columns='satisfaction')\n",
    "y_test = df_test_combined['satisfaction']\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='tanh'),\n",
    "    layers.Dense(32, activation='tanh'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('../MODELS/m11.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[time_callback, early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de entrenamiento: 333.18 segundos\n",
      "Pérdida: 0.19417467713356018\n",
      "Accuracy Modelo: 92.11342334747314\n",
      "Recall: 0.878926528816542\n",
      "Specificity: 0.5810451\n",
      "F1-Score: 0.8993832440462792\n",
      "Precisión: 0.9208148967551623\n"
     ]
    }
   ],
   "source": [
    "#Resultados Modelo\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "print(f'Tiempo total de entrenamiento: {time_callback.total_train_time:.2f} segundos')\n",
    "print(f'Pérdida: {loss[-1]}')\n",
    "print(f'Accuracy Modelo: {accuracy[-1]*100}')\n",
    "\n",
    "# Resultados Validación\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 0)), dtype=tf.float32))\n",
    "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(tf.round(y_pred), 1)), dtype=tf.float32))\n",
    "    return true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "# Validación con x_test\n",
    "\n",
    "model = tf.keras.models.load_model('../MODELS/m11.h5')\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "specificity = specificity(y_test, y_pred).numpy()\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F1-Score:\", f1)\n",
    "print('Precisión:', precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorenviron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
